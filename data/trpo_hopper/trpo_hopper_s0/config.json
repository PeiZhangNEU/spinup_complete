{
    "ac_kwargs":	{
        "hidden_sizes":	[
            64,
            64
        ]
    },
    "actor_critic":	"MLPActorCritic",
    "backtrack_alpha":	0.5,
    "backtrack_coeff":	1.0,
    "backtrack_iter":	10,
    "delta":	0.01,
    "device":	"cuda:0",
    "env_fn":	"<function <lambda> at 0x7fc3115b4200>",
    "exp_name":	"trpo_hopper",
    "gamma":	0.99,
    "lam":	0.97,
    "logger_kwargs":	{
        "exp_name":	"trpo_hopper",
        "output_dir":	"/home/zp/deeplearning/spinningup_project/data/trpo_hopper/trpo_hopper_s0"
    },
    "mode":	"TRPO",
    "self":	{
        "<spinup.alogos.trpo.trpo.trpo object at 0x7fc310a87550>":	{
            "ac":	{
                "MLPActorCritic(\n  (pi): MLPGaussianActor(\n    (mu_net): Sequential(\n      (0): Linear(in_features=11, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=64, out_features=3, bias=True)\n      (5): Identity()\n    )\n  )\n  (v): MLPCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=11, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=64, out_features=1, bias=True)\n      (5): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "MLPGaussianActor(\n  (mu_net): Sequential(\n    (0): Linear(in_features=11, out_features=64, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=64, out_features=3, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "mu_net":	{
                                        "Sequential(\n  (0): Linear(in_features=11, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=3, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=11, out_features=64, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1690, -0.0876, -0.0053,  0.2295, -0.2611, -0.0208, -0.2205,  0.0847,\n         0.1604, -0.1062,  0.0436,  0.1789,  0.1569,  0.1047, -0.0343, -0.0305,\n        -0.0719,  0.0106, -0.2190, -0.0034,  0.1400,  0.2196,  0.0650, -0.2894,\n        -0.1923,  0.0232, -0.0364,  0.0524,  0.0027, -0.0596,  0.1058, -0.2237,\n        -0.2602,  0.1594,  0.1143, -0.1984, -0.0529,  0.1786, -0.2202, -0.2578,\n         0.2499,  0.2735,  0.1173,  0.2816, -0.2720,  0.2330,  0.1316, -0.1268,\n         0.1078,  0.2677,  0.0383, -0.2816,  0.0156, -0.2850,  0.0041, -0.2866,\n         0.1285, -0.2212, -0.1849, -0.1152, -0.0104,  0.1114, -0.1414, -0.0369],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 5.4141e-02,  1.6113e-01, -1.4225e-01,  1.6002e-01, -1.5729e-01,\n          8.6254e-02,  1.0037e-01, -2.5793e-01, -8.7578e-02,  1.9048e-01,\n          2.7444e-01],\n        [-2.4710e-01, -8.6364e-02,  2.0492e-01, -1.2012e-01,  1.0582e-01,\n         -1.9747e-02, -1.4898e-01, -2.3155e-01,  2.7211e-01, -2.9919e-01,\n         -9.5591e-02],\n        [-2.6901e-01, -8.9960e-02, -7.6308e-03, -2.1350e-01, -8.2136e-03,\n         -8.9956e-02, -8.8068e-02,  1.8671e-01,  6.9136e-02, -2.7019e-01,\n         -2.1307e-01],\n        [ 1.2710e-01, -2.4466e-01, -1.0406e-01, -2.8413e-01, -2.0324e-01,\n         -3.0028e-01, -1.0440e-01, -5.0968e-02,  1.0823e-01, -2.7649e-01,\n          2.8740e-02],\n        [ 2.0589e-01,  9.4873e-02, -1.1239e-01, -9.3379e-02,  2.4048e-01,\n         -1.3009e-01, -2.0245e-01,  3.9185e-02, -2.2132e-01, -8.3849e-02,\n         -3.9292e-02],\n        [ 5.0953e-02,  2.4421e-01, -1.1770e-03, -2.6835e-01, -1.0936e-01,\n         -6.2004e-02,  1.8599e-01, -1.0171e-01,  1.9423e-01, -2.5978e-02,\n         -2.1285e-02],\n        [-1.0625e-01, -1.8009e-02,  1.9741e-01, -2.4266e-01, -1.4678e-01,\n          4.3802e-03, -2.3465e-01, -1.0864e-01, -2.5484e-01, -5.0709e-02,\n         -9.5393e-02],\n        [ 3.5927e-02, -2.9739e-01,  1.6154e-01,  1.1888e-01, -9.2234e-02,\n         -8.8440e-02, -1.5919e-01, -2.3108e-01,  7.9378e-02, -2.7672e-01,\n          3.1407e-02],\n        [ 6.9912e-02,  2.3987e-01, -2.2929e-01, -4.3322e-03, -1.7616e-01,\n          1.2829e-01, -2.5215e-01,  2.1766e-01, -2.1364e-01,  2.8563e-01,\n         -2.7680e-01],\n        [-2.2288e-01, -2.4635e-01, -1.0269e-01,  8.3526e-02,  1.2382e-01,\n         -1.2256e-01, -1.6784e-01, -1.8750e-01,  1.8200e-01, -1.1446e-01,\n         -2.0819e-01],\n        [ 1.4686e-01,  2.7703e-01, -1.7001e-01, -2.5330e-01, -1.1521e-01,\n          1.9152e-01, -1.2436e-01,  3.0659e-02,  9.1523e-02, -9.5426e-02,\n          1.5368e-01],\n        [-3.0057e-01, -1.4344e-01, -1.3619e-01,  9.5425e-02, -1.7744e-01,\n         -2.7663e-01, -1.6362e-01,  1.5686e-01, -2.0212e-01, -2.0796e-02,\n         -2.1171e-01],\n        [ 2.7986e-01, -1.5343e-01,  2.6659e-01,  2.7906e-01,  1.0195e-01,\n         -8.3553e-02,  2.2882e-02, -8.2358e-02,  2.7981e-01,  2.7597e-01,\n         -2.9730e-01],\n        [-1.9712e-01, -2.0831e-01,  3.1530e-02, -2.6606e-01,  8.5405e-02,\n          2.6540e-01, -2.8941e-01, -9.0200e-02,  1.1604e-01,  1.5562e-01,\n         -2.7850e-02],\n        [ 9.2527e-02,  1.1769e-01, -3.2822e-02,  7.6254e-03,  2.4946e-01,\n         -2.2294e-01, -3.3306e-02,  2.1548e-01,  1.5662e-01,  2.6939e-01,\n         -2.8464e-01],\n        [ 2.3888e-03, -2.6359e-01,  2.1486e-01, -4.9504e-02,  1.7277e-01,\n          2.1842e-01,  1.3502e-01, -1.6518e-01, -2.7339e-01,  9.5725e-03,\n          1.7320e-01],\n        [-1.7007e-01, -1.6209e-01,  9.4105e-02, -2.8023e-01,  5.5122e-04,\n         -4.3738e-02,  1.5160e-01, -2.3739e-01, -1.4602e-01,  2.5643e-01,\n          1.9590e-01],\n        [-2.8940e-01, -3.8497e-02,  6.7296e-02, -2.3141e-01, -1.9524e-01,\n         -9.6383e-03,  2.5529e-01,  5.7778e-02,  1.1115e-01,  2.3537e-01,\n         -8.0454e-02],\n        [-3.5214e-02,  4.1133e-02, -2.2591e-01,  2.5287e-01,  2.7737e-01,\n          1.6746e-01,  2.7813e-02,  1.9168e-01,  2.8584e-01,  1.6411e-01,\n         -2.5609e-03],\n        [ 8.4833e-02,  8.0571e-02,  1.8235e-01, -1.1174e-01,  8.9676e-02,\n         -2.8040e-01,  1.2340e-01, -6.6818e-02, -1.4559e-01,  1.0762e-01,\n         -3.2908e-03],\n        [-2.5025e-01,  2.5416e-01, -4.3708e-02, -3.3329e-02, -1.2222e-01,\n          1.4890e-01, -2.9900e-01, -4.3950e-03, -8.6760e-02, -2.1829e-01,\n          2.0139e-01],\n        [-1.5008e-01, -1.7350e-01, -6.7908e-02,  2.3246e-01, -2.5102e-01,\n         -1.7367e-01,  8.9359e-02, -1.9772e-01, -2.2382e-01,  1.0144e-01,\n          2.0532e-01],\n        [-1.2658e-01,  2.4014e-01, -2.7797e-03,  2.4348e-01,  2.2694e-01,\n          2.3494e-01,  2.4786e-01,  8.5139e-02, -2.6877e-01, -8.5165e-02,\n         -1.6442e-01],\n        [-8.6180e-02, -6.6545e-02, -1.0482e-01, -1.7499e-02,  1.1549e-01,\n         -1.1902e-01,  5.3084e-02, -2.4499e-01,  1.2521e-01, -4.0170e-02,\n          2.6467e-01],\n        [-2.1661e-01, -2.6421e-01, -2.0462e-03,  3.7357e-02, -6.5827e-02,\n         -1.0044e-01,  2.8995e-01,  1.6715e-01,  2.6762e-01,  1.0339e-01,\n         -1.7027e-01],\n        [ 2.4323e-01, -1.6892e-01,  2.4539e-02, -2.6898e-01,  5.6358e-02,\n          3.3409e-02,  1.6957e-01,  2.2962e-01, -1.9035e-01, -2.1432e-01,\n          2.8797e-01],\n        [-2.7702e-01,  1.8178e-01,  2.3547e-01, -2.4546e-01,  1.5486e-01,\n          7.7084e-02, -1.2873e-01,  1.5269e-01, -1.0246e-01,  2.0878e-02,\n          2.1146e-01],\n        [ 5.9724e-03,  2.4736e-01,  1.2225e-01,  2.7311e-01, -5.0316e-02,\n         -1.9815e-01, -1.2967e-01,  2.2139e-01, -2.7980e-01, -2.5843e-01,\n          2.9952e-01],\n        [ 6.2903e-02,  8.0521e-02,  1.3570e-01, -2.2530e-02,  1.2476e-01,\n         -1.2682e-01,  2.6329e-02,  3.3994e-03, -2.8103e-02, -1.6068e-01,\n         -7.5600e-02],\n        [ 1.3387e-01, -2.0812e-01,  1.8799e-01, -2.6415e-01,  4.3292e-02,\n          1.9419e-01,  2.9427e-01,  4.9464e-02,  8.4303e-02, -1.2142e-01,\n          2.2382e-01],\n        [-1.7442e-01, -2.7036e-01,  2.5649e-01,  7.7196e-02, -3.2196e-02,\n         -2.6069e-01,  1.9362e-01,  1.3820e-01, -1.9296e-01,  2.7893e-01,\n         -8.3676e-02],\n        [ 2.4162e-01, -4.0851e-02,  1.8024e-02,  1.5459e-01,  8.6581e-02,\n         -8.2270e-02, -1.7551e-02,  2.2081e-01,  3.8897e-02, -8.4139e-02,\n          1.0519e-02],\n        [-3.5243e-03, -1.1274e-01,  1.1233e-01, -1.8401e-01,  1.6560e-01,\n          9.0717e-02,  1.3309e-01,  2.6576e-02, -8.6575e-02, -2.0615e-01,\n          2.1704e-01],\n        [-3.9277e-03, -8.0862e-03,  1.1379e-01, -1.3952e-01, -7.2595e-02,\n         -6.3419e-02, -2.1082e-01,  2.3405e-01,  2.8105e-01, -2.1513e-01,\n         -2.5119e-01],\n        [ 1.6387e-01, -2.0347e-01,  2.7932e-01,  2.6374e-01, -2.4643e-01,\n         -1.2420e-01, -2.0155e-01, -1.2941e-01,  2.7290e-01, -1.1614e-01,\n         -2.2722e-01],\n        [ 1.3858e-01,  2.9085e-04, -1.1467e-01,  2.3641e-01, -1.4426e-01,\n         -2.9309e-01, -6.0260e-02,  2.9813e-02, -2.5828e-01,  4.5000e-02,\n          1.0108e-01],\n        [-2.3825e-01, -5.7254e-02, -2.6274e-01,  2.7991e-01, -2.9205e-01,\n         -1.3471e-01,  2.4496e-01, -6.4255e-02, -2.7666e-01, -1.3966e-01,\n          1.1213e-01],\n        [-2.3667e-02,  1.4058e-01,  1.9963e-01,  1.1239e-01, -6.8975e-02,\n          2.5886e-01,  2.5588e-01,  2.1911e-01,  1.0708e-01,  4.9705e-02,\n         -1.8893e-01],\n        [ 2.1477e-01,  2.4439e-01, -9.4025e-02,  1.7023e-01,  1.4128e-02,\n          1.7355e-01,  5.2116e-02, -9.8065e-03, -1.2269e-01, -1.9443e-02,\n          8.3110e-02],\n        [-2.2881e-01,  8.8861e-02,  2.2460e-01, -1.1185e-01, -1.3728e-01,\n         -2.9171e-01, -5.2695e-02, -1.1726e-01,  1.9863e-01,  8.2572e-02,\n          2.4830e-01],\n        [-2.0468e-01, -1.8765e-01, -2.7354e-01,  2.4135e-01,  2.2398e-01,\n         -2.3910e-01, -1.4518e-01, -5.5107e-02, -2.4380e-01,  1.6696e-01,\n          1.0106e-01],\n        [-1.6403e-01,  1.7899e-01, -1.6452e-01,  2.5203e-01, -6.9909e-02,\n          1.5185e-01,  1.1032e-01, -2.5226e-01,  1.2596e-01,  2.6620e-01,\n         -2.6763e-01],\n        [ 5.1747e-02,  2.3534e-01, -6.3290e-02,  8.5215e-02, -7.2321e-02,\n         -1.1997e-01, -7.2169e-03, -2.1879e-01, -4.1903e-02, -1.1385e-01,\n         -2.9068e-01],\n        [-1.6837e-01,  1.2374e-01, -2.3703e-01,  2.8351e-01,  5.8341e-02,\n         -9.6646e-03, -6.7235e-02, -1.0607e-01, -7.1488e-02, -4.3852e-02,\n         -8.0702e-02],\n        [ 1.1262e-01,  7.4767e-02,  1.0383e-01, -2.4881e-01, -1.0026e-01,\n          2.5234e-01,  5.4249e-02,  7.0429e-02,  2.4163e-01, -2.0650e-01,\n         -9.2417e-02],\n        [-1.7115e-01,  4.4800e-02, -2.9604e-01,  2.6307e-01,  1.2344e-01,\n          2.0139e-01, -1.1598e-01, -1.3348e-01,  2.8452e-01, -1.4037e-01,\n          2.9104e-01],\n        [-1.6686e-01, -2.5411e-01,  1.2424e-01, -2.3874e-02,  2.2768e-01,\n          2.4120e-01, -2.8235e-01,  1.2549e-01, -8.4508e-02,  8.7327e-02,\n          5.5658e-02],\n        [ 1.4882e-01, -5.4782e-02,  6.4714e-02, -2.9247e-01, -1.1255e-01,\n          2.0523e-04, -5.6595e-02,  2.8466e-01,  1.1190e-01, -4.5624e-03,\n          3.0036e-02],\n        [-1.8343e-01,  8.3076e-02, -2.9103e-02, -2.4217e-01,  2.9580e-01,\n         -7.8742e-02, -2.3733e-01,  2.1319e-01,  2.8591e-01, -8.7737e-02,\n          2.7009e-01],\n        [-2.6284e-01,  2.4206e-01, -8.0135e-02,  1.0080e-01,  9.8725e-04,\n          5.7854e-02,  1.6848e-01, -2.0279e-01,  1.4428e-01,  7.0456e-02,\n         -5.8496e-02],\n        [ 2.5925e-02,  2.1938e-01,  5.8988e-02, -4.8142e-03,  1.0599e-01,\n          2.0843e-02, -1.0647e-01, -6.2003e-02,  1.9362e-02,  1.2848e-01,\n         -2.2099e-01],\n        [-1.4639e-01,  9.7031e-02,  1.1358e-02,  1.8021e-01, -1.4904e-01,\n         -8.6164e-02, -2.6472e-01, -1.6025e-01, -1.0553e-01,  8.4820e-02,\n          1.9494e-01],\n        [ 2.7516e-01,  6.7245e-02,  2.1341e-01, -1.9033e-01,  2.1212e-01,\n          5.7614e-02, -6.0208e-02, -6.9623e-02,  1.6813e-03, -3.0039e-01,\n         -5.6171e-02],\n        [ 1.7953e-01, -3.1666e-05, -2.7640e-01,  9.9144e-02,  2.3047e-01,\n          7.5992e-02,  9.0470e-02,  8.1115e-02,  2.8263e-02,  7.6257e-02,\n          1.9498e-01],\n        [ 7.8648e-02,  1.5596e-02, -2.8873e-01,  8.2213e-03, -2.6894e-01,\n         -5.9505e-02,  1.6013e-01,  2.9564e-01,  8.2151e-02, -8.7731e-02,\n          1.1874e-01],\n        [ 1.6070e-01,  2.8351e-01, -3.8723e-02, -2.0745e-01,  2.3738e-01,\n          1.7762e-01, -2.7196e-01,  2.7299e-01,  1.6690e-01,  1.6051e-02,\n          9.1469e-02],\n        [ 1.6977e-01, -9.5645e-02,  8.4201e-02,  8.1221e-02, -1.1091e-01,\n         -3.0030e-01, -1.3949e-01, -1.9598e-01, -5.4677e-02, -7.3659e-02,\n          2.8986e-01],\n        [ 1.5187e-02, -1.4250e-01,  2.0053e-01,  1.5450e-01,  1.3975e-01,\n          5.6282e-03, -1.4537e-01,  1.7954e-01,  2.8417e-01,  7.9677e-03,\n          4.7305e-03],\n        [-1.6650e-01,  4.9634e-02,  2.4070e-01, -1.7955e-01, -2.2255e-01,\n          1.9340e-01,  1.0418e-01,  9.0339e-02,  1.7757e-01, -2.5615e-02,\n          1.1988e-02],\n        [-2.0033e-01, -1.1982e-01,  6.9072e-02, -1.1493e-01,  1.9692e-01,\n         -1.9797e-03,  1.7827e-01, -1.0631e-01, -1.1032e-01, -2.9657e-01,\n          4.0516e-02],\n        [ 2.0428e-01, -1.8340e-01, -1.3979e-01,  5.4584e-02, -2.5143e-01,\n          3.3438e-02,  7.9660e-02, -2.0481e-01,  1.7440e-01,  1.8189e-01,\n         -1.6667e-01],\n        [ 1.8847e-01,  1.8160e-01,  2.4184e-01,  2.1652e-01,  1.0820e-01,\n          1.8635e-01,  1.9865e-01, -2.3529e-02, -1.3480e-01, -2.8353e-01,\n          1.9890e-01],\n        [ 1.5306e-01,  2.0942e-01, -2.7889e-01, -2.2951e-01, -2.7532e-02,\n          2.1926e-01, -1.7004e-01,  1.9184e-02,  2.8936e-01, -5.8070e-02,\n          1.2145e-01],\n        [ 1.8020e-01, -1.6466e-01, -1.1366e-02,  9.3561e-02, -1.4507e-01,\n          2.4879e-01,  1.4270e-01, -2.9740e-01,  1.6651e-01, -2.5830e-01,\n          6.6826e-02]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	11,
                                                        "out_features":	64,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "Tanh()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=64, out_features=64, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0842,  0.0403,  0.0135, -0.1200, -0.1230, -0.0367, -0.0280, -0.1178,\n        -0.0710, -0.0744,  0.1038,  0.0546, -0.0894,  0.0236, -0.0188, -0.0949,\n        -0.0080,  0.0714, -0.1044,  0.0981,  0.0690, -0.0026, -0.0752, -0.0390,\n        -0.0962, -0.0048, -0.0562, -0.0944, -0.0233,  0.1069, -0.0793, -0.0886,\n        -0.0828, -0.0353,  0.0551,  0.0271,  0.0549,  0.0160, -0.0313, -0.1025,\n        -0.0495, -0.1197, -0.0032, -0.0227, -0.0083,  0.0762, -0.0922,  0.0129,\n        -0.0826, -0.0039,  0.0927, -0.1164, -0.0045, -0.0501,  0.0540,  0.0853,\n         0.0555, -0.0699,  0.0249, -0.1075,  0.1002, -0.0629,  0.1222,  0.0180],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0144,  0.0939, -0.0602,  ..., -0.0545, -0.0357,  0.1187],\n        [-0.1050,  0.0103,  0.1082,  ..., -0.0587, -0.0432,  0.1028],\n        [ 0.0670,  0.0289, -0.0550,  ..., -0.0476, -0.1136, -0.0636],\n        ...,\n        [ 0.0279, -0.0612,  0.0543,  ..., -0.0252,  0.0169,  0.0493],\n        [-0.0008, -0.1146,  0.0277,  ..., -0.0236,  0.1037, -0.1233],\n        [-0.0476, -0.0840,  0.1127,  ...,  0.0464, -0.0758, -0.0866]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	64,
                                                        "out_features":	64,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "Tanh()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=64, out_features=3, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1167, -0.0273, -0.0312], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0329, -0.0193, -0.0339,  0.0985,  0.0028, -0.0138,  0.0141, -0.0470,\n          0.1229,  0.0497, -0.0336,  0.0041, -0.0495,  0.0215,  0.0083,  0.0560,\n         -0.0971,  0.1086,  0.0526,  0.0218,  0.0592, -0.0775,  0.0760,  0.1178,\n          0.0949,  0.0970, -0.0825,  0.0496,  0.0069, -0.0219, -0.0261,  0.0833,\n          0.1118,  0.0879, -0.0376, -0.0088, -0.0571,  0.0245, -0.0208, -0.1013,\n          0.0289,  0.0323, -0.1022,  0.0358,  0.1093,  0.0931,  0.1147,  0.0525,\n         -0.0089,  0.0345,  0.0023,  0.0593, -0.0326, -0.1155,  0.0633, -0.0411,\n         -0.0737, -0.0752,  0.0509,  0.0061,  0.0183, -0.0428,  0.0221,  0.0263],\n        [ 0.0886,  0.1186, -0.0798, -0.0238, -0.0871,  0.1206, -0.0068,  0.0568,\n          0.1234, -0.0794,  0.0787, -0.1154, -0.0997,  0.0985,  0.0575, -0.0715,\n          0.1150, -0.1099, -0.0639,  0.0602,  0.0816, -0.1099, -0.0275, -0.0670,\n          0.0190, -0.0399,  0.0963, -0.1238, -0.0491, -0.0859,  0.0743,  0.0712,\n         -0.0679,  0.0991, -0.0609, -0.0114,  0.0281,  0.1057,  0.1112,  0.0966,\n         -0.1192,  0.1196,  0.0323, -0.0360, -0.0581, -0.0988, -0.0910,  0.0440,\n          0.1036,  0.0132, -0.1122,  0.0638,  0.0357, -0.0095, -0.0654,  0.1076,\n         -0.1126,  0.0986,  0.0497,  0.0542, -0.0476,  0.1238,  0.0539,  0.0028],\n        [ 0.0177, -0.0503, -0.0421,  0.0242, -0.0845,  0.0727, -0.0149, -0.0361,\n          0.0105, -0.0832,  0.1165,  0.0626, -0.0283,  0.1004,  0.0009,  0.0962,\n          0.1222, -0.0730, -0.0237,  0.0777,  0.0670,  0.1100,  0.0195, -0.0449,\n          0.0678,  0.0674,  0.1166, -0.0295, -0.1026, -0.0944,  0.0767,  0.0945,\n          0.0660, -0.0494, -0.0160,  0.1197, -0.0997, -0.0101, -0.0635,  0.0529,\n         -0.0140,  0.0029, -0.0541, -0.0549, -0.0230, -0.0520, -0.0009, -0.0150,\n         -0.0940,  0.1232, -0.0532,  0.1137, -0.0969,  0.0103,  0.0596,  0.0797,\n          0.1210, -0.0597, -0.0386, -0.0645, -0.0759, -0.0548, -0.0911, -0.0469]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	64,
                                                        "out_features":	3,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "log_std":	"Parameter containing:\ntensor([-0.5000, -0.5000, -0.5000], device='cuda:0', requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "v":	{
                            "MLPCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=11, out_features=64, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=64, out_features=1, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=11, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=1, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=11, out_features=64, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1624,  0.1762,  0.0945, -0.1049,  0.1824, -0.2220, -0.2454,  0.2046,\n         0.1100, -0.1954,  0.0892,  0.1106,  0.1946, -0.1284, -0.0592, -0.1598,\n        -0.1521, -0.1451, -0.1761,  0.1581, -0.2694, -0.1363,  0.0384, -0.0316,\n         0.2094,  0.1734, -0.0236, -0.2619, -0.2038,  0.1972,  0.1469, -0.1363,\n        -0.1271, -0.2080,  0.0023,  0.1265,  0.1104,  0.1560, -0.0863,  0.1759,\n        -0.2394,  0.2215, -0.1381, -0.1691,  0.0486,  0.0982,  0.1562, -0.1885,\n        -0.1528, -0.2936,  0.1448, -0.0788, -0.1565, -0.2878,  0.0567,  0.0484,\n         0.0350, -0.1886, -0.0728,  0.1886,  0.2500, -0.2751, -0.1687,  0.1188],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-2.2332e-01, -1.8876e-01, -2.4180e-01, -2.6697e-02, -1.2155e-02,\n         -7.5172e-03,  1.9660e-01, -7.1801e-02, -7.1773e-02,  1.1780e-01,\n         -2.8576e-01],\n        [ 1.6933e-01, -1.7383e-01, -8.7280e-02,  1.2505e-01, -1.1139e-01,\n         -2.2754e-01,  1.8747e-01,  1.0720e-01,  1.6512e-01,  3.4975e-02,\n         -1.3721e-01],\n        [-1.5691e-01,  7.8367e-02,  2.9399e-01, -8.8598e-02,  1.9625e-01,\n         -2.4945e-01, -9.1432e-02,  2.4665e-01,  1.4598e-01,  1.3584e-01,\n         -2.8832e-01],\n        [-2.8275e-01, -1.6853e-02, -5.2873e-02,  2.8608e-01, -2.8011e-01,\n          9.8234e-02,  2.6776e-01,  2.3872e-01,  8.8866e-02,  2.4411e-01,\n          9.3631e-03],\n        [ 1.6211e-01,  1.6519e-01, -2.6252e-01, -3.3106e-02, -2.0619e-01,\n          3.0132e-01,  1.0526e-01,  1.1617e-01,  2.9970e-01, -1.1349e-01,\n         -2.3086e-01],\n        [ 9.4828e-02,  2.0153e-01,  4.4588e-03,  2.8294e-01,  2.7311e-01,\n          2.0378e-01,  5.8843e-03, -5.7444e-02, -1.0210e-01,  7.7234e-02,\n         -3.6243e-02],\n        [ 2.4744e-02, -1.6279e-01, -1.0642e-01, -1.9001e-02,  2.4471e-01,\n         -2.6831e-01,  3.8283e-02,  1.2188e-01,  1.1136e-01,  7.5069e-03,\n         -1.2190e-01],\n        [ 6.5991e-02, -7.8874e-02,  2.7760e-01,  1.1161e-01, -1.9169e-01,\n         -2.2104e-01,  6.6596e-02,  2.2514e-01, -2.3892e-01, -2.1263e-01,\n         -2.4192e-01],\n        [ 2.3654e-01, -4.9175e-02,  3.0118e-01,  1.6870e-01,  2.9562e-02,\n          1.3876e-01,  9.4508e-03,  2.4377e-02, -1.6575e-01,  1.5516e-01,\n         -1.7504e-01],\n        [ 2.5302e-02,  8.0326e-02, -1.9579e-01, -4.7019e-02,  1.8448e-01,\n          2.7822e-01,  1.8006e-01,  2.8674e-01, -2.8827e-02,  1.2987e-01,\n          1.5987e-01],\n        [ 4.7987e-02, -1.0797e-01,  1.7200e-01, -1.5645e-02, -2.3627e-01,\n          2.5771e-01, -1.5178e-01,  1.3774e-02, -1.0362e-01,  1.8805e-01,\n          1.9875e-01],\n        [-2.2174e-01,  5.3257e-02, -2.2280e-01,  3.1523e-02,  2.4147e-02,\n         -6.5517e-02, -1.6631e-01,  1.6378e-01, -2.2048e-01, -1.2771e-01,\n         -2.4421e-01],\n        [-1.5612e-01,  1.7257e-01,  1.0700e-01, -5.5708e-02, -3.7174e-02,\n         -3.7268e-02, -2.6598e-01,  2.6440e-01, -2.0065e-01,  6.8857e-02,\n         -6.9375e-02],\n        [-1.3627e-01, -2.7891e-01,  1.4635e-01,  1.6489e-01,  5.5326e-02,\n         -2.9360e-01,  9.6539e-02,  2.2203e-01,  1.3144e-01,  1.4619e-01,\n         -2.2400e-01],\n        [ 1.8121e-01,  2.9743e-01,  2.4596e-01,  2.5851e-01, -2.2179e-01,\n          4.0635e-02,  4.3811e-02, -1.7131e-02,  2.6481e-02, -4.0332e-02,\n         -2.2357e-02],\n        [ 1.1569e-01, -8.2271e-02, -2.1622e-01, -2.1500e-01, -2.4443e-01,\n          2.2459e-01, -2.5660e-01, -1.6396e-01, -6.4289e-03, -2.5637e-01,\n         -2.6043e-01],\n        [-1.9617e-01, -1.4667e-01,  2.8630e-01, -2.4367e-01, -2.0818e-01,\n         -5.2244e-02,  6.2259e-02,  2.6246e-01, -2.9216e-01, -1.3707e-01,\n          2.6917e-01],\n        [ 2.8386e-01, -1.0355e-01,  2.0958e-01, -2.4785e-01,  2.5480e-01,\n          1.4799e-01,  8.8423e-02, -2.5573e-01, -6.7524e-02, -2.1181e-01,\n          1.1534e-01],\n        [-2.7472e-02,  1.7643e-01, -6.0306e-02, -1.5375e-01, -3.3470e-02,\n         -6.8667e-02,  1.7701e-01,  9.6853e-02,  1.1269e-01,  1.3280e-01,\n          1.0990e-02],\n        [ 1.3153e-01,  2.6489e-01, -2.9380e-01,  1.8507e-01, -2.9935e-01,\n          1.7030e-01, -1.0731e-01,  2.9156e-02,  8.1263e-02, -1.7535e-01,\n          2.2232e-01],\n        [-8.1791e-02,  2.0256e-01, -6.1787e-02,  5.7007e-02,  6.2361e-02,\n         -2.0385e-01, -6.2321e-02, -2.4548e-01, -7.6373e-02, -2.3178e-01,\n          7.0159e-02],\n        [ 2.9395e-01,  1.6673e-01,  9.0589e-02,  7.4824e-02, -2.1004e-01,\n          2.3820e-01, -7.2674e-03, -8.3594e-02, -8.9571e-02,  1.4870e-02,\n          1.6138e-01],\n        [ 1.7426e-01, -2.8507e-01, -2.8515e-01,  2.6013e-02, -2.9001e-01,\n         -2.4925e-01, -1.7822e-01,  2.5567e-02,  5.6741e-02, -1.8318e-01,\n          2.8332e-01],\n        [-2.2436e-01, -4.0912e-02,  1.3938e-01,  1.2189e-01, -1.2447e-02,\n          1.8956e-01, -2.4845e-01, -2.1629e-01, -8.5975e-02,  2.5618e-01,\n          2.9049e-02],\n        [-2.1594e-01, -9.3293e-02, -2.3585e-01, -1.5172e-01,  2.8384e-01,\n         -1.2057e-01, -2.2032e-01,  2.8281e-01,  2.7011e-02,  9.3349e-02,\n         -7.7941e-02],\n        [-2.2723e-01,  2.0853e-01,  1.9083e-01, -2.2617e-01, -1.2373e-01,\n          2.4481e-01,  2.1486e-01,  2.1186e-01, -1.0406e-01, -2.5705e-01,\n          1.2513e-01],\n        [-1.3755e-01, -1.7560e-01,  1.2912e-01, -3.9356e-02,  1.6052e-01,\n          8.3033e-02, -1.7681e-01,  2.1405e-01, -2.2999e-01,  2.3857e-01,\n          1.9917e-01],\n        [-8.4097e-03, -7.3522e-02,  5.1083e-02, -8.6272e-02, -2.2764e-01,\n          6.5926e-02, -7.8723e-02,  1.5488e-01,  1.9717e-01,  1.7686e-01,\n         -4.1753e-03],\n        [-2.3004e-01,  2.3007e-01, -2.9837e-02, -8.4652e-02,  1.4901e-01,\n         -4.8512e-02,  5.1220e-02, -1.3524e-01,  4.8351e-02,  2.0185e-01,\n          2.3598e-01],\n        [ 1.3170e-01,  2.2044e-01, -2.4158e-01,  8.2110e-02,  2.2046e-02,\n         -7.3245e-02, -2.1845e-01,  1.8788e-01, -2.1005e-01,  2.4018e-01,\n          2.4775e-02],\n        [-2.1944e-01, -2.5796e-01, -2.3534e-01, -3.5402e-03, -7.0543e-02,\n         -1.7837e-01, -3.2779e-02, -1.0862e-01,  1.2894e-01, -1.3143e-01,\n          6.8769e-02],\n        [ 1.0419e-01,  7.8907e-02, -2.1341e-02, -1.1150e-01,  4.2720e-03,\n          1.2888e-01,  1.9800e-01,  2.7045e-01,  1.4943e-01,  5.3681e-02,\n         -8.0321e-02],\n        [-2.3052e-01,  1.4315e-01, -1.0714e-01, -1.4889e-01,  5.7996e-02,\n         -2.6970e-01, -2.9965e-01,  4.2158e-02,  1.9203e-01,  2.9917e-03,\n         -3.6427e-02],\n        [ 9.0656e-02, -4.7307e-02, -1.2856e-01,  1.0290e-01, -3.0344e-02,\n          2.0764e-01, -2.3760e-01,  8.6956e-02,  4.2646e-02, -3.0134e-01,\n         -3.7905e-02],\n        [-1.7309e-01,  1.7487e-01, -1.4082e-01,  2.7456e-02, -1.8819e-02,\n         -1.2935e-01, -2.6363e-02,  2.7592e-01,  1.5993e-01,  2.8836e-01,\n          2.1778e-01],\n        [-1.4979e-01,  5.5819e-02,  1.0051e-01,  2.4226e-01,  6.7796e-02,\n         -1.7625e-01,  1.1218e-01, -1.9223e-01, -2.2355e-01,  2.7607e-01,\n         -1.0480e-01],\n        [-1.4924e-01,  1.0560e-01,  7.0235e-02,  1.9986e-01, -1.8440e-01,\n         -1.4603e-01, -6.7502e-02, -2.2944e-01, -2.8418e-01,  6.7034e-02,\n          1.6229e-01],\n        [ 2.8101e-01, -6.9967e-02, -1.6248e-01, -2.1542e-02,  1.2966e-01,\n          8.3730e-02, -2.0365e-01,  4.9493e-02,  8.2221e-02, -2.2509e-01,\n         -9.1599e-03],\n        [ 5.8835e-02,  1.5620e-01, -8.4471e-02, -1.0863e-01, -2.6562e-01,\n         -2.0918e-01, -1.8827e-01,  4.8305e-02,  2.2187e-01, -9.8067e-02,\n          1.4860e-01],\n        [ 1.8680e-01, -2.9516e-01,  2.8030e-01, -2.5329e-01,  2.9931e-01,\n         -1.4009e-01, -2.7685e-01, -1.9443e-01, -1.0957e-01,  1.5418e-02,\n         -1.7634e-01],\n        [ 4.7757e-02, -2.8418e-02,  2.4755e-01, -1.4655e-01, -1.0172e-01,\n         -1.1323e-01, -8.6760e-02,  8.3303e-02, -3.2036e-02,  1.0074e-02,\n          9.5540e-02],\n        [-3.3923e-02,  8.3451e-02,  2.6354e-02,  2.7649e-01,  2.7948e-01,\n          2.5758e-01, -5.1857e-02,  6.7780e-02, -2.1740e-01,  1.3730e-01,\n          3.0016e-01],\n        [ 2.0432e-01, -1.8471e-01,  5.5980e-02, -1.7011e-01,  1.7934e-01,\n         -1.1187e-01, -2.3862e-01,  4.7182e-03, -1.0286e-01, -2.1046e-01,\n          2.6550e-01],\n        [ 1.5538e-01,  8.9623e-02,  1.4072e-01, -1.2246e-01, -1.5305e-01,\n         -2.0910e-01, -2.5582e-01, -2.1938e-02, -1.8305e-01, -7.6265e-03,\n         -2.0317e-01],\n        [ 1.8712e-01,  8.6788e-02, -1.5149e-01, -1.8920e-01, -9.5064e-02,\n         -2.6550e-01,  1.9446e-01, -9.5523e-03, -3.8990e-02,  1.4048e-01,\n         -1.5657e-01],\n        [-1.1191e-01,  2.7792e-01, -1.3236e-01, -4.8941e-03,  1.0388e-01,\n          9.7380e-03, -6.7352e-02, -1.0517e-01,  1.9007e-01, -1.2473e-01,\n         -3.9266e-02],\n        [-7.3290e-02, -1.0426e-01, -2.3895e-01, -1.7663e-01, -9.4983e-02,\n         -2.8600e-01,  1.0174e-01, -8.1894e-02, -5.4346e-05, -8.0161e-02,\n          2.3915e-01],\n        [-1.2483e-01,  1.0813e-01,  1.7504e-01, -2.0044e-01, -1.5969e-01,\n         -6.2901e-02,  1.9403e-01,  1.3463e-01,  5.2400e-02,  2.8466e-01,\n         -6.9401e-02],\n        [ 3.5062e-02, -5.2675e-02, -2.6295e-01,  1.2419e-02, -1.3259e-01,\n         -1.0155e-01,  1.6283e-01,  2.1113e-01, -2.4850e-02, -1.8227e-01,\n         -1.3424e-01],\n        [-2.8442e-01,  1.6493e-01, -2.5474e-01, -2.5019e-01,  1.6535e-01,\n          1.0277e-01,  7.8166e-02, -1.1966e-01, -2.2072e-01,  1.1839e-01,\n          1.5674e-01],\n        [-2.8882e-01, -2.1021e-01,  2.0033e-01, -1.3862e-01, -1.4601e-01,\n         -2.0708e-01,  1.1797e-01,  3.5179e-02, -2.5090e-03, -2.4861e-01,\n          1.4470e-01],\n        [-2.3517e-01, -1.0034e-01, -5.9584e-02,  2.7551e-01, -1.6484e-02,\n         -1.1258e-01, -1.7354e-01, -1.8827e-01,  2.5125e-01, -1.8351e-01,\n         -2.6983e-01],\n        [ 1.5203e-01,  2.0302e-02, -1.8171e-01, -1.4541e-02,  2.6286e-01,\n         -8.1372e-02, -2.3584e-01, -2.4229e-01, -2.6194e-02,  1.0077e-01,\n         -2.6662e-01],\n        [ 1.8518e-01, -2.7820e-01, -1.4234e-01,  1.1806e-01, -1.2501e-01,\n          1.8723e-02, -5.9479e-02,  3.2075e-02,  8.4401e-03,  2.2670e-01,\n          2.1437e-01],\n        [-2.0528e-01,  2.3031e-02,  2.4643e-01,  1.1809e-01,  1.4833e-01,\n         -1.3490e-01,  1.8122e-01, -1.5777e-01,  1.1183e-01,  6.7236e-02,\n         -4.3736e-02],\n        [ 1.1791e-01, -1.9750e-01,  8.3867e-02, -2.7053e-03, -6.8858e-02,\n         -5.4495e-02,  2.3147e-02,  2.0298e-01,  2.0485e-01, -4.1148e-02,\n          1.0637e-01],\n        [-2.0789e-01,  1.6507e-01,  2.2904e-01,  2.8206e-01, -2.1199e-01,\n         -2.1653e-01,  8.8743e-02, -4.9242e-02, -2.7768e-01, -1.4998e-02,\n          2.1024e-01],\n        [ 1.3438e-01, -2.2892e-01,  1.3405e-01, -1.5495e-01,  1.9356e-01,\n          1.7663e-01,  7.3334e-02, -3.7913e-02,  2.2263e-01, -1.4390e-02,\n          1.0229e-02],\n        [-5.8547e-02,  2.1029e-01,  2.2491e-01,  1.4273e-01, -1.1555e-01,\n         -2.8519e-01,  2.9584e-01,  1.0250e-01, -1.5292e-01, -1.7549e-01,\n          1.6914e-01],\n        [ 1.2993e-01, -2.1760e-01,  1.8074e-01, -2.9914e-01, -2.0282e-02,\n          9.3186e-02, -1.3123e-01,  2.9674e-01,  6.5308e-02,  2.8086e-01,\n          2.2963e-02],\n        [ 1.6248e-01, -1.0683e-01, -7.7475e-02, -1.9657e-01, -5.7275e-02,\n         -1.2531e-01, -1.8193e-01,  2.7493e-01,  1.4485e-01, -3.3638e-02,\n          1.4048e-01],\n        [ 2.6934e-01,  2.7303e-01,  1.6959e-01,  1.4674e-01, -7.4985e-03,\n          1.7014e-01,  2.1503e-01, -2.2513e-01, -1.7315e-01,  2.0475e-01,\n         -1.6272e-01],\n        [ 2.5981e-02, -1.0780e-01,  2.4470e-01, -2.3988e-01,  2.6895e-01,\n         -1.5258e-01, -6.8608e-02,  5.9314e-02,  2.4812e-01, -2.8675e-01,\n         -2.1363e-01],\n        [ 3.1882e-02, -1.0986e-01,  1.5978e-01, -1.2785e-01, -2.5412e-02,\n         -4.8812e-02,  8.2593e-03, -1.8910e-01, -1.6709e-01, -8.3408e-02,\n          2.4812e-01]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	11,
                                                        "out_features":	64,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "Tanh()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=64, out_features=64, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1014,  0.0638,  0.0962, -0.1212,  0.0969, -0.0573,  0.0136, -0.0914,\n         0.0707,  0.0868, -0.1086, -0.0780,  0.0757, -0.0803, -0.0557,  0.0533,\n         0.1054, -0.0282, -0.0740, -0.0817, -0.1219,  0.1101, -0.0879,  0.0996,\n         0.0363, -0.0387,  0.0870, -0.0843, -0.0386, -0.0462,  0.0240,  0.0212,\n         0.0035, -0.1213, -0.1035,  0.0782, -0.0244, -0.0560,  0.0850, -0.0098,\n         0.0128,  0.0851, -0.0588, -0.0275,  0.0853, -0.0212, -0.0965, -0.0278,\n        -0.0865,  0.0107,  0.0550, -0.0437,  0.0517,  0.0048, -0.0591, -0.0465,\n         0.0337,  0.0949, -0.0646, -0.0072, -0.0439, -0.1024,  0.1162, -0.0309],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0771, -0.0366,  0.0571,  ...,  0.0329, -0.0995, -0.0317],\n        [-0.0420, -0.0487, -0.0518,  ..., -0.0662,  0.0779,  0.0496],\n        [-0.0415,  0.1015,  0.0797,  ...,  0.0078, -0.0930, -0.0847],\n        ...,\n        [-0.0776,  0.1033, -0.0164,  ..., -0.1080,  0.1002,  0.1107],\n        [-0.0037,  0.0527,  0.0155,  ..., -0.1241, -0.1231, -0.0273],\n        [ 0.1048,  0.0556,  0.0068,  ..., -0.1140, -0.0744,  0.0576]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	64,
                                                        "out_features":	64,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "Tanh()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=64, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0923], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1150,  0.0612, -0.0785,  0.0777, -0.1015,  0.1243, -0.0263, -0.1071,\n         -0.0340, -0.0087,  0.0387, -0.0831, -0.0734,  0.0338, -0.0692, -0.1009,\n         -0.1150,  0.0299,  0.0722,  0.0781, -0.0147, -0.1219, -0.0819, -0.0525,\n         -0.0750, -0.1184, -0.0531,  0.0106, -0.0085, -0.0348, -0.1106,  0.0667,\n         -0.0584, -0.1129, -0.0576,  0.0141,  0.0396, -0.0607, -0.0424,  0.0653,\n          0.1141,  0.0786,  0.0006,  0.0281,  0.1072, -0.0977, -0.0034, -0.0149,\n         -0.1211,  0.0822, -0.1107,  0.0453, -0.0535, -0.0072, -0.0597,  0.0881,\n         -0.0418, -0.0259, -0.1189, -0.0043, -0.0756,  0.0843, -0.0719, -0.0714]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	64,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "act_dim":	[
                3
            ],
            "backtrack_alpha":	0.5,
            "backtrack_coeff":	1.0,
            "backtrack_iter":	10,
            "buf":	{
                "<spinup.alogos.trpo.trpo.TRPOBuffer object at 0x7fc30810cb50>":	{
                    "act_buf":	"[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]\n ...\n [0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "device":	"cuda:0",
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "max_size":	3000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "delta":	0.01,
            "device":	"cuda:0",
            "env":	{
                "<TimeLimit<HopperEnv<Hopper-v2>>>":	{
                    "_action_space":	null,
                    "_elapsed_steps":	null,
                    "_max_episode_steps":	1000,
                    "_metadata":	null,
                    "_observation_space":	null,
                    "_reward_range":	null,
                    "env":	{
                        "<HopperEnv<Hopper-v2>>":	{
                            "_ezpickle_args":	[],
                            "_ezpickle_kwargs":	{},
                            "_viewers":	{},
                            "action_space":	{
                                "Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)":	{
                                    "_np_random":	"RandomState(MT19937)",
                                    "_shape":	[
                                        3
                                    ],
                                    "bounded_above":	"[ True  True  True]",
                                    "bounded_below":	"[ True  True  True]",
                                    "dtype":	"float32",
                                    "high":	"[1. 1. 1.]",
                                    "low":	"[-1. -1. -1.]"
                                }
                            },
                            "data":	"<mujoco_py.cymj.PyMjData object at 0x5564827a4210>",
                            "frame_skip":	4,
                            "init_qpos":	"[0.   1.25 0.   0.   0.   0.  ]",
                            "init_qvel":	"[0. 0. 0. 0. 0. 0.]",
                            "metadata":	{
                                "render.modes":	[
                                    "human",
                                    "rgb_array",
                                    "depth_array"
                                ],
                                "video.frames_per_second":	125
                            },
                            "model":	"<mujoco_py.cymj.PyMjModel object at 0x556482a12ae0>",
                            "np_random":	"RandomState(MT19937)",
                            "observation_space":	{
                                "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)":	{
                                    "_np_random":	null,
                                    "_shape":	[
                                        11
                                    ],
                                    "bounded_above":	"[False False False False False False False False False False False]",
                                    "bounded_below":	"[False False False False False False False False False False False]",
                                    "dtype":	"float64",
                                    "high":	"[inf inf inf inf inf inf inf inf inf inf inf]",
                                    "low":	"[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]"
                                }
                            },
                            "sim":	"<mujoco_py.cymj.MjSim object at 0x7fc30821e710>",
                            "spec":	{
                                "EnvSpec(Hopper-v2)":	{
                                    "_env_name":	"Hopper",
                                    "_kwargs":	{},
                                    "entry_point":	"gym.envs.mujoco:HopperEnv",
                                    "id":	"Hopper-v2",
                                    "max_episode_steps":	1000,
                                    "nondeterministic":	false,
                                    "order_enforce":	true,
                                    "reward_threshold":	3800.0
                                }
                            },
                            "viewer":	null
                        }
                    }
                }
            },
            "logger":	{
                "<spinup.utils.logx.EpochLogger object at 0x7fc30826b810>":	{
                    "epoch_dict":	{},
                    "exp_name":	"trpo_hopper",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/zp/deeplearning/spinningup_project/data/trpo_hopper/trpo_hopper_s0",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/zp/deeplearning/spinningup_project/data/trpo_hopper/trpo_hopper_s0/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "mode":	"TRPO",
            "obs_dim":	[
                11
            ],
            "old_pi":	{
                "MLPGaussianActor(\n  (mu_net): Sequential(\n    (0): Linear(in_features=11, out_features=64, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=64, out_features=3, bias=True)\n    (5): Identity()\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "mu_net":	{
                            "Sequential(\n  (0): Linear(in_features=11, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=3, bias=True)\n  (5): Identity()\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=11, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1690, -0.0876, -0.0053,  0.2295, -0.2611, -0.0208, -0.2205,  0.0847,\n         0.1604, -0.1062,  0.0436,  0.1789,  0.1569,  0.1047, -0.0343, -0.0305,\n        -0.0719,  0.0106, -0.2190, -0.0034,  0.1400,  0.2196,  0.0650, -0.2894,\n        -0.1923,  0.0232, -0.0364,  0.0524,  0.0027, -0.0596,  0.1058, -0.2237,\n        -0.2602,  0.1594,  0.1143, -0.1984, -0.0529,  0.1786, -0.2202, -0.2578,\n         0.2499,  0.2735,  0.1173,  0.2816, -0.2720,  0.2330,  0.1316, -0.1268,\n         0.1078,  0.2677,  0.0383, -0.2816,  0.0156, -0.2850,  0.0041, -0.2866,\n         0.1285, -0.2212, -0.1849, -0.1152, -0.0104,  0.1114, -0.1414, -0.0369],\n       device='cuda:0', requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 5.4141e-02,  1.6113e-01, -1.4225e-01,  1.6002e-01, -1.5729e-01,\n          8.6254e-02,  1.0037e-01, -2.5793e-01, -8.7578e-02,  1.9048e-01,\n          2.7444e-01],\n        [-2.4710e-01, -8.6364e-02,  2.0492e-01, -1.2012e-01,  1.0582e-01,\n         -1.9747e-02, -1.4898e-01, -2.3155e-01,  2.7211e-01, -2.9919e-01,\n         -9.5591e-02],\n        [-2.6901e-01, -8.9960e-02, -7.6308e-03, -2.1350e-01, -8.2136e-03,\n         -8.9956e-02, -8.8068e-02,  1.8671e-01,  6.9136e-02, -2.7019e-01,\n         -2.1307e-01],\n        [ 1.2710e-01, -2.4466e-01, -1.0406e-01, -2.8413e-01, -2.0324e-01,\n         -3.0028e-01, -1.0440e-01, -5.0968e-02,  1.0823e-01, -2.7649e-01,\n          2.8740e-02],\n        [ 2.0589e-01,  9.4873e-02, -1.1239e-01, -9.3379e-02,  2.4048e-01,\n         -1.3009e-01, -2.0245e-01,  3.9185e-02, -2.2132e-01, -8.3849e-02,\n         -3.9292e-02],\n        [ 5.0953e-02,  2.4421e-01, -1.1770e-03, -2.6835e-01, -1.0936e-01,\n         -6.2004e-02,  1.8599e-01, -1.0171e-01,  1.9423e-01, -2.5978e-02,\n         -2.1285e-02],\n        [-1.0625e-01, -1.8009e-02,  1.9741e-01, -2.4266e-01, -1.4678e-01,\n          4.3802e-03, -2.3465e-01, -1.0864e-01, -2.5484e-01, -5.0709e-02,\n         -9.5393e-02],\n        [ 3.5927e-02, -2.9739e-01,  1.6154e-01,  1.1888e-01, -9.2234e-02,\n         -8.8440e-02, -1.5919e-01, -2.3108e-01,  7.9378e-02, -2.7672e-01,\n          3.1407e-02],\n        [ 6.9912e-02,  2.3987e-01, -2.2929e-01, -4.3322e-03, -1.7616e-01,\n          1.2829e-01, -2.5215e-01,  2.1766e-01, -2.1364e-01,  2.8563e-01,\n         -2.7680e-01],\n        [-2.2288e-01, -2.4635e-01, -1.0269e-01,  8.3526e-02,  1.2382e-01,\n         -1.2256e-01, -1.6784e-01, -1.8750e-01,  1.8200e-01, -1.1446e-01,\n         -2.0819e-01],\n        [ 1.4686e-01,  2.7703e-01, -1.7001e-01, -2.5330e-01, -1.1521e-01,\n          1.9152e-01, -1.2436e-01,  3.0659e-02,  9.1523e-02, -9.5426e-02,\n          1.5368e-01],\n        [-3.0057e-01, -1.4344e-01, -1.3619e-01,  9.5425e-02, -1.7744e-01,\n         -2.7663e-01, -1.6362e-01,  1.5686e-01, -2.0212e-01, -2.0796e-02,\n         -2.1171e-01],\n        [ 2.7986e-01, -1.5343e-01,  2.6659e-01,  2.7906e-01,  1.0195e-01,\n         -8.3553e-02,  2.2882e-02, -8.2358e-02,  2.7981e-01,  2.7597e-01,\n         -2.9730e-01],\n        [-1.9712e-01, -2.0831e-01,  3.1530e-02, -2.6606e-01,  8.5405e-02,\n          2.6540e-01, -2.8941e-01, -9.0200e-02,  1.1604e-01,  1.5562e-01,\n         -2.7850e-02],\n        [ 9.2527e-02,  1.1769e-01, -3.2822e-02,  7.6254e-03,  2.4946e-01,\n         -2.2294e-01, -3.3306e-02,  2.1548e-01,  1.5662e-01,  2.6939e-01,\n         -2.8464e-01],\n        [ 2.3888e-03, -2.6359e-01,  2.1486e-01, -4.9504e-02,  1.7277e-01,\n          2.1842e-01,  1.3502e-01, -1.6518e-01, -2.7339e-01,  9.5725e-03,\n          1.7320e-01],\n        [-1.7007e-01, -1.6209e-01,  9.4105e-02, -2.8023e-01,  5.5122e-04,\n         -4.3738e-02,  1.5160e-01, -2.3739e-01, -1.4602e-01,  2.5643e-01,\n          1.9590e-01],\n        [-2.8940e-01, -3.8497e-02,  6.7296e-02, -2.3141e-01, -1.9524e-01,\n         -9.6383e-03,  2.5529e-01,  5.7778e-02,  1.1115e-01,  2.3537e-01,\n         -8.0454e-02],\n        [-3.5214e-02,  4.1133e-02, -2.2591e-01,  2.5287e-01,  2.7737e-01,\n          1.6746e-01,  2.7813e-02,  1.9168e-01,  2.8584e-01,  1.6411e-01,\n         -2.5609e-03],\n        [ 8.4833e-02,  8.0571e-02,  1.8235e-01, -1.1174e-01,  8.9676e-02,\n         -2.8040e-01,  1.2340e-01, -6.6818e-02, -1.4559e-01,  1.0762e-01,\n         -3.2908e-03],\n        [-2.5025e-01,  2.5416e-01, -4.3708e-02, -3.3329e-02, -1.2222e-01,\n          1.4890e-01, -2.9900e-01, -4.3950e-03, -8.6760e-02, -2.1829e-01,\n          2.0139e-01],\n        [-1.5008e-01, -1.7350e-01, -6.7908e-02,  2.3246e-01, -2.5102e-01,\n         -1.7367e-01,  8.9359e-02, -1.9772e-01, -2.2382e-01,  1.0144e-01,\n          2.0532e-01],\n        [-1.2658e-01,  2.4014e-01, -2.7797e-03,  2.4348e-01,  2.2694e-01,\n          2.3494e-01,  2.4786e-01,  8.5139e-02, -2.6877e-01, -8.5165e-02,\n         -1.6442e-01],\n        [-8.6180e-02, -6.6545e-02, -1.0482e-01, -1.7499e-02,  1.1549e-01,\n         -1.1902e-01,  5.3084e-02, -2.4499e-01,  1.2521e-01, -4.0170e-02,\n          2.6467e-01],\n        [-2.1661e-01, -2.6421e-01, -2.0462e-03,  3.7357e-02, -6.5827e-02,\n         -1.0044e-01,  2.8995e-01,  1.6715e-01,  2.6762e-01,  1.0339e-01,\n         -1.7027e-01],\n        [ 2.4323e-01, -1.6892e-01,  2.4539e-02, -2.6898e-01,  5.6358e-02,\n          3.3409e-02,  1.6957e-01,  2.2962e-01, -1.9035e-01, -2.1432e-01,\n          2.8797e-01],\n        [-2.7702e-01,  1.8178e-01,  2.3547e-01, -2.4546e-01,  1.5486e-01,\n          7.7084e-02, -1.2873e-01,  1.5269e-01, -1.0246e-01,  2.0878e-02,\n          2.1146e-01],\n        [ 5.9724e-03,  2.4736e-01,  1.2225e-01,  2.7311e-01, -5.0316e-02,\n         -1.9815e-01, -1.2967e-01,  2.2139e-01, -2.7980e-01, -2.5843e-01,\n          2.9952e-01],\n        [ 6.2903e-02,  8.0521e-02,  1.3570e-01, -2.2530e-02,  1.2476e-01,\n         -1.2682e-01,  2.6329e-02,  3.3994e-03, -2.8103e-02, -1.6068e-01,\n         -7.5600e-02],\n        [ 1.3387e-01, -2.0812e-01,  1.8799e-01, -2.6415e-01,  4.3292e-02,\n          1.9419e-01,  2.9427e-01,  4.9464e-02,  8.4303e-02, -1.2142e-01,\n          2.2382e-01],\n        [-1.7442e-01, -2.7036e-01,  2.5649e-01,  7.7196e-02, -3.2196e-02,\n         -2.6069e-01,  1.9362e-01,  1.3820e-01, -1.9296e-01,  2.7893e-01,\n         -8.3676e-02],\n        [ 2.4162e-01, -4.0851e-02,  1.8024e-02,  1.5459e-01,  8.6581e-02,\n         -8.2270e-02, -1.7551e-02,  2.2081e-01,  3.8897e-02, -8.4139e-02,\n          1.0519e-02],\n        [-3.5243e-03, -1.1274e-01,  1.1233e-01, -1.8401e-01,  1.6560e-01,\n          9.0717e-02,  1.3309e-01,  2.6576e-02, -8.6575e-02, -2.0615e-01,\n          2.1704e-01],\n        [-3.9277e-03, -8.0862e-03,  1.1379e-01, -1.3952e-01, -7.2595e-02,\n         -6.3419e-02, -2.1082e-01,  2.3405e-01,  2.8105e-01, -2.1513e-01,\n         -2.5119e-01],\n        [ 1.6387e-01, -2.0347e-01,  2.7932e-01,  2.6374e-01, -2.4643e-01,\n         -1.2420e-01, -2.0155e-01, -1.2941e-01,  2.7290e-01, -1.1614e-01,\n         -2.2722e-01],\n        [ 1.3858e-01,  2.9085e-04, -1.1467e-01,  2.3641e-01, -1.4426e-01,\n         -2.9309e-01, -6.0260e-02,  2.9813e-02, -2.5828e-01,  4.5000e-02,\n          1.0108e-01],\n        [-2.3825e-01, -5.7254e-02, -2.6274e-01,  2.7991e-01, -2.9205e-01,\n         -1.3471e-01,  2.4496e-01, -6.4255e-02, -2.7666e-01, -1.3966e-01,\n          1.1213e-01],\n        [-2.3667e-02,  1.4058e-01,  1.9963e-01,  1.1239e-01, -6.8975e-02,\n          2.5886e-01,  2.5588e-01,  2.1911e-01,  1.0708e-01,  4.9705e-02,\n         -1.8893e-01],\n        [ 2.1477e-01,  2.4439e-01, -9.4025e-02,  1.7023e-01,  1.4128e-02,\n          1.7355e-01,  5.2116e-02, -9.8065e-03, -1.2269e-01, -1.9443e-02,\n          8.3110e-02],\n        [-2.2881e-01,  8.8861e-02,  2.2460e-01, -1.1185e-01, -1.3728e-01,\n         -2.9171e-01, -5.2695e-02, -1.1726e-01,  1.9863e-01,  8.2572e-02,\n          2.4830e-01],\n        [-2.0468e-01, -1.8765e-01, -2.7354e-01,  2.4135e-01,  2.2398e-01,\n         -2.3910e-01, -1.4518e-01, -5.5107e-02, -2.4380e-01,  1.6696e-01,\n          1.0106e-01],\n        [-1.6403e-01,  1.7899e-01, -1.6452e-01,  2.5203e-01, -6.9909e-02,\n          1.5185e-01,  1.1032e-01, -2.5226e-01,  1.2596e-01,  2.6620e-01,\n         -2.6763e-01],\n        [ 5.1747e-02,  2.3534e-01, -6.3290e-02,  8.5215e-02, -7.2321e-02,\n         -1.1997e-01, -7.2169e-03, -2.1879e-01, -4.1903e-02, -1.1385e-01,\n         -2.9068e-01],\n        [-1.6837e-01,  1.2374e-01, -2.3703e-01,  2.8351e-01,  5.8341e-02,\n         -9.6646e-03, -6.7235e-02, -1.0607e-01, -7.1488e-02, -4.3852e-02,\n         -8.0702e-02],\n        [ 1.1262e-01,  7.4767e-02,  1.0383e-01, -2.4881e-01, -1.0026e-01,\n          2.5234e-01,  5.4249e-02,  7.0429e-02,  2.4163e-01, -2.0650e-01,\n         -9.2417e-02],\n        [-1.7115e-01,  4.4800e-02, -2.9604e-01,  2.6307e-01,  1.2344e-01,\n          2.0139e-01, -1.1598e-01, -1.3348e-01,  2.8452e-01, -1.4037e-01,\n          2.9104e-01],\n        [-1.6686e-01, -2.5411e-01,  1.2424e-01, -2.3874e-02,  2.2768e-01,\n          2.4120e-01, -2.8235e-01,  1.2549e-01, -8.4508e-02,  8.7327e-02,\n          5.5658e-02],\n        [ 1.4882e-01, -5.4782e-02,  6.4714e-02, -2.9247e-01, -1.1255e-01,\n          2.0523e-04, -5.6595e-02,  2.8466e-01,  1.1190e-01, -4.5624e-03,\n          3.0036e-02],\n        [-1.8343e-01,  8.3076e-02, -2.9103e-02, -2.4217e-01,  2.9580e-01,\n         -7.8742e-02, -2.3733e-01,  2.1319e-01,  2.8591e-01, -8.7737e-02,\n          2.7009e-01],\n        [-2.6284e-01,  2.4206e-01, -8.0135e-02,  1.0080e-01,  9.8725e-04,\n          5.7854e-02,  1.6848e-01, -2.0279e-01,  1.4428e-01,  7.0456e-02,\n         -5.8496e-02],\n        [ 2.5925e-02,  2.1938e-01,  5.8988e-02, -4.8142e-03,  1.0599e-01,\n          2.0843e-02, -1.0647e-01, -6.2003e-02,  1.9362e-02,  1.2848e-01,\n         -2.2099e-01],\n        [-1.4639e-01,  9.7031e-02,  1.1358e-02,  1.8021e-01, -1.4904e-01,\n         -8.6164e-02, -2.6472e-01, -1.6025e-01, -1.0553e-01,  8.4820e-02,\n          1.9494e-01],\n        [ 2.7516e-01,  6.7245e-02,  2.1341e-01, -1.9033e-01,  2.1212e-01,\n          5.7614e-02, -6.0208e-02, -6.9623e-02,  1.6813e-03, -3.0039e-01,\n         -5.6171e-02],\n        [ 1.7953e-01, -3.1666e-05, -2.7640e-01,  9.9144e-02,  2.3047e-01,\n          7.5992e-02,  9.0470e-02,  8.1115e-02,  2.8263e-02,  7.6257e-02,\n          1.9498e-01],\n        [ 7.8648e-02,  1.5596e-02, -2.8873e-01,  8.2213e-03, -2.6894e-01,\n         -5.9505e-02,  1.6013e-01,  2.9564e-01,  8.2151e-02, -8.7731e-02,\n          1.1874e-01],\n        [ 1.6070e-01,  2.8351e-01, -3.8723e-02, -2.0745e-01,  2.3738e-01,\n          1.7762e-01, -2.7196e-01,  2.7299e-01,  1.6690e-01,  1.6051e-02,\n          9.1469e-02],\n        [ 1.6977e-01, -9.5645e-02,  8.4201e-02,  8.1221e-02, -1.1091e-01,\n         -3.0030e-01, -1.3949e-01, -1.9598e-01, -5.4677e-02, -7.3659e-02,\n          2.8986e-01],\n        [ 1.5187e-02, -1.4250e-01,  2.0053e-01,  1.5450e-01,  1.3975e-01,\n          5.6282e-03, -1.4537e-01,  1.7954e-01,  2.8417e-01,  7.9677e-03,\n          4.7305e-03],\n        [-1.6650e-01,  4.9634e-02,  2.4070e-01, -1.7955e-01, -2.2255e-01,\n          1.9340e-01,  1.0418e-01,  9.0339e-02,  1.7757e-01, -2.5615e-02,\n          1.1988e-02],\n        [-2.0033e-01, -1.1982e-01,  6.9072e-02, -1.1493e-01,  1.9692e-01,\n         -1.9797e-03,  1.7827e-01, -1.0631e-01, -1.1032e-01, -2.9657e-01,\n          4.0516e-02],\n        [ 2.0428e-01, -1.8340e-01, -1.3979e-01,  5.4584e-02, -2.5143e-01,\n          3.3438e-02,  7.9660e-02, -2.0481e-01,  1.7440e-01,  1.8189e-01,\n         -1.6667e-01],\n        [ 1.8847e-01,  1.8160e-01,  2.4184e-01,  2.1652e-01,  1.0820e-01,\n          1.8635e-01,  1.9865e-01, -2.3529e-02, -1.3480e-01, -2.8353e-01,\n          1.9890e-01],\n        [ 1.5306e-01,  2.0942e-01, -2.7889e-01, -2.2951e-01, -2.7532e-02,\n          2.1926e-01, -1.7004e-01,  1.9184e-02,  2.8936e-01, -5.8070e-02,\n          1.2145e-01],\n        [ 1.8020e-01, -1.6466e-01, -1.1366e-02,  9.3561e-02, -1.4507e-01,\n          2.4879e-01,  1.4270e-01, -2.9740e-01,  1.6651e-01, -2.5830e-01,\n          6.6826e-02]], device='cuda:0', requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	11,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "Tanh()":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0842,  0.0403,  0.0135, -0.1200, -0.1230, -0.0367, -0.0280, -0.1178,\n        -0.0710, -0.0744,  0.1038,  0.0546, -0.0894,  0.0236, -0.0188, -0.0949,\n        -0.0080,  0.0714, -0.1044,  0.0981,  0.0690, -0.0026, -0.0752, -0.0390,\n        -0.0962, -0.0048, -0.0562, -0.0944, -0.0233,  0.1069, -0.0793, -0.0886,\n        -0.0828, -0.0353,  0.0551,  0.0271,  0.0549,  0.0160, -0.0313, -0.1025,\n        -0.0495, -0.1197, -0.0032, -0.0227, -0.0083,  0.0762, -0.0922,  0.0129,\n        -0.0826, -0.0039,  0.0927, -0.1164, -0.0045, -0.0501,  0.0540,  0.0853,\n         0.0555, -0.0699,  0.0249, -0.1075,  0.1002, -0.0629,  0.1222,  0.0180],\n       device='cuda:0', requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0144,  0.0939, -0.0602,  ..., -0.0545, -0.0357,  0.1187],\n        [-0.1050,  0.0103,  0.1082,  ..., -0.0587, -0.0432,  0.1028],\n        [ 0.0670,  0.0289, -0.0550,  ..., -0.0476, -0.1136, -0.0636],\n        ...,\n        [ 0.0279, -0.0612,  0.0543,  ..., -0.0252,  0.0169,  0.0493],\n        [-0.0008, -0.1146,  0.0277,  ..., -0.0236,  0.1037, -0.1233],\n        [-0.0476, -0.0840,  0.1127,  ...,  0.0464, -0.0758, -0.0866]],\n       device='cuda:0', requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "Tanh()":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=3, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1167, -0.0273, -0.0312], device='cuda:0', requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0329, -0.0193, -0.0339,  0.0985,  0.0028, -0.0138,  0.0141, -0.0470,\n          0.1229,  0.0497, -0.0336,  0.0041, -0.0495,  0.0215,  0.0083,  0.0560,\n         -0.0971,  0.1086,  0.0526,  0.0218,  0.0592, -0.0775,  0.0760,  0.1178,\n          0.0949,  0.0970, -0.0825,  0.0496,  0.0069, -0.0219, -0.0261,  0.0833,\n          0.1118,  0.0879, -0.0376, -0.0088, -0.0571,  0.0245, -0.0208, -0.1013,\n          0.0289,  0.0323, -0.1022,  0.0358,  0.1093,  0.0931,  0.1147,  0.0525,\n         -0.0089,  0.0345,  0.0023,  0.0593, -0.0326, -0.1155,  0.0633, -0.0411,\n         -0.0737, -0.0752,  0.0509,  0.0061,  0.0183, -0.0428,  0.0221,  0.0263],\n        [ 0.0886,  0.1186, -0.0798, -0.0238, -0.0871,  0.1206, -0.0068,  0.0568,\n          0.1234, -0.0794,  0.0787, -0.1154, -0.0997,  0.0985,  0.0575, -0.0715,\n          0.1150, -0.1099, -0.0639,  0.0602,  0.0816, -0.1099, -0.0275, -0.0670,\n          0.0190, -0.0399,  0.0963, -0.1238, -0.0491, -0.0859,  0.0743,  0.0712,\n         -0.0679,  0.0991, -0.0609, -0.0114,  0.0281,  0.1057,  0.1112,  0.0966,\n         -0.1192,  0.1196,  0.0323, -0.0360, -0.0581, -0.0988, -0.0910,  0.0440,\n          0.1036,  0.0132, -0.1122,  0.0638,  0.0357, -0.0095, -0.0654,  0.1076,\n         -0.1126,  0.0986,  0.0497,  0.0542, -0.0476,  0.1238,  0.0539,  0.0028],\n        [ 0.0177, -0.0503, -0.0421,  0.0242, -0.0845,  0.0727, -0.0149, -0.0361,\n          0.0105, -0.0832,  0.1165,  0.0626, -0.0283,  0.1004,  0.0009,  0.0962,\n          0.1222, -0.0730, -0.0237,  0.0777,  0.0670,  0.1100,  0.0195, -0.0449,\n          0.0678,  0.0674,  0.1166, -0.0295, -0.1026, -0.0944,  0.0767,  0.0945,\n          0.0660, -0.0494, -0.0160,  0.1197, -0.0997, -0.0101, -0.0635,  0.0529,\n         -0.0140,  0.0029, -0.0541, -0.0549, -0.0230, -0.0520, -0.0009, -0.0150,\n         -0.0940,  0.1232, -0.0532,  0.1137, -0.0969,  0.0103,  0.0596,  0.0797,\n          0.1210, -0.0597, -0.0386, -0.0645, -0.0759, -0.0548, -0.0911, -0.0469]],\n       device='cuda:0', requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	3,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "Identity()":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{
                        "log_std":	"Parameter containing:\ntensor([-0.5000, -0.5000, -0.5000], device='cuda:0', requires_grad=True)"
                    },
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "steps_per_epoch":	3000,
            "train_v_iters":	80,
            "vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "Parameter containing:\ntensor([[-2.2332e-01, -1.8876e-01, -2.4180e-01, -2.6697e-02, -1.2155e-02,\n         -7.5172e-03,  1.9660e-01, -7.1801e-02, -7.1773e-02,  1.1780e-01,\n         -2.8576e-01],\n        [ 1.6933e-01, -1.7383e-01, -8.7280e-02,  1.2505e-01, -1.1139e-01,\n         -2.2754e-01,  1.8747e-01,  1.0720e-01,  1.6512e-01,  3.4975e-02,\n         -1.3721e-01],\n        [-1.5691e-01,  7.8367e-02,  2.9399e-01, -8.8598e-02,  1.9625e-01,\n         -2.4945e-01, -9.1432e-02,  2.4665e-01,  1.4598e-01,  1.3584e-01,\n         -2.8832e-01],\n        [-2.8275e-01, -1.6853e-02, -5.2873e-02,  2.8608e-01, -2.8011e-01,\n          9.8234e-02,  2.6776e-01,  2.3872e-01,  8.8866e-02,  2.4411e-01,\n          9.3631e-03],\n        [ 1.6211e-01,  1.6519e-01, -2.6252e-01, -3.3106e-02, -2.0619e-01,\n          3.0132e-01,  1.0526e-01,  1.1617e-01,  2.9970e-01, -1.1349e-01,\n         -2.3086e-01],\n        [ 9.4828e-02,  2.0153e-01,  4.4588e-03,  2.8294e-01,  2.7311e-01,\n          2.0378e-01,  5.8843e-03, -5.7444e-02, -1.0210e-01,  7.7234e-02,\n         -3.6243e-02],\n        [ 2.4744e-02, -1.6279e-01, -1.0642e-01, -1.9001e-02,  2.4471e-01,\n         -2.6831e-01,  3.8283e-02,  1.2188e-01,  1.1136e-01,  7.5069e-03,\n         -1.2190e-01],\n        [ 6.5991e-02, -7.8874e-02,  2.7760e-01,  1.1161e-01, -1.9169e-01,\n         -2.2104e-01,  6.6596e-02,  2.2514e-01, -2.3892e-01, -2.1263e-01,\n         -2.4192e-01],\n        [ 2.3654e-01, -4.9175e-02,  3.0118e-01,  1.6870e-01,  2.9562e-02,\n          1.3876e-01,  9.4508e-03,  2.4377e-02, -1.6575e-01,  1.5516e-01,\n         -1.7504e-01],\n        [ 2.5302e-02,  8.0326e-02, -1.9579e-01, -4.7019e-02,  1.8448e-01,\n          2.7822e-01,  1.8006e-01,  2.8674e-01, -2.8827e-02,  1.2987e-01,\n          1.5987e-01],\n        [ 4.7987e-02, -1.0797e-01,  1.7200e-01, -1.5645e-02, -2.3627e-01,\n          2.5771e-01, -1.5178e-01,  1.3774e-02, -1.0362e-01,  1.8805e-01,\n          1.9875e-01],\n        [-2.2174e-01,  5.3257e-02, -2.2280e-01,  3.1523e-02,  2.4147e-02,\n         -6.5517e-02, -1.6631e-01,  1.6378e-01, -2.2048e-01, -1.2771e-01,\n         -2.4421e-01],\n        [-1.5612e-01,  1.7257e-01,  1.0700e-01, -5.5708e-02, -3.7174e-02,\n         -3.7268e-02, -2.6598e-01,  2.6440e-01, -2.0065e-01,  6.8857e-02,\n         -6.9375e-02],\n        [-1.3627e-01, -2.7891e-01,  1.4635e-01,  1.6489e-01,  5.5326e-02,\n         -2.9360e-01,  9.6539e-02,  2.2203e-01,  1.3144e-01,  1.4619e-01,\n         -2.2400e-01],\n        [ 1.8121e-01,  2.9743e-01,  2.4596e-01,  2.5851e-01, -2.2179e-01,\n          4.0635e-02,  4.3811e-02, -1.7131e-02,  2.6481e-02, -4.0332e-02,\n         -2.2357e-02],\n        [ 1.1569e-01, -8.2271e-02, -2.1622e-01, -2.1500e-01, -2.4443e-01,\n          2.2459e-01, -2.5660e-01, -1.6396e-01, -6.4289e-03, -2.5637e-01,\n         -2.6043e-01],\n        [-1.9617e-01, -1.4667e-01,  2.8630e-01, -2.4367e-01, -2.0818e-01,\n         -5.2244e-02,  6.2259e-02,  2.6246e-01, -2.9216e-01, -1.3707e-01,\n          2.6917e-01],\n        [ 2.8386e-01, -1.0355e-01,  2.0958e-01, -2.4785e-01,  2.5480e-01,\n          1.4799e-01,  8.8423e-02, -2.5573e-01, -6.7524e-02, -2.1181e-01,\n          1.1534e-01],\n        [-2.7472e-02,  1.7643e-01, -6.0306e-02, -1.5375e-01, -3.3470e-02,\n         -6.8667e-02,  1.7701e-01,  9.6853e-02,  1.1269e-01,  1.3280e-01,\n          1.0990e-02],\n        [ 1.3153e-01,  2.6489e-01, -2.9380e-01,  1.8507e-01, -2.9935e-01,\n          1.7030e-01, -1.0731e-01,  2.9156e-02,  8.1263e-02, -1.7535e-01,\n          2.2232e-01],\n        [-8.1791e-02,  2.0256e-01, -6.1787e-02,  5.7007e-02,  6.2361e-02,\n         -2.0385e-01, -6.2321e-02, -2.4548e-01, -7.6373e-02, -2.3178e-01,\n          7.0159e-02],\n        [ 2.9395e-01,  1.6673e-01,  9.0589e-02,  7.4824e-02, -2.1004e-01,\n          2.3820e-01, -7.2674e-03, -8.3594e-02, -8.9571e-02,  1.4870e-02,\n          1.6138e-01],\n        [ 1.7426e-01, -2.8507e-01, -2.8515e-01,  2.6013e-02, -2.9001e-01,\n         -2.4925e-01, -1.7822e-01,  2.5567e-02,  5.6741e-02, -1.8318e-01,\n          2.8332e-01],\n        [-2.2436e-01, -4.0912e-02,  1.3938e-01,  1.2189e-01, -1.2447e-02,\n          1.8956e-01, -2.4845e-01, -2.1629e-01, -8.5975e-02,  2.5618e-01,\n          2.9049e-02],\n        [-2.1594e-01, -9.3293e-02, -2.3585e-01, -1.5172e-01,  2.8384e-01,\n         -1.2057e-01, -2.2032e-01,  2.8281e-01,  2.7011e-02,  9.3349e-02,\n         -7.7941e-02],\n        [-2.2723e-01,  2.0853e-01,  1.9083e-01, -2.2617e-01, -1.2373e-01,\n          2.4481e-01,  2.1486e-01,  2.1186e-01, -1.0406e-01, -2.5705e-01,\n          1.2513e-01],\n        [-1.3755e-01, -1.7560e-01,  1.2912e-01, -3.9356e-02,  1.6052e-01,\n          8.3033e-02, -1.7681e-01,  2.1405e-01, -2.2999e-01,  2.3857e-01,\n          1.9917e-01],\n        [-8.4097e-03, -7.3522e-02,  5.1083e-02, -8.6272e-02, -2.2764e-01,\n          6.5926e-02, -7.8723e-02,  1.5488e-01,  1.9717e-01,  1.7686e-01,\n         -4.1753e-03],\n        [-2.3004e-01,  2.3007e-01, -2.9837e-02, -8.4652e-02,  1.4901e-01,\n         -4.8512e-02,  5.1220e-02, -1.3524e-01,  4.8351e-02,  2.0185e-01,\n          2.3598e-01],\n        [ 1.3170e-01,  2.2044e-01, -2.4158e-01,  8.2110e-02,  2.2046e-02,\n         -7.3245e-02, -2.1845e-01,  1.8788e-01, -2.1005e-01,  2.4018e-01,\n          2.4775e-02],\n        [-2.1944e-01, -2.5796e-01, -2.3534e-01, -3.5402e-03, -7.0543e-02,\n         -1.7837e-01, -3.2779e-02, -1.0862e-01,  1.2894e-01, -1.3143e-01,\n          6.8769e-02],\n        [ 1.0419e-01,  7.8907e-02, -2.1341e-02, -1.1150e-01,  4.2720e-03,\n          1.2888e-01,  1.9800e-01,  2.7045e-01,  1.4943e-01,  5.3681e-02,\n         -8.0321e-02],\n        [-2.3052e-01,  1.4315e-01, -1.0714e-01, -1.4889e-01,  5.7996e-02,\n         -2.6970e-01, -2.9965e-01,  4.2158e-02,  1.9203e-01,  2.9917e-03,\n         -3.6427e-02],\n        [ 9.0656e-02, -4.7307e-02, -1.2856e-01,  1.0290e-01, -3.0344e-02,\n          2.0764e-01, -2.3760e-01,  8.6956e-02,  4.2646e-02, -3.0134e-01,\n         -3.7905e-02],\n        [-1.7309e-01,  1.7487e-01, -1.4082e-01,  2.7456e-02, -1.8819e-02,\n         -1.2935e-01, -2.6363e-02,  2.7592e-01,  1.5993e-01,  2.8836e-01,\n          2.1778e-01],\n        [-1.4979e-01,  5.5819e-02,  1.0051e-01,  2.4226e-01,  6.7796e-02,\n         -1.7625e-01,  1.1218e-01, -1.9223e-01, -2.2355e-01,  2.7607e-01,\n         -1.0480e-01],\n        [-1.4924e-01,  1.0560e-01,  7.0235e-02,  1.9986e-01, -1.8440e-01,\n         -1.4603e-01, -6.7502e-02, -2.2944e-01, -2.8418e-01,  6.7034e-02,\n          1.6229e-01],\n        [ 2.8101e-01, -6.9967e-02, -1.6248e-01, -2.1542e-02,  1.2966e-01,\n          8.3730e-02, -2.0365e-01,  4.9493e-02,  8.2221e-02, -2.2509e-01,\n         -9.1599e-03],\n        [ 5.8835e-02,  1.5620e-01, -8.4471e-02, -1.0863e-01, -2.6562e-01,\n         -2.0918e-01, -1.8827e-01,  4.8305e-02,  2.2187e-01, -9.8067e-02,\n          1.4860e-01],\n        [ 1.8680e-01, -2.9516e-01,  2.8030e-01, -2.5329e-01,  2.9931e-01,\n         -1.4009e-01, -2.7685e-01, -1.9443e-01, -1.0957e-01,  1.5418e-02,\n         -1.7634e-01],\n        [ 4.7757e-02, -2.8418e-02,  2.4755e-01, -1.4655e-01, -1.0172e-01,\n         -1.1323e-01, -8.6760e-02,  8.3303e-02, -3.2036e-02,  1.0074e-02,\n          9.5540e-02],\n        [-3.3923e-02,  8.3451e-02,  2.6354e-02,  2.7649e-01,  2.7948e-01,\n          2.5758e-01, -5.1857e-02,  6.7780e-02, -2.1740e-01,  1.3730e-01,\n          3.0016e-01],\n        [ 2.0432e-01, -1.8471e-01,  5.5980e-02, -1.7011e-01,  1.7934e-01,\n         -1.1187e-01, -2.3862e-01,  4.7182e-03, -1.0286e-01, -2.1046e-01,\n          2.6550e-01],\n        [ 1.5538e-01,  8.9623e-02,  1.4072e-01, -1.2246e-01, -1.5305e-01,\n         -2.0910e-01, -2.5582e-01, -2.1938e-02, -1.8305e-01, -7.6265e-03,\n         -2.0317e-01],\n        [ 1.8712e-01,  8.6788e-02, -1.5149e-01, -1.8920e-01, -9.5064e-02,\n         -2.6550e-01,  1.9446e-01, -9.5523e-03, -3.8990e-02,  1.4048e-01,\n         -1.5657e-01],\n        [-1.1191e-01,  2.7792e-01, -1.3236e-01, -4.8941e-03,  1.0388e-01,\n          9.7380e-03, -6.7352e-02, -1.0517e-01,  1.9007e-01, -1.2473e-01,\n         -3.9266e-02],\n        [-7.3290e-02, -1.0426e-01, -2.3895e-01, -1.7663e-01, -9.4983e-02,\n         -2.8600e-01,  1.0174e-01, -8.1894e-02, -5.4346e-05, -8.0161e-02,\n          2.3915e-01],\n        [-1.2483e-01,  1.0813e-01,  1.7504e-01, -2.0044e-01, -1.5969e-01,\n         -6.2901e-02,  1.9403e-01,  1.3463e-01,  5.2400e-02,  2.8466e-01,\n         -6.9401e-02],\n        [ 3.5062e-02, -5.2675e-02, -2.6295e-01,  1.2419e-02, -1.3259e-01,\n         -1.0155e-01,  1.6283e-01,  2.1113e-01, -2.4850e-02, -1.8227e-01,\n         -1.3424e-01],\n        [-2.8442e-01,  1.6493e-01, -2.5474e-01, -2.5019e-01,  1.6535e-01,\n          1.0277e-01,  7.8166e-02, -1.1966e-01, -2.2072e-01,  1.1839e-01,\n          1.5674e-01],\n        [-2.8882e-01, -2.1021e-01,  2.0033e-01, -1.3862e-01, -1.4601e-01,\n         -2.0708e-01,  1.1797e-01,  3.5179e-02, -2.5090e-03, -2.4861e-01,\n          1.4470e-01],\n        [-2.3517e-01, -1.0034e-01, -5.9584e-02,  2.7551e-01, -1.6484e-02,\n         -1.1258e-01, -1.7354e-01, -1.8827e-01,  2.5125e-01, -1.8351e-01,\n         -2.6983e-01],\n        [ 1.5203e-01,  2.0302e-02, -1.8171e-01, -1.4541e-02,  2.6286e-01,\n         -8.1372e-02, -2.3584e-01, -2.4229e-01, -2.6194e-02,  1.0077e-01,\n         -2.6662e-01],\n        [ 1.8518e-01, -2.7820e-01, -1.4234e-01,  1.1806e-01, -1.2501e-01,\n          1.8723e-02, -5.9479e-02,  3.2075e-02,  8.4401e-03,  2.2670e-01,\n          2.1437e-01],\n        [-2.0528e-01,  2.3031e-02,  2.4643e-01,  1.1809e-01,  1.4833e-01,\n         -1.3490e-01,  1.8122e-01, -1.5777e-01,  1.1183e-01,  6.7236e-02,\n         -4.3736e-02],\n        [ 1.1791e-01, -1.9750e-01,  8.3867e-02, -2.7053e-03, -6.8858e-02,\n         -5.4495e-02,  2.3147e-02,  2.0298e-01,  2.0485e-01, -4.1148e-02,\n          1.0637e-01],\n        [-2.0789e-01,  1.6507e-01,  2.2904e-01,  2.8206e-01, -2.1199e-01,\n         -2.1653e-01,  8.8743e-02, -4.9242e-02, -2.7768e-01, -1.4998e-02,\n          2.1024e-01],\n        [ 1.3438e-01, -2.2892e-01,  1.3405e-01, -1.5495e-01,  1.9356e-01,\n          1.7663e-01,  7.3334e-02, -3.7913e-02,  2.2263e-01, -1.4390e-02,\n          1.0229e-02],\n        [-5.8547e-02,  2.1029e-01,  2.2491e-01,  1.4273e-01, -1.1555e-01,\n         -2.8519e-01,  2.9584e-01,  1.0250e-01, -1.5292e-01, -1.7549e-01,\n          1.6914e-01],\n        [ 1.2993e-01, -2.1760e-01,  1.8074e-01, -2.9914e-01, -2.0282e-02,\n          9.3186e-02, -1.3123e-01,  2.9674e-01,  6.5308e-02,  2.8086e-01,\n          2.2963e-02],\n        [ 1.6248e-01, -1.0683e-01, -7.7475e-02, -1.9657e-01, -5.7275e-02,\n         -1.2531e-01, -1.8193e-01,  2.7493e-01,  1.4485e-01, -3.3638e-02,\n          1.4048e-01],\n        [ 2.6934e-01,  2.7303e-01,  1.6959e-01,  1.4674e-01, -7.4985e-03,\n          1.7014e-01,  2.1503e-01, -2.2513e-01, -1.7315e-01,  2.0475e-01,\n         -1.6272e-01],\n        [ 2.5981e-02, -1.0780e-01,  2.4470e-01, -2.3988e-01,  2.6895e-01,\n         -1.5258e-01, -6.8608e-02,  5.9314e-02,  2.4812e-01, -2.8675e-01,\n         -2.1363e-01],\n        [ 3.1882e-02, -1.0986e-01,  1.5978e-01, -1.2785e-01, -2.5412e-02,\n         -4.8812e-02,  8.2593e-03, -1.8910e-01, -1.6709e-01, -8.3408e-02,\n          2.4812e-01]], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1624,  0.1762,  0.0945, -0.1049,  0.1824, -0.2220, -0.2454,  0.2046,\n         0.1100, -0.1954,  0.0892,  0.1106,  0.1946, -0.1284, -0.0592, -0.1598,\n        -0.1521, -0.1451, -0.1761,  0.1581, -0.2694, -0.1363,  0.0384, -0.0316,\n         0.2094,  0.1734, -0.0236, -0.2619, -0.2038,  0.1972,  0.1469, -0.1363,\n        -0.1271, -0.2080,  0.0023,  0.1265,  0.1104,  0.1560, -0.0863,  0.1759,\n        -0.2394,  0.2215, -0.1381, -0.1691,  0.0486,  0.0982,  0.1562, -0.1885,\n        -0.1528, -0.2936,  0.1448, -0.0788, -0.1565, -0.2878,  0.0567,  0.0484,\n         0.0350, -0.1886, -0.0728,  0.1886,  0.2500, -0.2751, -0.1687,  0.1188],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0771, -0.0366,  0.0571,  ...,  0.0329, -0.0995, -0.0317],\n        [-0.0420, -0.0487, -0.0518,  ..., -0.0662,  0.0779,  0.0496],\n        [-0.0415,  0.1015,  0.0797,  ...,  0.0078, -0.0930, -0.0847],\n        ...,\n        [-0.0776,  0.1033, -0.0164,  ..., -0.1080,  0.1002,  0.1107],\n        [-0.0037,  0.0527,  0.0155,  ..., -0.1241, -0.1231, -0.0273],\n        [ 0.1048,  0.0556,  0.0068,  ..., -0.1140, -0.0744,  0.0576]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1014,  0.0638,  0.0962, -0.1212,  0.0969, -0.0573,  0.0136, -0.0914,\n         0.0707,  0.0868, -0.1086, -0.0780,  0.0757, -0.0803, -0.0557,  0.0533,\n         0.1054, -0.0282, -0.0740, -0.0817, -0.1219,  0.1101, -0.0879,  0.0996,\n         0.0363, -0.0387,  0.0870, -0.0843, -0.0386, -0.0462,  0.0240,  0.0212,\n         0.0035, -0.1213, -0.1035,  0.0782, -0.0244, -0.0560,  0.0850, -0.0098,\n         0.0128,  0.0851, -0.0588, -0.0275,  0.0853, -0.0212, -0.0965, -0.0278,\n        -0.0865,  0.0107,  0.0550, -0.0437,  0.0517,  0.0048, -0.0591, -0.0465,\n         0.0337,  0.0949, -0.0646, -0.0072, -0.0439, -0.1024,  0.1162, -0.0309],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1150,  0.0612, -0.0785,  0.0777, -0.1015,  0.1243, -0.0263, -0.1071,\n         -0.0340, -0.0087,  0.0387, -0.0831, -0.0734,  0.0338, -0.0692, -0.1009,\n         -0.1150,  0.0299,  0.0722,  0.0781, -0.0147, -0.1219, -0.0819, -0.0525,\n         -0.0750, -0.1184, -0.0531,  0.0106, -0.0085, -0.0348, -0.1106,  0.0667,\n         -0.0584, -0.1129, -0.0576,  0.0141,  0.0396, -0.0607, -0.0424,  0.0653,\n          0.1141,  0.0786,  0.0006,  0.0281,  0.1072, -0.0977, -0.0034, -0.0149,\n         -0.1211,  0.0822, -0.1107,  0.0453, -0.0535, -0.0072, -0.0597,  0.0881,\n         -0.0418, -0.0259, -0.1189, -0.0043, -0.0756,  0.0843, -0.0719, -0.0714]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0923], device='cuda:0', requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            }
        }
    },
    "steps_per_epoch":	3000,
    "train_v_iters":	80,
    "vf_lr":	0.001
}