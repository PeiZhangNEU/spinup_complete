{
    "ac_kwargs":	{
        "hidden_sizes":	[
            256,
            256
        ]
    },
    "act_store_dim":	1,
    "actor_critic":	"MLPActorCritic",
    "alpha":	0.2,
    "alpha_lr":	0.001,
    "delayup":	0.995,
    "device":	"cuda:0",
    "env_fn":	"<function <lambda> at 0x7fe23cf65ef0>",
    "exp_name":	"sac_discrete",
    "gamma":	0.99,
    "logger_kwargs":	{
        "exp_name":	"sac_discrete",
        "output_dir":	"/home/zp/deeplearning/spinningup_project/data/sac_discrete/sac_discrete_s0"
    },
    "max_ep_len":	200,
    "num_test_episodes":	10,
    "p":	"Parameter containing:\ntensor([ 0.0513, -0.0575], device='cuda:0')",
    "pi_lr":	0.001,
    "q_lr":	0.001,
    "replay_size":	5000,
    "self":	{
        "<spinup.alogos.sac_discrete.sac_discrete.sac_discrete object at 0x7fe228b9f610>":	{
            "ac":	{
                "MLPActorCritic(\n  (pi): MLPActor(\n    (net): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n  (q1): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n  (q2): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "MLPActor(\n  (net): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "net":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1541, -0.4159,  0.3853,  0.4909, -0.1822,  0.2241,  0.0790,  0.4716,\n        -0.0851, -0.4201,  0.4691,  0.3279,  0.1977, -0.3808, -0.2493, -0.0974,\n         0.1907, -0.1346, -0.2550,  0.0028,  0.3137, -0.3281,  0.3892, -0.3942,\n        -0.1578, -0.3482, -0.1839, -0.1785,  0.3096, -0.4544, -0.0559, -0.0329,\n         0.2175,  0.2057,  0.1354,  0.4713, -0.2613, -0.1574, -0.0184,  0.0499,\n        -0.1615, -0.1994,  0.3056,  0.3308, -0.0904, -0.3837, -0.3643, -0.4495,\n        -0.2535,  0.2318,  0.4125,  0.1745,  0.3060, -0.2390, -0.2896, -0.0022,\n         0.4859,  0.0916,  0.0431, -0.4949,  0.4407,  0.0937, -0.2983,  0.0932,\n         0.3823,  0.3002,  0.3597,  0.3885, -0.3056,  0.1730,  0.0912,  0.4607,\n        -0.1155, -0.1826,  0.2963,  0.2815, -0.2779, -0.2819, -0.0942,  0.1194,\n        -0.3230, -0.1076,  0.2892,  0.1770, -0.3554,  0.3223,  0.3673, -0.3316,\n        -0.1575,  0.1628,  0.1424, -0.0615,  0.2566, -0.2889, -0.1131,  0.0411,\n         0.4378,  0.1474,  0.2161,  0.1242, -0.3460,  0.4658,  0.3356, -0.1140,\n        -0.1447,  0.0533,  0.0561, -0.1323,  0.4937, -0.0492, -0.2637,  0.1563,\n        -0.4334, -0.3190, -0.3294, -0.3876, -0.2595, -0.3287,  0.0521, -0.3565,\n        -0.4516,  0.0241, -0.4528, -0.4785, -0.3299, -0.2054,  0.4456,  0.0314,\n         0.2575,  0.2961, -0.0574,  0.1288, -0.3652, -0.1092, -0.2511, -0.1517,\n        -0.1428, -0.3170, -0.0636, -0.4711,  0.2585,  0.0537, -0.0280,  0.2702,\n        -0.1270, -0.2970, -0.0441, -0.3504, -0.0158,  0.2653,  0.1672, -0.4291,\n        -0.2718, -0.1302, -0.4594,  0.1485,  0.3876,  0.1043,  0.1029, -0.0941,\n         0.4854, -0.1430,  0.1418,  0.3379,  0.0219,  0.2282, -0.3402,  0.1435,\n        -0.4495,  0.3182, -0.2586,  0.0080, -0.0707, -0.1093,  0.1884,  0.3559,\n         0.1060, -0.3599,  0.2154,  0.2876,  0.3600, -0.4414,  0.1092, -0.3698,\n        -0.4709, -0.2815, -0.2144, -0.0020,  0.3811,  0.4574, -0.0452, -0.4172,\n         0.1605,  0.1199, -0.2493,  0.0941,  0.0513, -0.1973,  0.3298,  0.3019,\n         0.1807, -0.3165,  0.3916,  0.2440, -0.0787, -0.0737, -0.3538,  0.4308,\n         0.1346,  0.3063, -0.4400,  0.3356,  0.0176,  0.0928, -0.1947, -0.1292,\n         0.4845,  0.3905, -0.3184,  0.3226, -0.4356,  0.3759, -0.2887,  0.2277,\n        -0.4938,  0.3111, -0.0172,  0.3766,  0.3298,  0.3606, -0.2939,  0.2581,\n         0.0993,  0.3365, -0.1031, -0.1453,  0.2812, -0.4781,  0.4312, -0.3871,\n        -0.3865,  0.4090,  0.0550,  0.4060, -0.4014,  0.1968, -0.0704,  0.0931,\n         0.2417, -0.4376, -0.3782, -0.0060,  0.4483,  0.2144,  0.2118, -0.1602],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.4290, -0.1058,  0.4743, -0.1028],\n        [ 0.2531, -0.4780,  0.1732, -0.4999],\n        [ 0.0339,  0.0157,  0.2901, -0.2286],\n        ...,\n        [-0.0745, -0.1397, -0.1894,  0.4891],\n        [-0.0853, -0.2386,  0.3482,  0.0950],\n        [ 0.2819,  0.4207,  0.3679, -0.3548]], device='cuda:0',\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 6.0913e-02, -3.4626e-02,  4.4969e-02, -2.3780e-02,  3.5794e-02,\n        -5.5496e-02,  2.1002e-02,  5.9911e-02, -9.2531e-03, -4.9601e-02,\n        -6.0456e-02, -2.7516e-02, -5.7320e-02, -5.7427e-02, -2.9750e-02,\n        -6.0037e-03, -3.9257e-02, -2.7400e-02, -7.5555e-03, -8.1710e-03,\n         3.6639e-02, -3.0473e-02, -4.1667e-02, -5.1269e-02,  4.2324e-02,\n         1.2772e-02, -3.1106e-03, -4.4313e-02, -1.4366e-02,  2.8707e-05,\n         4.9017e-02, -2.4572e-02,  5.9941e-02, -3.1341e-02,  4.5435e-02,\n         3.9680e-03,  3.6046e-02, -5.2321e-02,  1.4783e-02, -1.3904e-02,\n        -2.4301e-02,  2.8245e-02, -6.0579e-02, -1.6902e-02, -5.3758e-02,\n        -5.2327e-02, -5.5550e-03, -4.5158e-02,  3.3012e-02, -4.6085e-02,\n        -1.1712e-02,  8.2660e-03,  7.2619e-03,  5.7591e-02, -4.5676e-02,\n        -4.6310e-02,  3.8462e-02,  2.1397e-02, -4.9478e-02,  2.8170e-02,\n        -1.4347e-02, -4.0269e-02,  3.9209e-02, -4.0345e-05,  3.4664e-02,\n        -2.8357e-02, -5.0968e-02,  6.2614e-03, -4.3510e-02, -3.3587e-02,\n         4.0547e-02, -3.0356e-02,  4.2414e-02, -7.9272e-03,  3.1174e-02,\n         4.9423e-02, -4.0581e-02, -4.0482e-02,  2.9091e-02,  5.0387e-02,\n         1.2945e-03,  2.2616e-02,  1.5659e-02, -4.1182e-02, -3.4933e-02,\n         4.7361e-03,  5.3783e-02,  4.5305e-02, -3.8264e-02, -6.0913e-02,\n         6.0611e-02, -5.4911e-02, -3.5395e-02,  5.6411e-02, -3.8706e-02,\n        -1.8125e-02, -2.5594e-03, -4.7945e-02, -3.3631e-02, -3.5977e-02,\n         2.4727e-02,  2.5808e-02,  5.9960e-02, -3.3034e-02,  5.9527e-02,\n        -1.3264e-02, -5.0596e-02, -4.8315e-03, -6.6214e-03, -3.6731e-02,\n         1.5343e-02, -3.1068e-02, -7.0883e-03,  5.1601e-03,  3.2882e-02,\n         2.6287e-02, -2.8058e-03, -1.5868e-02, -1.6833e-02,  2.5641e-02,\n         7.3576e-03,  5.6714e-02,  2.0377e-02,  3.4872e-02,  1.5106e-02,\n         5.9687e-02,  1.3695e-02,  2.3007e-02,  1.0371e-02,  3.7556e-02,\n        -2.8821e-02,  4.9481e-03, -3.0349e-02,  1.8002e-02, -6.0813e-03,\n        -9.2954e-03,  4.4846e-02, -5.2925e-02,  2.1532e-02, -2.2245e-02,\n        -5.5667e-02,  9.6197e-03,  9.1972e-03,  5.9052e-02, -4.6993e-02,\n        -5.1885e-02,  2.0214e-02,  5.5119e-02,  2.1642e-02, -5.5193e-02,\n        -5.9041e-02, -1.1775e-02,  3.3470e-02, -3.8805e-02, -5.8032e-03,\n         3.9051e-02,  1.9301e-02, -4.0188e-02,  1.6646e-02, -5.4245e-02,\n         1.5857e-02, -3.9512e-02,  5.5565e-02, -2.2895e-02,  1.3024e-02,\n         2.5005e-02,  5.8054e-04, -8.7451e-03,  3.2832e-02, -3.0688e-02,\n        -1.4325e-02,  5.2305e-02,  5.9901e-02, -5.1228e-02, -3.4108e-02,\n        -5.6050e-03, -1.6375e-02,  3.8231e-03,  9.1362e-03, -5.6739e-02,\n        -2.3406e-02, -5.8379e-02, -3.0658e-04, -3.0870e-02,  1.2085e-02,\n         2.8206e-02,  6.2357e-02,  1.1117e-02,  2.9934e-02,  5.2959e-02,\n         1.7304e-03, -1.3512e-02, -3.4765e-02, -2.5731e-02, -4.8099e-02,\n        -4.6679e-03,  4.1993e-02, -1.0396e-02, -6.9333e-03,  2.6476e-02,\n         1.3559e-02, -1.1189e-02, -4.2326e-02,  3.8801e-02,  4.9281e-02,\n         1.7189e-02, -4.2487e-02,  3.4443e-02, -5.1766e-03,  5.4068e-02,\n        -2.9003e-02,  5.4127e-02,  3.5559e-02, -5.3971e-02,  8.2017e-03,\n         2.9802e-02,  3.6643e-02, -1.9452e-02, -2.1991e-02,  2.3713e-02,\n        -6.1883e-02, -8.7566e-03, -4.1851e-02,  6.8833e-03,  2.9856e-02,\n         4.3381e-02,  4.1761e-02,  2.9507e-02, -4.3322e-04, -3.8456e-02,\n         1.0690e-02, -3.3456e-02,  2.3969e-02,  4.8107e-02,  1.3027e-02,\n         2.5272e-02, -5.8870e-02,  2.8631e-02, -6.9940e-03, -1.7893e-02,\n        -4.0558e-02, -3.4221e-02, -6.1249e-02,  4.9052e-02, -4.0314e-03,\n         5.7556e-02, -1.7077e-03,  3.9282e-02, -2.1724e-02, -5.9710e-02,\n        -4.4200e-04, -6.1539e-03, -5.9075e-02, -1.7899e-02,  1.4553e-02,\n        -2.0001e-02], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0567,  0.0051, -0.0064,  ..., -0.0003, -0.0510, -0.0299],\n        [-0.0563,  0.0271, -0.0128,  ..., -0.0542, -0.0206,  0.0111],\n        [ 0.0124, -0.0209, -0.0301,  ...,  0.0117, -0.0340,  0.0066],\n        ...,\n        [-0.0330, -0.0120,  0.0465,  ...,  0.0598, -0.0344,  0.0237],\n        [ 0.0014, -0.0141,  0.0435,  ..., -0.0568, -0.0229, -0.0330],\n        [-0.0034, -0.0281,  0.0468,  ..., -0.0276, -0.0483,  0.0426]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0578,  0.0395], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0097, -0.0180, -0.0193,  0.0276,  0.0150,  0.0457, -0.0304, -0.0543,\n          0.0339,  0.0306, -0.0527, -0.0610,  0.0604, -0.0020, -0.0395,  0.0295,\n         -0.0074, -0.0542, -0.0490, -0.0233, -0.0513,  0.0517,  0.0422, -0.0301,\n         -0.0111, -0.0369,  0.0204, -0.0130,  0.0563, -0.0196,  0.0558,  0.0038,\n          0.0536, -0.0493,  0.0275, -0.0129,  0.0124,  0.0218, -0.0144, -0.0267,\n         -0.0530, -0.0317,  0.0541, -0.0318,  0.0502, -0.0553,  0.0303, -0.0120,\n         -0.0409, -0.0311, -0.0206, -0.0012, -0.0013, -0.0329, -0.0563,  0.0579,\n         -0.0265,  0.0165, -0.0450, -0.0062,  0.0057, -0.0381, -0.0189, -0.0248,\n         -0.0560, -0.0132,  0.0254, -0.0490, -0.0148,  0.0074,  0.0132,  0.0539,\n          0.0464, -0.0539,  0.0198,  0.0003,  0.0498,  0.0624, -0.0100,  0.0309,\n          0.0391,  0.0028, -0.0386,  0.0359, -0.0402,  0.0452, -0.0277,  0.0382,\n          0.0495, -0.0307,  0.0220,  0.0304,  0.0414,  0.0463,  0.0539, -0.0007,\n         -0.0623,  0.0029, -0.0290,  0.0392, -0.0221,  0.0302,  0.0516,  0.0022,\n          0.0543, -0.0157,  0.0476, -0.0596,  0.0559,  0.0427, -0.0319,  0.0303,\n         -0.0603,  0.0138,  0.0278, -0.0140, -0.0245,  0.0472, -0.0427,  0.0367,\n          0.0459, -0.0367,  0.0120, -0.0333, -0.0031,  0.0121,  0.0440,  0.0077,\n         -0.0566, -0.0380, -0.0542,  0.0166,  0.0427,  0.0250, -0.0350, -0.0134,\n         -0.0412, -0.0462, -0.0552, -0.0035, -0.0155,  0.0398,  0.0496, -0.0016,\n          0.0102, -0.0180, -0.0356,  0.0152,  0.0379,  0.0099,  0.0399,  0.0238,\n          0.0005, -0.0192,  0.0011, -0.0348,  0.0603, -0.0023,  0.0582, -0.0538,\n         -0.0623, -0.0009,  0.0118, -0.0131, -0.0516, -0.0007,  0.0151,  0.0625,\n         -0.0136,  0.0450, -0.0016, -0.0444,  0.0274,  0.0344,  0.0425,  0.0283,\n          0.0535,  0.0454,  0.0272, -0.0554, -0.0521, -0.0138,  0.0553,  0.0157,\n          0.0121,  0.0077,  0.0264,  0.0361, -0.0369, -0.0249, -0.0466, -0.0211,\n         -0.0456, -0.0439, -0.0087,  0.0403,  0.0021,  0.0238, -0.0187,  0.0368,\n         -0.0160, -0.0182, -0.0161, -0.0200,  0.0107, -0.0032, -0.0607, -0.0015,\n          0.0275,  0.0575,  0.0514, -0.0603, -0.0017, -0.0071, -0.0419, -0.0336,\n          0.0214, -0.0587,  0.0587,  0.0479,  0.0268,  0.0223, -0.0119, -0.0486,\n          0.0540, -0.0399, -0.0296, -0.0006,  0.0392,  0.0533,  0.0137, -0.0512,\n          0.0429, -0.0162, -0.0120,  0.0593, -0.0094, -0.0129,  0.0365,  0.0167,\n         -0.0409, -0.0079, -0.0026, -0.0430,  0.0004, -0.0503,  0.0138, -0.0325,\n         -0.0459, -0.0076,  0.0494, -0.0126,  0.0471,  0.0007, -0.0414,  0.0195],\n        [ 0.0266,  0.0261, -0.0105, -0.0487,  0.0470,  0.0283,  0.0126, -0.0094,\n         -0.0508, -0.0049,  0.0287,  0.0504,  0.0450, -0.0105, -0.0545, -0.0489,\n         -0.0344, -0.0096, -0.0605,  0.0402, -0.0377, -0.0381,  0.0121, -0.0483,\n          0.0488, -0.0099,  0.0103,  0.0483, -0.0092,  0.0234, -0.0314,  0.0304,\n          0.0383,  0.0102, -0.0239,  0.0310, -0.0168,  0.0112, -0.0588, -0.0012,\n         -0.0286,  0.0283,  0.0576,  0.0480, -0.0048, -0.0377,  0.0076, -0.0466,\n         -0.0458,  0.0099, -0.0591, -0.0210,  0.0232, -0.0131,  0.0609, -0.0518,\n          0.0563, -0.0322,  0.0002, -0.0215, -0.0397, -0.0450, -0.0260,  0.0021,\n         -0.0460, -0.0176,  0.0493, -0.0358, -0.0434,  0.0301,  0.0264,  0.0021,\n          0.0281,  0.0548, -0.0301, -0.0217,  0.0387,  0.0079, -0.0196,  0.0197,\n         -0.0163, -0.0258, -0.0513,  0.0070,  0.0537, -0.0377,  0.0539,  0.0522,\n          0.0050,  0.0509, -0.0123,  0.0248,  0.0171, -0.0204, -0.0242, -0.0303,\n         -0.0170,  0.0387,  0.0028,  0.0200, -0.0250,  0.0215, -0.0449, -0.0027,\n         -0.0404,  0.0450, -0.0230, -0.0591, -0.0236,  0.0290,  0.0045,  0.0227,\n         -0.0586, -0.0209, -0.0504, -0.0212, -0.0517, -0.0504,  0.0514, -0.0094,\n          0.0506,  0.0316,  0.0348, -0.0592, -0.0244, -0.0583, -0.0315, -0.0445,\n         -0.0598,  0.0263,  0.0538,  0.0556,  0.0278,  0.0314,  0.0053,  0.0617,\n          0.0276,  0.0283,  0.0509,  0.0237,  0.0131, -0.0198, -0.0269,  0.0315,\n          0.0317, -0.0503, -0.0316,  0.0102,  0.0063,  0.0219, -0.0541, -0.0508,\n         -0.0113,  0.0156,  0.0264, -0.0066,  0.0528,  0.0074,  0.0048,  0.0267,\n         -0.0511,  0.0098,  0.0185, -0.0205, -0.0293, -0.0540,  0.0600,  0.0180,\n         -0.0308, -0.0355,  0.0396, -0.0054, -0.0078, -0.0616,  0.0038, -0.0041,\n         -0.0009, -0.0119, -0.0543,  0.0283,  0.0422, -0.0311, -0.0058,  0.0623,\n         -0.0364,  0.0423, -0.0254,  0.0411,  0.0240, -0.0333,  0.0143,  0.0423,\n         -0.0428, -0.0020,  0.0297,  0.0350,  0.0345,  0.0041, -0.0504, -0.0514,\n         -0.0462, -0.0198, -0.0298, -0.0028,  0.0249, -0.0021, -0.0573, -0.0166,\n         -0.0524,  0.0327,  0.0228,  0.0624, -0.0057, -0.0142, -0.0514, -0.0237,\n         -0.0069, -0.0553, -0.0339,  0.0106,  0.0453,  0.0454, -0.0366, -0.0160,\n         -0.0307,  0.0601,  0.0432,  0.0197,  0.0312, -0.0426, -0.0610,  0.0426,\n         -0.0284, -0.0442,  0.0612,  0.0093,  0.0021, -0.0188,  0.0071,  0.0080,\n         -0.0096,  0.0140,  0.0135, -0.0257,  0.0312,  0.0105,  0.0101, -0.0056,\n         -0.0389, -0.0294,  0.0448,  0.0559, -0.0542, -0.0520,  0.0392,  0.0516]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "act_dim":	2,
                                "obs_dim":	4,
                                "training":	true
                            }
                        },
                        "q1":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-1.9962e-01,  1.2976e-01,  2.7294e-01, -5.7560e-02,  4.3497e-01,\n         2.3543e-01,  3.6013e-02,  5.3409e-02, -3.3610e-01, -3.6582e-01,\n         4.3450e-01,  4.7132e-01,  1.4130e-02, -1.9506e-02, -1.8033e-01,\n         3.7473e-01, -2.3706e-01, -6.9214e-02,  3.4421e-01, -1.7500e-01,\n         6.3653e-02, -4.7311e-01,  1.9863e-01,  3.3056e-01, -2.8121e-01,\n        -2.0563e-01,  3.4080e-01,  1.9393e-01,  3.2922e-01,  2.2447e-01,\n         2.4548e-01, -1.3538e-01,  1.0371e-01, -2.3775e-01, -3.8911e-01,\n        -3.2659e-01,  4.4025e-01, -1.2251e-01, -4.2622e-01,  3.2950e-01,\n        -2.8402e-01,  1.0951e-01, -4.7868e-01,  1.6723e-01,  2.7159e-01,\n        -4.6678e-01,  3.9085e-01, -1.0209e-01,  4.1880e-01, -1.7394e-01,\n        -2.4641e-01, -3.8244e-01, -4.3572e-01,  1.0206e-01, -3.6070e-01,\n        -1.1019e-01,  3.5549e-02,  6.9859e-03, -2.5251e-01,  9.6788e-02,\n        -2.0265e-01, -4.0044e-01, -1.5973e-01,  4.8261e-01, -1.2343e-01,\n         3.2452e-01,  2.7381e-02, -3.5123e-01, -3.5580e-02, -3.0196e-02,\n         3.9375e-01, -3.5212e-02,  3.4686e-02, -8.7625e-03, -4.6724e-01,\n         6.3440e-02,  2.8392e-01, -2.9722e-01,  4.8024e-01, -9.0158e-04,\n         1.5095e-01,  4.4028e-01, -3.3151e-01,  2.0686e-02, -3.1721e-01,\n         1.5876e-01, -3.0394e-01,  6.5505e-02,  1.6096e-02, -1.5596e-01,\n        -6.6804e-02,  1.3482e-01, -4.4710e-01,  3.9394e-01, -1.2698e-01,\n         1.8031e-01,  4.6012e-01,  2.1281e-01,  2.4823e-01, -3.0084e-01,\n         2.2770e-01,  4.9406e-01,  4.3865e-01, -4.7583e-01,  2.5661e-01,\n        -5.0738e-02, -2.8174e-01, -9.4003e-02,  2.1648e-01, -2.6443e-01,\n         2.2057e-01,  3.2453e-01,  1.5271e-01,  4.1228e-01, -3.8116e-02,\n         2.9939e-03, -4.6855e-01,  4.8571e-01,  3.9091e-01, -4.4468e-01,\n         2.4410e-01, -2.9081e-02, -2.4988e-01, -3.7520e-01, -4.3670e-01,\n        -2.6576e-01,  2.4013e-01, -1.8935e-01, -4.5507e-01,  3.1774e-01,\n         3.7077e-01, -3.0619e-01, -3.6326e-02, -2.0766e-01, -2.2440e-01,\n         3.7366e-01,  2.5821e-03,  2.6856e-01,  4.8135e-01,  4.3445e-01,\n         3.9880e-03,  2.0563e-01,  2.5620e-01, -2.0266e-01, -4.2443e-01,\n         4.4976e-01,  4.3077e-01, -2.6392e-01, -4.4410e-01,  4.0813e-01,\n         2.9686e-01,  1.0877e-01, -2.1348e-01,  1.1285e-01,  4.4605e-01,\n        -5.4893e-02, -1.8589e-02,  1.7188e-01, -4.2742e-01,  2.4292e-01,\n         1.2697e-01, -2.1291e-01, -3.5114e-01, -2.8034e-01, -3.3928e-01,\n         6.1714e-02, -2.1038e-01,  1.0554e-01, -5.6190e-02,  4.3339e-02,\n         4.7976e-02,  2.2437e-01,  3.8838e-01,  2.1905e-01, -1.8607e-01,\n         4.9909e-02, -4.2789e-01,  4.1267e-01,  1.9608e-01,  3.0970e-02,\n        -1.7694e-01,  4.2423e-01, -3.7706e-01,  7.4076e-02, -2.0542e-01,\n         3.5590e-01, -1.8422e-01, -1.7219e-01,  4.1969e-01,  1.6671e-01,\n        -4.1719e-01,  4.7291e-01, -1.6880e-01,  2.4419e-01, -2.1781e-01,\n         4.3933e-01,  1.0093e-01,  3.7270e-01,  4.9201e-01, -1.4436e-01,\n         2.8692e-01,  1.7837e-01, -1.4133e-01, -4.0764e-01,  5.2528e-02,\n        -2.5284e-01,  2.7737e-01,  4.9643e-01,  5.9057e-02, -2.7105e-01,\n        -4.4060e-02,  6.0942e-03,  7.2555e-02, -9.1431e-02, -1.5090e-01,\n        -2.1872e-01, -4.1075e-01,  3.8461e-01, -4.5157e-03, -4.9067e-01,\n         4.6612e-01,  2.5406e-01,  4.2418e-01, -4.0354e-01, -4.8299e-01,\n         2.2403e-01, -2.1654e-02,  3.3083e-01, -4.7570e-01, -4.1944e-01,\n        -7.7381e-02, -1.5930e-01,  4.7680e-01, -4.0373e-01, -3.9075e-01,\n        -2.8293e-01,  3.7644e-01, -7.9051e-03, -1.9506e-01, -3.2510e-01,\n        -4.7790e-01, -2.1574e-01,  4.6893e-01, -1.5588e-01,  4.5955e-05,\n         8.2703e-02,  4.3051e-01, -1.1578e-01,  2.7984e-01,  3.7855e-01,\n         4.8422e-01,  3.8446e-01,  1.3210e-01, -3.4336e-01,  8.0217e-02,\n         3.3007e-01], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.3650,  0.1926,  0.3665, -0.4551],\n        [-0.4671,  0.0869, -0.1379, -0.4116],\n        [-0.0655,  0.3748, -0.2167, -0.2616],\n        ...,\n        [ 0.1532,  0.1845,  0.2320,  0.1809],\n        [-0.3210,  0.0358, -0.2053, -0.0046],\n        [ 0.1897, -0.4997,  0.0539, -0.3697]], device='cuda:0',\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-2.2604e-02,  3.1567e-02, -4.7032e-02, -1.3071e-02, -3.1565e-02,\n         5.1928e-02,  1.1242e-03, -1.0280e-02,  4.1787e-02, -3.4881e-02,\n         4.8470e-02,  3.3419e-02, -3.1485e-03,  3.7777e-02, -5.9138e-02,\n        -4.0488e-02,  3.6577e-02,  4.9368e-02, -2.1430e-02, -1.2739e-02,\n         6.4866e-03,  5.4008e-03,  2.4772e-02,  2.6358e-02, -3.4074e-02,\n        -4.1407e-02, -5.9629e-02, -5.8664e-02,  3.4731e-02,  8.8219e-03,\n         1.5506e-02,  4.8163e-02,  2.5956e-02,  5.4496e-02,  2.7068e-02,\n        -4.0188e-02, -4.5402e-03, -5.5804e-02,  7.0584e-03,  2.3410e-02,\n        -4.8404e-02, -4.0739e-02,  2.2476e-03, -2.3985e-02, -4.0246e-02,\n        -1.4682e-02,  4.1274e-03, -4.6117e-02, -6.8751e-04,  6.2484e-02,\n        -5.2852e-02,  9.7730e-03,  4.8335e-02, -4.0360e-02,  6.6055e-03,\n         1.4531e-02,  5.9382e-02, -3.2185e-03,  3.2042e-02,  2.0246e-02,\n         9.9710e-03,  2.9443e-02, -6.0054e-02,  5.6436e-02,  4.7874e-02,\n         2.1782e-02,  2.4294e-02,  6.6594e-03, -8.4765e-03, -1.5208e-02,\n        -5.6865e-02,  3.8000e-02, -6.0692e-03,  4.2630e-02, -5.7178e-02,\n         4.6558e-02, -9.2130e-03, -2.9130e-02,  3.7176e-02, -2.6513e-02,\n        -3.1311e-02, -1.3649e-02, -4.9194e-03, -2.5279e-02,  1.3388e-03,\n        -1.3581e-02, -2.1734e-02, -2.3988e-02, -3.9658e-02,  3.9210e-02,\n         1.1916e-02,  4.0918e-02,  5.2344e-02, -9.3701e-03,  1.5082e-02,\n        -4.8007e-02,  5.8493e-02, -3.6079e-02,  5.0136e-02,  4.3922e-02,\n        -2.8601e-02,  3.5702e-03, -2.1551e-02,  2.3366e-02, -5.2549e-02,\n        -1.2403e-02,  8.4423e-05, -2.8221e-02,  2.1658e-03, -3.5255e-02,\n         8.0655e-03,  1.5776e-02,  3.0857e-02,  5.1387e-02, -2.6135e-02,\n         4.0753e-02,  4.9788e-02,  4.9571e-02,  5.2945e-02,  3.9130e-02,\n        -3.3891e-02, -4.1595e-02, -2.8531e-02, -5.4222e-03,  1.1716e-02,\n         3.4571e-02,  4.8683e-02,  4.3623e-02,  2.7669e-03,  9.6493e-03,\n         3.5790e-02,  1.0275e-02,  4.4709e-02, -5.4412e-02,  4.9899e-02,\n        -1.5718e-02,  4.1906e-03,  5.6973e-02, -3.0233e-03,  2.1672e-02,\n         3.8345e-02,  2.7300e-02,  4.9417e-03,  5.5755e-02, -2.9071e-02,\n        -4.7819e-02,  1.3359e-03,  4.3200e-02,  4.1314e-02, -6.2012e-02,\n         8.3524e-03,  2.5685e-02,  5.7996e-03, -4.9345e-02, -2.9467e-03,\n        -5.9417e-02,  4.6109e-02,  1.8613e-02, -5.0013e-03, -4.5992e-02,\n         4.6029e-02,  1.2358e-02,  2.4165e-02, -5.2408e-02,  2.6222e-02,\n        -4.5874e-02,  1.2107e-03,  2.3497e-02, -2.3079e-02,  3.1804e-02,\n         3.7814e-02, -2.8218e-02, -1.7235e-02,  4.2929e-02,  5.4327e-02,\n         3.4098e-02, -6.1104e-02,  1.6557e-02, -1.2751e-02, -4.7365e-02,\n         5.5777e-02,  4.7833e-05,  2.6629e-02, -5.4816e-02, -3.2067e-02,\n        -5.0143e-02,  3.2576e-03,  4.4309e-02,  4.1694e-02,  4.0892e-02,\n        -5.8621e-02,  6.0942e-02, -5.1636e-02,  5.0797e-02, -2.7219e-02,\n        -1.3578e-02,  5.2339e-02, -9.9539e-04,  5.8648e-02,  6.0967e-02,\n        -4.9219e-02, -4.0899e-02, -1.3053e-02,  3.2349e-02, -2.4511e-02,\n        -5.9191e-02, -3.9231e-02,  7.6393e-04, -1.0076e-02,  8.2299e-03,\n        -1.2487e-02,  5.2082e-02,  6.1497e-02, -6.0370e-02,  5.9855e-02,\n         8.8103e-03, -1.7743e-03, -6.3060e-03,  8.3604e-03, -5.1302e-02,\n        -7.1222e-04,  4.1206e-03,  2.7157e-02, -5.2260e-02, -4.9903e-02,\n         4.8954e-02, -1.0563e-02, -5.4621e-02, -4.4943e-02, -5.9938e-02,\n        -5.6685e-02,  5.3392e-02,  1.5170e-02,  1.8297e-02,  1.4722e-02,\n        -4.1134e-02, -3.2979e-02,  3.6884e-02,  1.2875e-02,  2.8458e-02,\n         2.6316e-02, -2.7398e-02, -5.8625e-02,  5.4713e-02,  3.5349e-02,\n        -4.4725e-02,  3.6600e-02, -4.2638e-02,  2.6515e-03,  6.2422e-02,\n        -9.3373e-03,  6.9790e-03,  6.1502e-02, -4.2043e-02, -2.3079e-02,\n         6.1346e-02], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0183, -0.0330,  0.0475,  ..., -0.0102,  0.0508, -0.0552],\n        [ 0.0230,  0.0404, -0.0175,  ...,  0.0610, -0.0133,  0.0342],\n        [-0.0116,  0.0319, -0.0504,  ...,  0.0063, -0.0390,  0.0021],\n        ...,\n        [-0.0481, -0.0069, -0.0012,  ...,  0.0447, -0.0473,  0.0456],\n        [-0.0011, -0.0501,  0.0077,  ...,  0.0340,  0.0290,  0.0382],\n        [-0.0072, -0.0250,  0.0189,  ..., -0.0423, -0.0489, -0.0230]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0339, -0.0256], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-5.1386e-03, -3.6500e-02, -4.5660e-02, -5.7929e-02,  5.7241e-02,\n         -1.4348e-02,  5.8078e-02,  1.3565e-02, -4.4403e-02,  5.0631e-02,\n          3.3267e-02,  2.0705e-02,  5.1059e-02, -3.1209e-02,  2.6400e-03,\n         -4.5928e-02, -4.5103e-02,  2.4290e-02, -1.6746e-02,  4.4139e-02,\n         -1.7876e-02,  3.2466e-02,  3.8775e-02,  4.3882e-02,  4.9926e-02,\n          2.5948e-02,  1.1067e-02, -5.2174e-02,  4.9200e-02,  4.4737e-02,\n         -2.5652e-02, -3.2573e-02, -2.3861e-03,  2.7533e-02,  4.5714e-02,\n          5.9700e-02, -5.8999e-02, -4.8578e-02, -3.3012e-02, -4.0647e-02,\n          2.4606e-02,  2.8370e-02, -4.0493e-02, -4.8130e-02, -5.6823e-03,\n          2.2402e-02,  5.3185e-02,  6.7808e-03,  6.0597e-02, -4.1758e-02,\n          1.5805e-02, -1.5054e-02,  4.2120e-02, -2.7022e-02,  5.8519e-02,\n          6.0667e-02,  4.8642e-02, -3.0237e-02, -2.1638e-02, -1.7833e-02,\n          2.3787e-02, -4.1359e-02, -4.3630e-02, -3.7798e-02,  2.0184e-02,\n         -2.8839e-02, -3.1096e-02,  1.9031e-02,  2.4672e-02,  2.5068e-02,\n         -4.9902e-02, -2.3427e-02,  3.6031e-02, -2.3276e-02,  5.5070e-02,\n          4.8558e-02, -2.7940e-02,  2.1498e-02, -4.1303e-02,  3.4286e-02,\n          5.3664e-02,  4.4376e-02,  5.0474e-03, -1.9207e-02,  2.9926e-02,\n         -5.5592e-02,  2.6029e-02, -1.0144e-02,  9.1866e-06,  3.6897e-02,\n         -1.6283e-02,  2.8397e-02,  4.6940e-02,  4.4245e-02,  6.1046e-02,\n          5.8959e-02,  3.3180e-02, -3.5616e-02,  9.6771e-03, -2.7611e-02,\n         -6.2753e-03, -3.9665e-02, -4.3359e-02, -4.2270e-02, -4.3682e-02,\n          3.2047e-02,  1.7213e-03,  2.1672e-02,  4.9777e-02, -1.8996e-02,\n          1.8557e-03,  2.3308e-02,  1.7778e-02,  5.3154e-02, -2.2372e-02,\n          3.5463e-02, -1.9317e-03, -1.2226e-02, -1.4400e-02, -6.0124e-03,\n         -1.3936e-02,  4.1061e-02,  5.1002e-02, -1.2609e-02,  1.4679e-02,\n          3.3463e-02,  4.1305e-02, -3.4433e-02,  4.8141e-02, -2.2699e-02,\n         -4.3505e-02,  5.4451e-02, -1.0238e-02, -5.7694e-02, -1.2353e-02,\n         -4.3291e-02,  2.8926e-02,  3.1781e-02, -3.0289e-02,  5.8222e-02,\n         -5.8108e-02, -1.0935e-02, -5.1726e-02,  2.2265e-02, -2.0251e-02,\n          8.5905e-03,  4.4099e-03, -1.6824e-02,  6.7532e-03,  4.8639e-02,\n         -1.1607e-02,  2.0699e-02, -3.1267e-02,  3.8250e-02, -4.6874e-02,\n          6.0836e-02,  9.4357e-03, -3.9092e-02, -2.3922e-02,  5.0376e-02,\n         -4.1962e-02,  2.1529e-02,  1.0412e-02,  1.6689e-02,  4.6943e-02,\n         -2.8955e-02,  1.1092e-02,  4.0190e-02, -6.1299e-02,  4.1534e-03,\n          4.2600e-02,  1.3020e-02, -3.6156e-02, -2.3985e-02, -5.2355e-02,\n          4.3914e-04,  2.6606e-02, -2.7612e-02,  2.1861e-02,  4.8673e-03,\n         -4.5080e-02,  3.2328e-02, -2.7480e-02, -1.4795e-03, -2.8557e-02,\n          3.3459e-02,  8.8954e-03, -6.0928e-02, -1.4938e-04,  3.9835e-03,\n         -4.0394e-02,  1.5224e-02, -4.8976e-02, -9.0517e-03,  3.5259e-02,\n         -4.4643e-02, -4.4473e-02,  3.3178e-02, -2.0099e-02, -7.1318e-03,\n          7.3179e-03, -5.6166e-03,  4.8161e-02,  1.8558e-02, -2.1767e-02,\n         -7.0796e-03, -2.8087e-02,  6.0145e-02, -3.5429e-02, -4.6039e-02,\n         -2.4594e-02, -4.9719e-02, -2.5513e-02,  2.8310e-02, -3.1527e-02,\n         -3.1042e-02,  1.5367e-02, -1.5218e-02, -4.2219e-02,  3.4638e-03,\n         -6.1562e-02,  1.8113e-02,  2.7047e-02, -6.0515e-02, -1.9570e-04,\n          4.1359e-02,  1.4679e-02, -3.2822e-02, -2.3895e-02, -3.7231e-02,\n         -4.6841e-02,  5.4524e-02,  2.1658e-02, -2.6191e-02, -5.0055e-02,\n          3.3266e-02, -4.4339e-02,  6.2350e-03, -5.2591e-02, -2.8909e-03,\n          5.7354e-02, -3.2398e-02, -6.1121e-02,  2.1703e-02,  1.3556e-02,\n          4.6202e-02, -4.0231e-02,  3.3896e-04, -2.7437e-02,  1.8636e-02,\n         -4.5120e-02, -1.5158e-02, -4.2555e-02,  8.8862e-03, -2.6450e-02,\n          4.1052e-02],\n        [ 5.7454e-02,  4.5058e-02, -2.8317e-02,  9.6026e-03, -3.3439e-02,\n         -2.1535e-02,  6.1609e-03, -6.4634e-03,  4.8397e-02, -8.0976e-04,\n          2.9914e-02, -5.8263e-02,  4.5082e-02, -2.9109e-02, -3.0090e-02,\n         -6.2373e-02, -6.2219e-02,  4.8708e-03, -3.6894e-02,  2.0139e-02,\n          5.9661e-02,  2.2438e-02, -6.0632e-02, -4.7058e-02,  2.8859e-02,\n         -4.8921e-02, -5.3941e-02,  1.0461e-02, -1.4912e-03,  4.7038e-02,\n          4.9554e-02, -2.5301e-02, -1.7063e-02, -1.2578e-02,  3.3010e-02,\n          1.4477e-02,  3.8827e-02, -2.4149e-02, -5.1312e-02, -3.3827e-02,\n         -5.8316e-02, -4.6354e-02, -5.2413e-02,  4.2478e-02,  1.3623e-02,\n          5.2481e-02,  3.1054e-03, -2.7862e-02,  1.0981e-02,  1.6863e-02,\n         -1.1249e-02, -1.3443e-02, -3.1842e-02, -3.0497e-02,  1.2903e-03,\n         -1.8698e-02,  2.3219e-02, -1.3956e-02,  3.4970e-02, -1.2143e-02,\n          2.8276e-02,  3.1505e-03,  4.3355e-02, -1.3152e-02,  2.8764e-02,\n          1.8895e-02,  5.9398e-02,  2.3092e-02,  5.5753e-02, -2.3797e-02,\n          1.2399e-02,  3.0812e-02,  2.3646e-02, -1.7164e-03, -2.3159e-02,\n         -2.1681e-02, -4.8665e-02,  9.4970e-03,  1.0137e-02,  2.0323e-02,\n          4.8283e-02,  3.3770e-03, -4.7562e-02,  5.1089e-02, -8.3045e-03,\n          1.8764e-02, -5.0342e-02, -4.8200e-03, -2.6801e-02, -2.9844e-03,\n         -2.7471e-02,  3.0838e-02, -2.5140e-02, -3.1490e-03, -5.0561e-02,\n          5.0871e-03, -2.4195e-02, -3.8189e-02,  5.0358e-05,  5.0408e-02,\n         -1.9806e-02, -7.6828e-03,  2.5709e-02,  5.2703e-02,  5.3084e-02,\n          7.4778e-04,  1.1595e-02, -5.5334e-02, -1.7039e-02,  5.8033e-02,\n          4.6508e-02, -4.8204e-02, -5.1268e-02, -3.9107e-02,  1.9972e-02,\n          2.9479e-02, -4.3707e-02,  1.0844e-03,  9.5288e-03,  3.3115e-02,\n          2.9815e-02,  5.1017e-02, -6.0316e-02, -2.2462e-02,  2.4875e-02,\n          1.7425e-03, -1.3190e-02, -1.1203e-02,  4.6913e-02, -8.9444e-03,\n          1.8103e-02,  8.7861e-03, -4.5732e-02, -3.2436e-02,  5.4780e-03,\n          4.6254e-02,  4.4766e-02, -1.4231e-02,  3.3950e-02,  3.8489e-02,\n         -1.9364e-02,  3.9205e-02, -3.0073e-02,  5.1559e-02,  5.0060e-02,\n         -3.8754e-02, -5.5984e-02, -5.7404e-02,  5.0497e-02, -4.8585e-02,\n         -5.7034e-02,  6.3831e-03, -3.6545e-02,  3.1704e-02,  5.4925e-02,\n          6.5841e-03,  3.4278e-02,  4.9688e-03,  5.8060e-02, -3.6803e-02,\n          1.1048e-02, -6.7351e-03,  2.8072e-02, -8.3644e-03,  4.3363e-02,\n          3.2519e-03, -5.1070e-02, -3.0732e-02, -5.6665e-02, -4.3732e-02,\n          2.2879e-02, -6.1774e-02,  3.3243e-02,  9.0315e-03, -4.7999e-02,\n         -2.2573e-02, -5.9884e-02, -1.2378e-02,  5.9045e-02,  2.9512e-02,\n          4.6932e-02,  1.0502e-02,  1.3195e-02,  2.8691e-02, -4.7618e-02,\n          5.3908e-03,  3.6562e-02,  5.5809e-02, -5.4790e-02, -1.4019e-02,\n         -2.9631e-02,  1.0266e-02,  2.2250e-02, -5.2885e-02, -3.9302e-02,\n          1.0473e-02, -1.9716e-02, -3.0295e-02, -6.2168e-02, -2.0362e-02,\n          1.1706e-02, -5.5644e-02,  3.4809e-02,  8.0311e-04,  5.6560e-02,\n         -4.4043e-02, -2.7580e-02,  2.5577e-02,  4.3626e-02,  3.1293e-02,\n         -8.8088e-03, -3.8444e-02,  3.5484e-02,  1.0399e-02,  5.4511e-02,\n         -5.2267e-03,  2.1604e-02,  2.0689e-02,  5.6147e-02,  3.4622e-02,\n         -6.4848e-03, -4.7649e-02, -2.4433e-02, -2.1759e-02, -4.0691e-02,\n          2.2269e-02, -2.5158e-02,  3.8042e-02, -4.2510e-02,  2.7479e-02,\n          5.6316e-03,  4.0246e-03,  1.5221e-03, -9.1264e-03, -3.0843e-02,\n         -1.6612e-02,  1.8427e-02, -4.4932e-02, -1.6035e-02,  3.8048e-02,\n         -8.3792e-03, -5.1971e-02, -5.6108e-02,  1.3894e-02, -5.9453e-02,\n         -5.5200e-02, -5.6137e-03,  1.2901e-02,  3.7651e-02, -5.3007e-02,\n          3.7677e-02,  3.7266e-02, -4.8865e-02, -1.6006e-02,  1.6093e-02,\n          5.7319e-02]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "q2":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0290, -0.1145, -0.0660, -0.0373, -0.3267,  0.0126, -0.4886, -0.2750,\n        -0.3283, -0.0967,  0.0219, -0.2301,  0.2991,  0.2299,  0.1215,  0.2964,\n        -0.3071, -0.3243,  0.0457,  0.2193, -0.4251, -0.0467,  0.0990,  0.3500,\n        -0.3833, -0.0221, -0.4643, -0.1733,  0.2285,  0.2291,  0.0031, -0.4485,\n        -0.4698,  0.4632,  0.0316, -0.3789,  0.1312, -0.0713,  0.4102,  0.1044,\n         0.2670, -0.4494, -0.1593,  0.1233, -0.5000,  0.0557, -0.4926, -0.3504,\n         0.2960, -0.1449,  0.2107, -0.2437,  0.2563, -0.1217,  0.2817,  0.0793,\n        -0.2548, -0.4924, -0.2933, -0.1720,  0.0268,  0.0075,  0.4960,  0.0385,\n         0.1497, -0.1715,  0.1861,  0.1153,  0.0072, -0.2398, -0.2796,  0.3501,\n        -0.2943, -0.4778, -0.2045, -0.1804, -0.0870,  0.1673,  0.3141, -0.2550,\n        -0.2367,  0.1137, -0.3174, -0.1768,  0.2714,  0.3668, -0.0391, -0.3422,\n         0.2964, -0.2188,  0.3997,  0.1952,  0.4604,  0.1389, -0.0988,  0.0154,\n        -0.1831, -0.3675,  0.0690, -0.4550,  0.0651, -0.1407, -0.0886, -0.4227,\n         0.2116,  0.4604, -0.1755, -0.1853, -0.3510,  0.0673, -0.3130, -0.1118,\n         0.4197,  0.2596,  0.1203,  0.1568, -0.3339, -0.0598, -0.1860,  0.0378,\n         0.1695,  0.3859,  0.2167, -0.1848,  0.0865, -0.1485, -0.4984, -0.4224,\n         0.4365,  0.3388,  0.0624,  0.3922,  0.2480, -0.1169,  0.0464, -0.1335,\n        -0.2286,  0.0164, -0.4118, -0.3478, -0.3522, -0.2627, -0.3254, -0.1034,\n         0.3458,  0.0475, -0.2511,  0.4250,  0.1684, -0.1452, -0.2503, -0.3781,\n        -0.4330, -0.3379,  0.1563, -0.0775, -0.3200, -0.0937, -0.3742, -0.2946,\n        -0.3419, -0.0227,  0.3673, -0.0395,  0.4269,  0.2444, -0.1320,  0.0528,\n        -0.4629, -0.3743,  0.2453,  0.4376,  0.0904, -0.1283,  0.1650,  0.3082,\n         0.1688, -0.2560,  0.2868, -0.0032, -0.1436, -0.2712, -0.3660,  0.0670,\n         0.0665,  0.4443, -0.3624,  0.0670, -0.3484,  0.0629, -0.4814, -0.0782,\n        -0.0981, -0.3608, -0.4695,  0.2772,  0.1644, -0.3063, -0.1772,  0.1063,\n         0.2820, -0.4574,  0.1419,  0.0131, -0.2264, -0.1254, -0.3272, -0.3202,\n         0.2530, -0.2182,  0.2519,  0.2208, -0.4772,  0.0964,  0.0487, -0.3381,\n        -0.4866,  0.1433,  0.3350,  0.0771, -0.2538,  0.3221, -0.1189,  0.0796,\n        -0.0331,  0.0524,  0.1004, -0.2211, -0.4443, -0.3033, -0.3381,  0.2769,\n        -0.3335,  0.3241, -0.1402, -0.0296, -0.0858, -0.4495,  0.3946, -0.3463,\n        -0.0769,  0.4904, -0.1490, -0.3573,  0.1338, -0.3741,  0.4622, -0.4332,\n         0.2613, -0.0756,  0.1712,  0.4687, -0.1898, -0.3281, -0.2226, -0.1625],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1298, -0.2212, -0.2846,  0.1385],\n        [ 0.2766,  0.1821, -0.4600,  0.1437],\n        [-0.4907,  0.2830,  0.2819,  0.0194],\n        ...,\n        [ 0.2698, -0.0346, -0.2598, -0.1458],\n        [ 0.2572, -0.0251, -0.1817,  0.2091],\n        [ 0.4902,  0.2523, -0.2817, -0.0128]], device='cuda:0',\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0180,  0.0571,  0.0068, -0.0161,  0.0036,  0.0566,  0.0062,  0.0115,\n         0.0406,  0.0254, -0.0129, -0.0160,  0.0178,  0.0407,  0.0533,  0.0237,\n         0.0471,  0.0523,  0.0361,  0.0424,  0.0359, -0.0036, -0.0304,  0.0131,\n        -0.0394, -0.0452, -0.0605, -0.0502,  0.0364, -0.0304, -0.0521, -0.0011,\n        -0.0337, -0.0368,  0.0584, -0.0407,  0.0208,  0.0177,  0.0596,  0.0474,\n         0.0509, -0.0625, -0.0621, -0.0268, -0.0623, -0.0172,  0.0607,  0.0171,\n        -0.0305, -0.0203, -0.0474, -0.0219,  0.0005, -0.0617, -0.0067,  0.0114,\n         0.0255, -0.0121, -0.0496, -0.0573,  0.0348, -0.0033,  0.0135,  0.0607,\n         0.0200, -0.0583, -0.0126,  0.0289,  0.0192, -0.0046, -0.0443, -0.0599,\n         0.0528,  0.0366, -0.0612, -0.0187,  0.0112,  0.0592,  0.0524,  0.0537,\n         0.0520, -0.0201, -0.0599,  0.0064,  0.0411, -0.0029, -0.0339, -0.0481,\n        -0.0402, -0.0160,  0.0595,  0.0030,  0.0437, -0.0299,  0.0273,  0.0511,\n        -0.0395,  0.0165,  0.0315, -0.0132,  0.0544, -0.0275,  0.0602, -0.0200,\n        -0.0269, -0.0229,  0.0623, -0.0275,  0.0330,  0.0175, -0.0356, -0.0234,\n        -0.0243, -0.0259,  0.0067, -0.0454, -0.0201,  0.0376, -0.0509, -0.0467,\n        -0.0355,  0.0335, -0.0600, -0.0513, -0.0414, -0.0532, -0.0081, -0.0175,\n         0.0610,  0.0118,  0.0105,  0.0011, -0.0597, -0.0330, -0.0435,  0.0485,\n        -0.0623, -0.0400,  0.0614, -0.0363,  0.0258, -0.0516,  0.0511,  0.0450,\n        -0.0165, -0.0482, -0.0072, -0.0199, -0.0611, -0.0060, -0.0187, -0.0558,\n        -0.0434, -0.0180,  0.0412, -0.0129, -0.0456, -0.0066,  0.0436, -0.0263,\n         0.0566, -0.0327,  0.0300, -0.0443, -0.0008, -0.0486, -0.0476,  0.0225,\n        -0.0333,  0.0495, -0.0441, -0.0563, -0.0379,  0.0114, -0.0322,  0.0435,\n        -0.0446,  0.0322,  0.0589, -0.0338,  0.0161, -0.0387,  0.0426,  0.0599,\n         0.0228, -0.0504,  0.0528, -0.0176,  0.0490, -0.0396,  0.0326,  0.0363,\n        -0.0489,  0.0003,  0.0231, -0.0006,  0.0443, -0.0197, -0.0419,  0.0312,\n        -0.0133, -0.0398, -0.0478, -0.0232, -0.0338, -0.0291,  0.0204,  0.0197,\n         0.0118, -0.0202,  0.0264, -0.0625, -0.0403,  0.0294, -0.0111, -0.0415,\n         0.0347, -0.0541, -0.0285, -0.0039, -0.0373, -0.0104, -0.0010,  0.0565,\n        -0.0145,  0.0020, -0.0295, -0.0320,  0.0459, -0.0353,  0.0484,  0.0083,\n        -0.0183,  0.0029,  0.0448, -0.0398,  0.0560,  0.0298, -0.0464,  0.0342,\n         0.0409,  0.0378, -0.0458, -0.0399, -0.0591, -0.0200, -0.0488,  0.0191,\n         0.0382,  0.0555, -0.0350, -0.0478, -0.0054,  0.0189, -0.0342, -0.0517],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-1.2573e-02, -3.0363e-02,  3.4008e-02,  ...,  8.6647e-03,\n          1.1560e-02, -1.4140e-02],\n        [-3.9068e-02, -2.2558e-02,  5.5355e-03,  ...,  2.0758e-02,\n         -3.2366e-02,  3.4633e-02],\n        [ 1.2757e-02, -2.7424e-02,  2.8040e-02,  ..., -5.8893e-02,\n         -3.1864e-02, -1.3186e-02],\n        ...,\n        [ 2.1602e-02,  1.1588e-02,  4.5458e-03,  ...,  1.2327e-02,\n          4.8816e-02, -3.2194e-02],\n        [-4.3114e-02,  6.0637e-02,  1.1496e-05,  ...,  3.1135e-02,\n         -1.3356e-02, -3.2217e-02],\n        [-2.7925e-02,  2.4817e-03, -5.8972e-02,  ..., -1.5074e-02,\n         -5.7299e-02, -1.9535e-02]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0513, -0.0575], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-4.5320e-02, -4.3285e-02,  3.9831e-02,  3.5646e-02,  4.3496e-04,\n          4.5331e-02,  5.9911e-02,  3.2141e-04,  2.0202e-02,  3.0322e-02,\n          1.1896e-02,  5.0360e-02, -2.9928e-02,  4.3472e-03, -6.0561e-02,\n          1.5946e-02,  4.9403e-02,  2.9060e-02,  1.6339e-02, -1.0013e-02,\n          4.3396e-02,  4.7619e-02, -4.4034e-02,  4.6203e-02,  5.0311e-02,\n         -5.9997e-02,  5.9593e-02,  7.6818e-03,  1.7997e-02,  2.2810e-02,\n         -3.2233e-02,  4.0730e-02,  3.2331e-02,  1.6433e-02, -2.2317e-03,\n         -3.0240e-02, -5.5449e-02, -4.1709e-02, -1.8044e-02,  3.0528e-02,\n         -4.5471e-02,  9.0617e-03, -3.9050e-02, -1.5672e-02, -4.6976e-02,\n         -1.9595e-02, -4.3725e-02, -4.9003e-02,  6.2764e-03,  9.3671e-03,\n         -2.2823e-02,  1.6382e-02,  2.9085e-02,  3.0590e-03,  4.9841e-02,\n          3.3353e-02, -3.4112e-02, -4.7911e-02, -5.7419e-02, -1.4643e-02,\n         -2.0989e-02,  2.7641e-03,  1.1842e-02, -1.9344e-02,  3.3124e-02,\n          4.2960e-02,  1.6693e-02, -4.5054e-02, -1.5038e-02, -6.8432e-03,\n          5.2325e-03, -1.6878e-02,  3.2655e-02, -4.9473e-02, -3.9289e-02,\n          4.8467e-02, -5.6936e-02,  2.6813e-02, -5.2174e-02, -7.8691e-03,\n          2.4432e-02,  2.9676e-02, -1.3208e-02, -4.4179e-02,  2.5774e-02,\n         -3.1245e-02, -1.2471e-02, -2.8358e-02, -3.8136e-02,  5.7951e-02,\n         -4.4963e-02,  8.2170e-04, -5.6718e-02,  3.0459e-02,  5.3141e-03,\n          4.4787e-02,  5.6498e-02,  3.3972e-02, -2.4048e-02, -5.9263e-03,\n          5.4981e-03, -1.4650e-02,  4.9056e-03, -7.8577e-03,  2.4069e-02,\n         -1.3624e-02, -5.3591e-02,  3.2923e-02,  4.5546e-02,  4.9713e-02,\n          1.2761e-02, -3.3219e-02,  5.1345e-02,  3.4908e-02,  3.6084e-02,\n          3.0883e-02, -5.0442e-02,  6.0378e-02,  2.4006e-02, -4.2679e-02,\n          5.4741e-02,  4.9416e-02, -4.6410e-02, -2.4330e-02,  4.1201e-02,\n          5.3309e-02,  4.2248e-02,  4.4630e-02, -4.9638e-02, -2.6197e-02,\n          5.0665e-02,  1.0157e-02, -1.9666e-02, -2.3535e-03, -3.8100e-02,\n         -3.0332e-02, -3.7852e-02,  5.3157e-02, -6.0544e-02,  2.7405e-02,\n          4.4898e-02,  2.6490e-02,  4.8072e-02, -5.4813e-02,  1.1396e-02,\n         -1.1630e-02,  5.3641e-02,  1.8908e-02, -3.7403e-02, -1.0188e-02,\n         -3.7711e-02, -8.7358e-04,  4.6326e-02,  6.1561e-03, -1.4242e-02,\n          1.9100e-02, -3.3535e-02,  4.1680e-02, -3.8657e-02,  6.0534e-02,\n          5.3726e-02,  3.2471e-02,  3.7761e-02,  4.7851e-02,  2.7681e-02,\n         -1.5360e-02, -3.7640e-02, -5.7792e-02,  1.0835e-02,  3.9421e-02,\n          3.3378e-02, -3.6482e-02,  1.9653e-02, -3.4163e-02,  5.8173e-02,\n         -3.5044e-02,  2.9626e-02, -4.1131e-02,  5.8608e-02, -2.2617e-02,\n         -1.8576e-02,  5.8734e-02,  2.2270e-02, -2.4208e-02, -1.1179e-02,\n          1.2145e-02, -1.6433e-02,  1.9029e-02,  1.6702e-02, -5.5701e-02,\n          2.9336e-02,  3.5507e-02,  3.5825e-02,  4.6501e-02,  3.9044e-02,\n          5.6934e-02,  5.8284e-03, -4.4347e-02, -5.7323e-02,  2.6777e-02,\n         -2.7898e-02,  7.4982e-03,  2.7456e-02, -4.8860e-02, -1.0909e-02,\n          2.5413e-04,  2.4200e-02,  2.2069e-02,  4.3434e-02,  2.3006e-02,\n          3.9480e-02, -7.7999e-03,  4.4995e-02,  4.6018e-03, -1.7064e-02,\n         -5.3319e-02, -1.0883e-02,  4.5776e-02, -5.8425e-02,  4.8154e-02,\n         -1.4999e-02, -2.5724e-02, -2.3181e-02,  4.3677e-02, -5.4947e-02,\n          1.7388e-02, -2.7722e-02, -5.6883e-02, -5.8093e-04,  2.8396e-02,\n          6.2952e-03,  1.2465e-03,  3.1102e-02, -2.1257e-02,  5.8814e-02,\n         -1.2635e-02, -4.1419e-02, -3.2427e-03,  3.5820e-02, -2.3744e-02,\n         -2.1826e-02, -3.8083e-04,  2.5404e-02, -4.0319e-03, -6.6040e-04,\n         -5.0947e-02, -4.7234e-02, -4.9268e-02,  3.4094e-02, -1.9747e-03,\n          2.4816e-02, -8.2143e-05, -2.5160e-02, -1.4989e-02, -5.9384e-02,\n          1.8326e-03],\n        [-5.3580e-02, -7.6978e-03, -2.0866e-02,  1.6719e-02, -1.6956e-02,\n          3.8104e-02, -6.1697e-02,  8.3346e-03,  3.7452e-02,  4.3413e-02,\n          3.9356e-02,  3.5525e-03,  4.4565e-02, -5.2745e-02,  3.2745e-02,\n         -5.2167e-04, -2.3373e-02,  9.5391e-03,  4.1961e-02, -3.3728e-02,\n          2.5912e-02, -1.8922e-02, -7.1048e-03,  4.6341e-02,  6.8856e-03,\n          6.5757e-03, -4.9498e-02,  5.5083e-02,  1.9236e-02,  3.6218e-02,\n         -5.1799e-02,  3.0335e-02,  3.5281e-02,  3.6199e-02, -7.2493e-03,\n          5.4088e-02, -6.0521e-02,  8.2754e-05, -2.8085e-02,  1.2285e-02,\n         -4.7847e-02, -2.4299e-02, -6.0272e-02, -5.7520e-02, -4.9323e-02,\n          4.8360e-02,  3.9737e-02,  2.3570e-03,  3.2809e-03,  3.6694e-02,\n         -2.3566e-02,  1.6804e-02, -6.2031e-02, -1.2891e-02, -9.3096e-03,\n         -1.0324e-02,  1.2324e-02,  1.0243e-02,  1.4787e-02,  1.0888e-02,\n          5.6204e-02,  5.9298e-02, -1.8818e-02,  5.2134e-02, -4.7078e-02,\n          1.7681e-02, -4.2611e-03,  5.5445e-02,  3.3658e-02, -5.6581e-02,\n         -5.8154e-02,  4.0322e-02, -5.5973e-02, -1.7193e-03,  1.0708e-02,\n          1.6799e-02, -4.7714e-02,  3.5961e-02,  6.0243e-02,  1.1119e-02,\n         -5.7433e-02, -4.1154e-02, -5.6147e-02,  3.8439e-02, -2.6060e-02,\n         -4.3853e-02,  3.1502e-03, -1.0103e-02, -2.4678e-02,  3.8755e-02,\n          1.0089e-02, -1.5827e-02,  4.0332e-03, -5.0306e-03,  2.9502e-02,\n         -7.0741e-03,  1.8133e-02,  7.3761e-03, -3.0817e-03,  4.6040e-02,\n          2.0858e-02,  3.9110e-02,  5.5519e-02, -5.3168e-02, -5.0600e-03,\n         -2.0244e-02,  3.5218e-02, -5.3613e-02,  2.0115e-02,  1.9626e-02,\n          3.4896e-03, -3.1369e-02, -4.3026e-02, -1.6815e-02,  5.2387e-02,\n         -2.4194e-02, -1.5073e-02,  5.3163e-03,  1.3406e-02,  1.9487e-02,\n          2.2957e-02,  3.4846e-02, -3.0049e-02,  9.3546e-03,  2.6198e-02,\n          2.2760e-02,  4.6307e-02,  5.6098e-02,  3.4952e-02,  1.2398e-02,\n          3.9067e-02, -4.6304e-03,  5.0569e-02, -1.4478e-02, -3.2022e-02,\n         -2.3514e-02,  3.5755e-02,  5.1459e-02,  4.3608e-02,  1.9900e-02,\n         -5.8269e-02,  5.7878e-02, -3.8815e-02,  1.2587e-02, -2.9434e-02,\n         -1.8371e-02,  6.8510e-03, -5.7422e-02, -3.1840e-02, -6.7899e-04,\n         -5.8167e-05,  1.5687e-02, -1.2836e-02,  3.7322e-02,  3.1165e-02,\n         -5.3349e-02, -5.5576e-02,  1.7756e-02,  1.2865e-02,  2.5265e-02,\n         -9.0838e-03, -4.1317e-02, -3.3871e-02,  1.1511e-03, -4.6128e-02,\n          5.9619e-02, -1.7614e-02,  1.8629e-02,  2.6520e-02, -6.0923e-02,\n          3.9699e-02, -3.0792e-02,  5.2315e-02,  6.1510e-02, -5.8246e-02,\n         -5.7492e-02,  5.7301e-02, -1.0059e-02,  6.1893e-03,  4.5890e-02,\n         -3.6105e-02, -4.9430e-02,  5.6902e-02,  2.0788e-02, -2.4791e-02,\n          1.3720e-02,  4.9924e-02,  5.7998e-02,  5.0396e-02,  8.9931e-03,\n          3.8658e-02, -3.3123e-03,  5.3835e-02,  3.6809e-02,  2.9982e-02,\n          1.3040e-02,  1.4449e-02, -4.4134e-03,  6.2828e-03,  5.9483e-02,\n         -5.8289e-02, -5.6318e-03, -3.6926e-03,  2.9829e-02, -1.1631e-02,\n         -3.0765e-02, -4.3862e-02, -6.1831e-03,  1.3510e-03,  5.8283e-02,\n         -1.2201e-02,  5.8510e-02, -6.1373e-02, -4.7874e-02,  4.5690e-02,\n         -3.7745e-03, -2.9547e-02, -2.4893e-02,  3.0861e-02, -9.3280e-03,\n         -1.1658e-02,  4.8747e-02, -2.3986e-02, -2.3798e-02, -2.5947e-02,\n         -4.9524e-02, -1.6577e-02, -3.3801e-02,  2.4912e-02,  1.1998e-02,\n          4.2159e-03,  3.5738e-03, -5.8949e-02,  2.2693e-02, -1.2792e-02,\n         -2.3228e-02, -4.8938e-02, -2.4337e-02, -4.9047e-02, -6.2425e-02,\n          9.0554e-03,  4.4007e-02, -1.7237e-03, -3.0090e-02,  5.5654e-02,\n         -5.1312e-02,  2.4862e-02,  1.9600e-02,  7.4906e-03, -6.1055e-02,\n          4.1439e-02,  5.9419e-02, -5.6514e-02,  5.2410e-02,  3.3153e-02,\n         -4.1536e-02]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "ac_targ":	{
                "MLPActorCritic(\n  (pi): MLPActor(\n    (net): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n  (q1): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n  (q2): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=4, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n      (5): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "MLPActor(\n  (net): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "net":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1541, -0.4159,  0.3853,  0.4909, -0.1822,  0.2241,  0.0790,  0.4716,\n        -0.0851, -0.4201,  0.4691,  0.3279,  0.1977, -0.3808, -0.2493, -0.0974,\n         0.1907, -0.1346, -0.2550,  0.0028,  0.3137, -0.3281,  0.3892, -0.3942,\n        -0.1578, -0.3482, -0.1839, -0.1785,  0.3096, -0.4544, -0.0559, -0.0329,\n         0.2175,  0.2057,  0.1354,  0.4713, -0.2613, -0.1574, -0.0184,  0.0499,\n        -0.1615, -0.1994,  0.3056,  0.3308, -0.0904, -0.3837, -0.3643, -0.4495,\n        -0.2535,  0.2318,  0.4125,  0.1745,  0.3060, -0.2390, -0.2896, -0.0022,\n         0.4859,  0.0916,  0.0431, -0.4949,  0.4407,  0.0937, -0.2983,  0.0932,\n         0.3823,  0.3002,  0.3597,  0.3885, -0.3056,  0.1730,  0.0912,  0.4607,\n        -0.1155, -0.1826,  0.2963,  0.2815, -0.2779, -0.2819, -0.0942,  0.1194,\n        -0.3230, -0.1076,  0.2892,  0.1770, -0.3554,  0.3223,  0.3673, -0.3316,\n        -0.1575,  0.1628,  0.1424, -0.0615,  0.2566, -0.2889, -0.1131,  0.0411,\n         0.4378,  0.1474,  0.2161,  0.1242, -0.3460,  0.4658,  0.3356, -0.1140,\n        -0.1447,  0.0533,  0.0561, -0.1323,  0.4937, -0.0492, -0.2637,  0.1563,\n        -0.4334, -0.3190, -0.3294, -0.3876, -0.2595, -0.3287,  0.0521, -0.3565,\n        -0.4516,  0.0241, -0.4528, -0.4785, -0.3299, -0.2054,  0.4456,  0.0314,\n         0.2575,  0.2961, -0.0574,  0.1288, -0.3652, -0.1092, -0.2511, -0.1517,\n        -0.1428, -0.3170, -0.0636, -0.4711,  0.2585,  0.0537, -0.0280,  0.2702,\n        -0.1270, -0.2970, -0.0441, -0.3504, -0.0158,  0.2653,  0.1672, -0.4291,\n        -0.2718, -0.1302, -0.4594,  0.1485,  0.3876,  0.1043,  0.1029, -0.0941,\n         0.4854, -0.1430,  0.1418,  0.3379,  0.0219,  0.2282, -0.3402,  0.1435,\n        -0.4495,  0.3182, -0.2586,  0.0080, -0.0707, -0.1093,  0.1884,  0.3559,\n         0.1060, -0.3599,  0.2154,  0.2876,  0.3600, -0.4414,  0.1092, -0.3698,\n        -0.4709, -0.2815, -0.2144, -0.0020,  0.3811,  0.4574, -0.0452, -0.4172,\n         0.1605,  0.1199, -0.2493,  0.0941,  0.0513, -0.1973,  0.3298,  0.3019,\n         0.1807, -0.3165,  0.3916,  0.2440, -0.0787, -0.0737, -0.3538,  0.4308,\n         0.1346,  0.3063, -0.4400,  0.3356,  0.0176,  0.0928, -0.1947, -0.1292,\n         0.4845,  0.3905, -0.3184,  0.3226, -0.4356,  0.3759, -0.2887,  0.2277,\n        -0.4938,  0.3111, -0.0172,  0.3766,  0.3298,  0.3606, -0.2939,  0.2581,\n         0.0993,  0.3365, -0.1031, -0.1453,  0.2812, -0.4781,  0.4312, -0.3871,\n        -0.3865,  0.4090,  0.0550,  0.4060, -0.4014,  0.1968, -0.0704,  0.0931,\n         0.2417, -0.4376, -0.3782, -0.0060,  0.4483,  0.2144,  0.2118, -0.1602],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.4290, -0.1058,  0.4743, -0.1028],\n        [ 0.2531, -0.4780,  0.1732, -0.4999],\n        [ 0.0339,  0.0157,  0.2901, -0.2286],\n        ...,\n        [-0.0745, -0.1397, -0.1894,  0.4891],\n        [-0.0853, -0.2386,  0.3482,  0.0950],\n        [ 0.2819,  0.4207,  0.3679, -0.3548]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 6.0913e-02, -3.4626e-02,  4.4969e-02, -2.3780e-02,  3.5794e-02,\n        -5.5496e-02,  2.1002e-02,  5.9911e-02, -9.2531e-03, -4.9601e-02,\n        -6.0456e-02, -2.7516e-02, -5.7320e-02, -5.7427e-02, -2.9750e-02,\n        -6.0037e-03, -3.9257e-02, -2.7400e-02, -7.5555e-03, -8.1710e-03,\n         3.6639e-02, -3.0473e-02, -4.1667e-02, -5.1269e-02,  4.2324e-02,\n         1.2772e-02, -3.1106e-03, -4.4313e-02, -1.4366e-02,  2.8707e-05,\n         4.9017e-02, -2.4572e-02,  5.9941e-02, -3.1341e-02,  4.5435e-02,\n         3.9680e-03,  3.6046e-02, -5.2321e-02,  1.4783e-02, -1.3904e-02,\n        -2.4301e-02,  2.8245e-02, -6.0579e-02, -1.6902e-02, -5.3758e-02,\n        -5.2327e-02, -5.5550e-03, -4.5158e-02,  3.3012e-02, -4.6085e-02,\n        -1.1712e-02,  8.2660e-03,  7.2619e-03,  5.7591e-02, -4.5676e-02,\n        -4.6310e-02,  3.8462e-02,  2.1397e-02, -4.9478e-02,  2.8170e-02,\n        -1.4347e-02, -4.0269e-02,  3.9209e-02, -4.0345e-05,  3.4664e-02,\n        -2.8357e-02, -5.0968e-02,  6.2614e-03, -4.3510e-02, -3.3587e-02,\n         4.0547e-02, -3.0356e-02,  4.2414e-02, -7.9272e-03,  3.1174e-02,\n         4.9423e-02, -4.0581e-02, -4.0482e-02,  2.9091e-02,  5.0387e-02,\n         1.2945e-03,  2.2616e-02,  1.5659e-02, -4.1182e-02, -3.4933e-02,\n         4.7361e-03,  5.3783e-02,  4.5305e-02, -3.8264e-02, -6.0913e-02,\n         6.0611e-02, -5.4911e-02, -3.5395e-02,  5.6411e-02, -3.8706e-02,\n        -1.8125e-02, -2.5594e-03, -4.7945e-02, -3.3631e-02, -3.5977e-02,\n         2.4727e-02,  2.5808e-02,  5.9960e-02, -3.3034e-02,  5.9527e-02,\n        -1.3264e-02, -5.0596e-02, -4.8315e-03, -6.6214e-03, -3.6731e-02,\n         1.5343e-02, -3.1068e-02, -7.0883e-03,  5.1601e-03,  3.2882e-02,\n         2.6287e-02, -2.8058e-03, -1.5868e-02, -1.6833e-02,  2.5641e-02,\n         7.3576e-03,  5.6714e-02,  2.0377e-02,  3.4872e-02,  1.5106e-02,\n         5.9687e-02,  1.3695e-02,  2.3007e-02,  1.0371e-02,  3.7556e-02,\n        -2.8821e-02,  4.9481e-03, -3.0349e-02,  1.8002e-02, -6.0813e-03,\n        -9.2954e-03,  4.4846e-02, -5.2925e-02,  2.1532e-02, -2.2245e-02,\n        -5.5667e-02,  9.6197e-03,  9.1972e-03,  5.9052e-02, -4.6993e-02,\n        -5.1885e-02,  2.0214e-02,  5.5119e-02,  2.1642e-02, -5.5193e-02,\n        -5.9041e-02, -1.1775e-02,  3.3470e-02, -3.8805e-02, -5.8032e-03,\n         3.9051e-02,  1.9301e-02, -4.0188e-02,  1.6646e-02, -5.4245e-02,\n         1.5857e-02, -3.9512e-02,  5.5565e-02, -2.2895e-02,  1.3024e-02,\n         2.5005e-02,  5.8054e-04, -8.7451e-03,  3.2832e-02, -3.0688e-02,\n        -1.4325e-02,  5.2305e-02,  5.9901e-02, -5.1228e-02, -3.4108e-02,\n        -5.6050e-03, -1.6375e-02,  3.8231e-03,  9.1362e-03, -5.6739e-02,\n        -2.3406e-02, -5.8379e-02, -3.0658e-04, -3.0870e-02,  1.2085e-02,\n         2.8206e-02,  6.2357e-02,  1.1117e-02,  2.9934e-02,  5.2959e-02,\n         1.7304e-03, -1.3512e-02, -3.4765e-02, -2.5731e-02, -4.8099e-02,\n        -4.6679e-03,  4.1993e-02, -1.0396e-02, -6.9333e-03,  2.6476e-02,\n         1.3559e-02, -1.1189e-02, -4.2326e-02,  3.8801e-02,  4.9281e-02,\n         1.7189e-02, -4.2487e-02,  3.4443e-02, -5.1766e-03,  5.4068e-02,\n        -2.9003e-02,  5.4127e-02,  3.5559e-02, -5.3971e-02,  8.2017e-03,\n         2.9802e-02,  3.6643e-02, -1.9452e-02, -2.1991e-02,  2.3713e-02,\n        -6.1883e-02, -8.7566e-03, -4.1851e-02,  6.8833e-03,  2.9856e-02,\n         4.3381e-02,  4.1761e-02,  2.9507e-02, -4.3322e-04, -3.8456e-02,\n         1.0690e-02, -3.3456e-02,  2.3969e-02,  4.8107e-02,  1.3027e-02,\n         2.5272e-02, -5.8870e-02,  2.8631e-02, -6.9940e-03, -1.7893e-02,\n        -4.0558e-02, -3.4221e-02, -6.1249e-02,  4.9052e-02, -4.0314e-03,\n         5.7556e-02, -1.7077e-03,  3.9282e-02, -2.1724e-02, -5.9710e-02,\n        -4.4200e-04, -6.1539e-03, -5.9075e-02, -1.7899e-02,  1.4553e-02,\n        -2.0001e-02], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0567,  0.0051, -0.0064,  ..., -0.0003, -0.0510, -0.0299],\n        [-0.0563,  0.0271, -0.0128,  ..., -0.0542, -0.0206,  0.0111],\n        [ 0.0124, -0.0209, -0.0301,  ...,  0.0117, -0.0340,  0.0066],\n        ...,\n        [-0.0330, -0.0120,  0.0465,  ...,  0.0598, -0.0344,  0.0237],\n        [ 0.0014, -0.0141,  0.0435,  ..., -0.0568, -0.0229, -0.0330],\n        [-0.0034, -0.0281,  0.0468,  ..., -0.0276, -0.0483,  0.0426]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0578,  0.0395], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0097, -0.0180, -0.0193,  0.0276,  0.0150,  0.0457, -0.0304, -0.0543,\n          0.0339,  0.0306, -0.0527, -0.0610,  0.0604, -0.0020, -0.0395,  0.0295,\n         -0.0074, -0.0542, -0.0490, -0.0233, -0.0513,  0.0517,  0.0422, -0.0301,\n         -0.0111, -0.0369,  0.0204, -0.0130,  0.0563, -0.0196,  0.0558,  0.0038,\n          0.0536, -0.0493,  0.0275, -0.0129,  0.0124,  0.0218, -0.0144, -0.0267,\n         -0.0530, -0.0317,  0.0541, -0.0318,  0.0502, -0.0553,  0.0303, -0.0120,\n         -0.0409, -0.0311, -0.0206, -0.0012, -0.0013, -0.0329, -0.0563,  0.0579,\n         -0.0265,  0.0165, -0.0450, -0.0062,  0.0057, -0.0381, -0.0189, -0.0248,\n         -0.0560, -0.0132,  0.0254, -0.0490, -0.0148,  0.0074,  0.0132,  0.0539,\n          0.0464, -0.0539,  0.0198,  0.0003,  0.0498,  0.0624, -0.0100,  0.0309,\n          0.0391,  0.0028, -0.0386,  0.0359, -0.0402,  0.0452, -0.0277,  0.0382,\n          0.0495, -0.0307,  0.0220,  0.0304,  0.0414,  0.0463,  0.0539, -0.0007,\n         -0.0623,  0.0029, -0.0290,  0.0392, -0.0221,  0.0302,  0.0516,  0.0022,\n          0.0543, -0.0157,  0.0476, -0.0596,  0.0559,  0.0427, -0.0319,  0.0303,\n         -0.0603,  0.0138,  0.0278, -0.0140, -0.0245,  0.0472, -0.0427,  0.0367,\n          0.0459, -0.0367,  0.0120, -0.0333, -0.0031,  0.0121,  0.0440,  0.0077,\n         -0.0566, -0.0380, -0.0542,  0.0166,  0.0427,  0.0250, -0.0350, -0.0134,\n         -0.0412, -0.0462, -0.0552, -0.0035, -0.0155,  0.0398,  0.0496, -0.0016,\n          0.0102, -0.0180, -0.0356,  0.0152,  0.0379,  0.0099,  0.0399,  0.0238,\n          0.0005, -0.0192,  0.0011, -0.0348,  0.0603, -0.0023,  0.0582, -0.0538,\n         -0.0623, -0.0009,  0.0118, -0.0131, -0.0516, -0.0007,  0.0151,  0.0625,\n         -0.0136,  0.0450, -0.0016, -0.0444,  0.0274,  0.0344,  0.0425,  0.0283,\n          0.0535,  0.0454,  0.0272, -0.0554, -0.0521, -0.0138,  0.0553,  0.0157,\n          0.0121,  0.0077,  0.0264,  0.0361, -0.0369, -0.0249, -0.0466, -0.0211,\n         -0.0456, -0.0439, -0.0087,  0.0403,  0.0021,  0.0238, -0.0187,  0.0368,\n         -0.0160, -0.0182, -0.0161, -0.0200,  0.0107, -0.0032, -0.0607, -0.0015,\n          0.0275,  0.0575,  0.0514, -0.0603, -0.0017, -0.0071, -0.0419, -0.0336,\n          0.0214, -0.0587,  0.0587,  0.0479,  0.0268,  0.0223, -0.0119, -0.0486,\n          0.0540, -0.0399, -0.0296, -0.0006,  0.0392,  0.0533,  0.0137, -0.0512,\n          0.0429, -0.0162, -0.0120,  0.0593, -0.0094, -0.0129,  0.0365,  0.0167,\n         -0.0409, -0.0079, -0.0026, -0.0430,  0.0004, -0.0503,  0.0138, -0.0325,\n         -0.0459, -0.0076,  0.0494, -0.0126,  0.0471,  0.0007, -0.0414,  0.0195],\n        [ 0.0266,  0.0261, -0.0105, -0.0487,  0.0470,  0.0283,  0.0126, -0.0094,\n         -0.0508, -0.0049,  0.0287,  0.0504,  0.0450, -0.0105, -0.0545, -0.0489,\n         -0.0344, -0.0096, -0.0605,  0.0402, -0.0377, -0.0381,  0.0121, -0.0483,\n          0.0488, -0.0099,  0.0103,  0.0483, -0.0092,  0.0234, -0.0314,  0.0304,\n          0.0383,  0.0102, -0.0239,  0.0310, -0.0168,  0.0112, -0.0588, -0.0012,\n         -0.0286,  0.0283,  0.0576,  0.0480, -0.0048, -0.0377,  0.0076, -0.0466,\n         -0.0458,  0.0099, -0.0591, -0.0210,  0.0232, -0.0131,  0.0609, -0.0518,\n          0.0563, -0.0322,  0.0002, -0.0215, -0.0397, -0.0450, -0.0260,  0.0021,\n         -0.0460, -0.0176,  0.0493, -0.0358, -0.0434,  0.0301,  0.0264,  0.0021,\n          0.0281,  0.0548, -0.0301, -0.0217,  0.0387,  0.0079, -0.0196,  0.0197,\n         -0.0163, -0.0258, -0.0513,  0.0070,  0.0537, -0.0377,  0.0539,  0.0522,\n          0.0050,  0.0509, -0.0123,  0.0248,  0.0171, -0.0204, -0.0242, -0.0303,\n         -0.0170,  0.0387,  0.0028,  0.0200, -0.0250,  0.0215, -0.0449, -0.0027,\n         -0.0404,  0.0450, -0.0230, -0.0591, -0.0236,  0.0290,  0.0045,  0.0227,\n         -0.0586, -0.0209, -0.0504, -0.0212, -0.0517, -0.0504,  0.0514, -0.0094,\n          0.0506,  0.0316,  0.0348, -0.0592, -0.0244, -0.0583, -0.0315, -0.0445,\n         -0.0598,  0.0263,  0.0538,  0.0556,  0.0278,  0.0314,  0.0053,  0.0617,\n          0.0276,  0.0283,  0.0509,  0.0237,  0.0131, -0.0198, -0.0269,  0.0315,\n          0.0317, -0.0503, -0.0316,  0.0102,  0.0063,  0.0219, -0.0541, -0.0508,\n         -0.0113,  0.0156,  0.0264, -0.0066,  0.0528,  0.0074,  0.0048,  0.0267,\n         -0.0511,  0.0098,  0.0185, -0.0205, -0.0293, -0.0540,  0.0600,  0.0180,\n         -0.0308, -0.0355,  0.0396, -0.0054, -0.0078, -0.0616,  0.0038, -0.0041,\n         -0.0009, -0.0119, -0.0543,  0.0283,  0.0422, -0.0311, -0.0058,  0.0623,\n         -0.0364,  0.0423, -0.0254,  0.0411,  0.0240, -0.0333,  0.0143,  0.0423,\n         -0.0428, -0.0020,  0.0297,  0.0350,  0.0345,  0.0041, -0.0504, -0.0514,\n         -0.0462, -0.0198, -0.0298, -0.0028,  0.0249, -0.0021, -0.0573, -0.0166,\n         -0.0524,  0.0327,  0.0228,  0.0624, -0.0057, -0.0142, -0.0514, -0.0237,\n         -0.0069, -0.0553, -0.0339,  0.0106,  0.0453,  0.0454, -0.0366, -0.0160,\n         -0.0307,  0.0601,  0.0432,  0.0197,  0.0312, -0.0426, -0.0610,  0.0426,\n         -0.0284, -0.0442,  0.0612,  0.0093,  0.0021, -0.0188,  0.0071,  0.0080,\n         -0.0096,  0.0140,  0.0135, -0.0257,  0.0312,  0.0105,  0.0101, -0.0056,\n         -0.0389, -0.0294,  0.0448,  0.0559, -0.0542, -0.0520,  0.0392,  0.0516]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "act_dim":	2,
                                "obs_dim":	4,
                                "training":	true
                            }
                        },
                        "q1":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-1.9962e-01,  1.2976e-01,  2.7294e-01, -5.7560e-02,  4.3497e-01,\n         2.3543e-01,  3.6013e-02,  5.3409e-02, -3.3610e-01, -3.6582e-01,\n         4.3450e-01,  4.7132e-01,  1.4130e-02, -1.9506e-02, -1.8033e-01,\n         3.7473e-01, -2.3706e-01, -6.9214e-02,  3.4421e-01, -1.7500e-01,\n         6.3653e-02, -4.7311e-01,  1.9863e-01,  3.3056e-01, -2.8121e-01,\n        -2.0563e-01,  3.4080e-01,  1.9393e-01,  3.2922e-01,  2.2447e-01,\n         2.4548e-01, -1.3538e-01,  1.0371e-01, -2.3775e-01, -3.8911e-01,\n        -3.2659e-01,  4.4025e-01, -1.2251e-01, -4.2622e-01,  3.2950e-01,\n        -2.8402e-01,  1.0951e-01, -4.7868e-01,  1.6723e-01,  2.7159e-01,\n        -4.6678e-01,  3.9085e-01, -1.0209e-01,  4.1880e-01, -1.7394e-01,\n        -2.4641e-01, -3.8244e-01, -4.3572e-01,  1.0206e-01, -3.6070e-01,\n        -1.1019e-01,  3.5549e-02,  6.9859e-03, -2.5251e-01,  9.6788e-02,\n        -2.0265e-01, -4.0044e-01, -1.5973e-01,  4.8261e-01, -1.2343e-01,\n         3.2452e-01,  2.7381e-02, -3.5123e-01, -3.5580e-02, -3.0196e-02,\n         3.9375e-01, -3.5212e-02,  3.4686e-02, -8.7625e-03, -4.6724e-01,\n         6.3440e-02,  2.8392e-01, -2.9722e-01,  4.8024e-01, -9.0158e-04,\n         1.5095e-01,  4.4028e-01, -3.3151e-01,  2.0686e-02, -3.1721e-01,\n         1.5876e-01, -3.0394e-01,  6.5505e-02,  1.6096e-02, -1.5596e-01,\n        -6.6804e-02,  1.3482e-01, -4.4710e-01,  3.9394e-01, -1.2698e-01,\n         1.8031e-01,  4.6012e-01,  2.1281e-01,  2.4823e-01, -3.0084e-01,\n         2.2770e-01,  4.9406e-01,  4.3865e-01, -4.7583e-01,  2.5661e-01,\n        -5.0738e-02, -2.8174e-01, -9.4003e-02,  2.1648e-01, -2.6443e-01,\n         2.2057e-01,  3.2453e-01,  1.5271e-01,  4.1228e-01, -3.8116e-02,\n         2.9939e-03, -4.6855e-01,  4.8571e-01,  3.9091e-01, -4.4468e-01,\n         2.4410e-01, -2.9081e-02, -2.4988e-01, -3.7520e-01, -4.3670e-01,\n        -2.6576e-01,  2.4013e-01, -1.8935e-01, -4.5507e-01,  3.1774e-01,\n         3.7077e-01, -3.0619e-01, -3.6326e-02, -2.0766e-01, -2.2440e-01,\n         3.7366e-01,  2.5821e-03,  2.6856e-01,  4.8135e-01,  4.3445e-01,\n         3.9880e-03,  2.0563e-01,  2.5620e-01, -2.0266e-01, -4.2443e-01,\n         4.4976e-01,  4.3077e-01, -2.6392e-01, -4.4410e-01,  4.0813e-01,\n         2.9686e-01,  1.0877e-01, -2.1348e-01,  1.1285e-01,  4.4605e-01,\n        -5.4893e-02, -1.8589e-02,  1.7188e-01, -4.2742e-01,  2.4292e-01,\n         1.2697e-01, -2.1291e-01, -3.5114e-01, -2.8034e-01, -3.3928e-01,\n         6.1714e-02, -2.1038e-01,  1.0554e-01, -5.6190e-02,  4.3339e-02,\n         4.7976e-02,  2.2437e-01,  3.8838e-01,  2.1905e-01, -1.8607e-01,\n         4.9909e-02, -4.2789e-01,  4.1267e-01,  1.9608e-01,  3.0970e-02,\n        -1.7694e-01,  4.2423e-01, -3.7706e-01,  7.4076e-02, -2.0542e-01,\n         3.5590e-01, -1.8422e-01, -1.7219e-01,  4.1969e-01,  1.6671e-01,\n        -4.1719e-01,  4.7291e-01, -1.6880e-01,  2.4419e-01, -2.1781e-01,\n         4.3933e-01,  1.0093e-01,  3.7270e-01,  4.9201e-01, -1.4436e-01,\n         2.8692e-01,  1.7837e-01, -1.4133e-01, -4.0764e-01,  5.2528e-02,\n        -2.5284e-01,  2.7737e-01,  4.9643e-01,  5.9057e-02, -2.7105e-01,\n        -4.4060e-02,  6.0942e-03,  7.2555e-02, -9.1431e-02, -1.5090e-01,\n        -2.1872e-01, -4.1075e-01,  3.8461e-01, -4.5157e-03, -4.9067e-01,\n         4.6612e-01,  2.5406e-01,  4.2418e-01, -4.0354e-01, -4.8299e-01,\n         2.2403e-01, -2.1654e-02,  3.3083e-01, -4.7570e-01, -4.1944e-01,\n        -7.7381e-02, -1.5930e-01,  4.7680e-01, -4.0373e-01, -3.9075e-01,\n        -2.8293e-01,  3.7644e-01, -7.9051e-03, -1.9506e-01, -3.2510e-01,\n        -4.7790e-01, -2.1574e-01,  4.6893e-01, -1.5588e-01,  4.5955e-05,\n         8.2703e-02,  4.3051e-01, -1.1578e-01,  2.7984e-01,  3.7855e-01,\n         4.8422e-01,  3.8446e-01,  1.3210e-01, -3.4336e-01,  8.0217e-02,\n         3.3007e-01], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.3650,  0.1926,  0.3665, -0.4551],\n        [-0.4671,  0.0869, -0.1379, -0.4116],\n        [-0.0655,  0.3748, -0.2167, -0.2616],\n        ...,\n        [ 0.1532,  0.1845,  0.2320,  0.1809],\n        [-0.3210,  0.0358, -0.2053, -0.0046],\n        [ 0.1897, -0.4997,  0.0539, -0.3697]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-2.2604e-02,  3.1567e-02, -4.7032e-02, -1.3071e-02, -3.1565e-02,\n         5.1928e-02,  1.1242e-03, -1.0280e-02,  4.1787e-02, -3.4881e-02,\n         4.8470e-02,  3.3419e-02, -3.1485e-03,  3.7777e-02, -5.9138e-02,\n        -4.0488e-02,  3.6577e-02,  4.9368e-02, -2.1430e-02, -1.2739e-02,\n         6.4866e-03,  5.4008e-03,  2.4772e-02,  2.6358e-02, -3.4074e-02,\n        -4.1407e-02, -5.9629e-02, -5.8664e-02,  3.4731e-02,  8.8219e-03,\n         1.5506e-02,  4.8163e-02,  2.5956e-02,  5.4496e-02,  2.7068e-02,\n        -4.0188e-02, -4.5402e-03, -5.5804e-02,  7.0584e-03,  2.3410e-02,\n        -4.8404e-02, -4.0739e-02,  2.2476e-03, -2.3985e-02, -4.0246e-02,\n        -1.4682e-02,  4.1274e-03, -4.6117e-02, -6.8751e-04,  6.2484e-02,\n        -5.2852e-02,  9.7730e-03,  4.8335e-02, -4.0360e-02,  6.6055e-03,\n         1.4531e-02,  5.9382e-02, -3.2185e-03,  3.2042e-02,  2.0246e-02,\n         9.9710e-03,  2.9443e-02, -6.0054e-02,  5.6436e-02,  4.7874e-02,\n         2.1782e-02,  2.4294e-02,  6.6594e-03, -8.4765e-03, -1.5208e-02,\n        -5.6865e-02,  3.8000e-02, -6.0692e-03,  4.2630e-02, -5.7178e-02,\n         4.6558e-02, -9.2130e-03, -2.9130e-02,  3.7176e-02, -2.6513e-02,\n        -3.1311e-02, -1.3649e-02, -4.9194e-03, -2.5279e-02,  1.3388e-03,\n        -1.3581e-02, -2.1734e-02, -2.3988e-02, -3.9658e-02,  3.9210e-02,\n         1.1916e-02,  4.0918e-02,  5.2344e-02, -9.3701e-03,  1.5082e-02,\n        -4.8007e-02,  5.8493e-02, -3.6079e-02,  5.0136e-02,  4.3922e-02,\n        -2.8601e-02,  3.5702e-03, -2.1551e-02,  2.3366e-02, -5.2549e-02,\n        -1.2403e-02,  8.4423e-05, -2.8221e-02,  2.1658e-03, -3.5255e-02,\n         8.0655e-03,  1.5776e-02,  3.0857e-02,  5.1387e-02, -2.6135e-02,\n         4.0753e-02,  4.9788e-02,  4.9571e-02,  5.2945e-02,  3.9130e-02,\n        -3.3891e-02, -4.1595e-02, -2.8531e-02, -5.4222e-03,  1.1716e-02,\n         3.4571e-02,  4.8683e-02,  4.3623e-02,  2.7669e-03,  9.6493e-03,\n         3.5790e-02,  1.0275e-02,  4.4709e-02, -5.4412e-02,  4.9899e-02,\n        -1.5718e-02,  4.1906e-03,  5.6973e-02, -3.0233e-03,  2.1672e-02,\n         3.8345e-02,  2.7300e-02,  4.9417e-03,  5.5755e-02, -2.9071e-02,\n        -4.7819e-02,  1.3359e-03,  4.3200e-02,  4.1314e-02, -6.2012e-02,\n         8.3524e-03,  2.5685e-02,  5.7996e-03, -4.9345e-02, -2.9467e-03,\n        -5.9417e-02,  4.6109e-02,  1.8613e-02, -5.0013e-03, -4.5992e-02,\n         4.6029e-02,  1.2358e-02,  2.4165e-02, -5.2408e-02,  2.6222e-02,\n        -4.5874e-02,  1.2107e-03,  2.3497e-02, -2.3079e-02,  3.1804e-02,\n         3.7814e-02, -2.8218e-02, -1.7235e-02,  4.2929e-02,  5.4327e-02,\n         3.4098e-02, -6.1104e-02,  1.6557e-02, -1.2751e-02, -4.7365e-02,\n         5.5777e-02,  4.7833e-05,  2.6629e-02, -5.4816e-02, -3.2067e-02,\n        -5.0143e-02,  3.2576e-03,  4.4309e-02,  4.1694e-02,  4.0892e-02,\n        -5.8621e-02,  6.0942e-02, -5.1636e-02,  5.0797e-02, -2.7219e-02,\n        -1.3578e-02,  5.2339e-02, -9.9539e-04,  5.8648e-02,  6.0967e-02,\n        -4.9219e-02, -4.0899e-02, -1.3053e-02,  3.2349e-02, -2.4511e-02,\n        -5.9191e-02, -3.9231e-02,  7.6393e-04, -1.0076e-02,  8.2299e-03,\n        -1.2487e-02,  5.2082e-02,  6.1497e-02, -6.0370e-02,  5.9855e-02,\n         8.8103e-03, -1.7743e-03, -6.3060e-03,  8.3604e-03, -5.1302e-02,\n        -7.1222e-04,  4.1206e-03,  2.7157e-02, -5.2260e-02, -4.9903e-02,\n         4.8954e-02, -1.0563e-02, -5.4621e-02, -4.4943e-02, -5.9938e-02,\n        -5.6685e-02,  5.3392e-02,  1.5170e-02,  1.8297e-02,  1.4722e-02,\n        -4.1134e-02, -3.2979e-02,  3.6884e-02,  1.2875e-02,  2.8458e-02,\n         2.6316e-02, -2.7398e-02, -5.8625e-02,  5.4713e-02,  3.5349e-02,\n        -4.4725e-02,  3.6600e-02, -4.2638e-02,  2.6515e-03,  6.2422e-02,\n        -9.3373e-03,  6.9790e-03,  6.1502e-02, -4.2043e-02, -2.3079e-02,\n         6.1346e-02], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0183, -0.0330,  0.0475,  ..., -0.0102,  0.0508, -0.0552],\n        [ 0.0230,  0.0404, -0.0175,  ...,  0.0610, -0.0133,  0.0342],\n        [-0.0116,  0.0319, -0.0504,  ...,  0.0063, -0.0390,  0.0021],\n        ...,\n        [-0.0481, -0.0069, -0.0012,  ...,  0.0447, -0.0473,  0.0456],\n        [-0.0011, -0.0501,  0.0077,  ...,  0.0340,  0.0290,  0.0382],\n        [-0.0072, -0.0250,  0.0189,  ..., -0.0423, -0.0489, -0.0230]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0339, -0.0256], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-5.1386e-03, -3.6500e-02, -4.5660e-02, -5.7929e-02,  5.7241e-02,\n         -1.4348e-02,  5.8078e-02,  1.3565e-02, -4.4403e-02,  5.0631e-02,\n          3.3267e-02,  2.0705e-02,  5.1059e-02, -3.1209e-02,  2.6400e-03,\n         -4.5928e-02, -4.5103e-02,  2.4290e-02, -1.6746e-02,  4.4139e-02,\n         -1.7876e-02,  3.2466e-02,  3.8775e-02,  4.3882e-02,  4.9926e-02,\n          2.5948e-02,  1.1067e-02, -5.2174e-02,  4.9200e-02,  4.4737e-02,\n         -2.5652e-02, -3.2573e-02, -2.3861e-03,  2.7533e-02,  4.5714e-02,\n          5.9700e-02, -5.8999e-02, -4.8578e-02, -3.3012e-02, -4.0647e-02,\n          2.4606e-02,  2.8370e-02, -4.0493e-02, -4.8130e-02, -5.6823e-03,\n          2.2402e-02,  5.3185e-02,  6.7808e-03,  6.0597e-02, -4.1758e-02,\n          1.5805e-02, -1.5054e-02,  4.2120e-02, -2.7022e-02,  5.8519e-02,\n          6.0667e-02,  4.8642e-02, -3.0237e-02, -2.1638e-02, -1.7833e-02,\n          2.3787e-02, -4.1359e-02, -4.3630e-02, -3.7798e-02,  2.0184e-02,\n         -2.8839e-02, -3.1096e-02,  1.9031e-02,  2.4672e-02,  2.5068e-02,\n         -4.9902e-02, -2.3427e-02,  3.6031e-02, -2.3276e-02,  5.5070e-02,\n          4.8558e-02, -2.7940e-02,  2.1498e-02, -4.1303e-02,  3.4286e-02,\n          5.3664e-02,  4.4376e-02,  5.0474e-03, -1.9207e-02,  2.9926e-02,\n         -5.5592e-02,  2.6029e-02, -1.0144e-02,  9.1866e-06,  3.6897e-02,\n         -1.6283e-02,  2.8397e-02,  4.6940e-02,  4.4245e-02,  6.1046e-02,\n          5.8959e-02,  3.3180e-02, -3.5616e-02,  9.6771e-03, -2.7611e-02,\n         -6.2753e-03, -3.9665e-02, -4.3359e-02, -4.2270e-02, -4.3682e-02,\n          3.2047e-02,  1.7213e-03,  2.1672e-02,  4.9777e-02, -1.8996e-02,\n          1.8557e-03,  2.3308e-02,  1.7778e-02,  5.3154e-02, -2.2372e-02,\n          3.5463e-02, -1.9317e-03, -1.2226e-02, -1.4400e-02, -6.0124e-03,\n         -1.3936e-02,  4.1061e-02,  5.1002e-02, -1.2609e-02,  1.4679e-02,\n          3.3463e-02,  4.1305e-02, -3.4433e-02,  4.8141e-02, -2.2699e-02,\n         -4.3505e-02,  5.4451e-02, -1.0238e-02, -5.7694e-02, -1.2353e-02,\n         -4.3291e-02,  2.8926e-02,  3.1781e-02, -3.0289e-02,  5.8222e-02,\n         -5.8108e-02, -1.0935e-02, -5.1726e-02,  2.2265e-02, -2.0251e-02,\n          8.5905e-03,  4.4099e-03, -1.6824e-02,  6.7532e-03,  4.8639e-02,\n         -1.1607e-02,  2.0699e-02, -3.1267e-02,  3.8250e-02, -4.6874e-02,\n          6.0836e-02,  9.4357e-03, -3.9092e-02, -2.3922e-02,  5.0376e-02,\n         -4.1962e-02,  2.1529e-02,  1.0412e-02,  1.6689e-02,  4.6943e-02,\n         -2.8955e-02,  1.1092e-02,  4.0190e-02, -6.1299e-02,  4.1534e-03,\n          4.2600e-02,  1.3020e-02, -3.6156e-02, -2.3985e-02, -5.2355e-02,\n          4.3914e-04,  2.6606e-02, -2.7612e-02,  2.1861e-02,  4.8673e-03,\n         -4.5080e-02,  3.2328e-02, -2.7480e-02, -1.4795e-03, -2.8557e-02,\n          3.3459e-02,  8.8954e-03, -6.0928e-02, -1.4938e-04,  3.9835e-03,\n         -4.0394e-02,  1.5224e-02, -4.8976e-02, -9.0517e-03,  3.5259e-02,\n         -4.4643e-02, -4.4473e-02,  3.3178e-02, -2.0099e-02, -7.1318e-03,\n          7.3179e-03, -5.6166e-03,  4.8161e-02,  1.8558e-02, -2.1767e-02,\n         -7.0796e-03, -2.8087e-02,  6.0145e-02, -3.5429e-02, -4.6039e-02,\n         -2.4594e-02, -4.9719e-02, -2.5513e-02,  2.8310e-02, -3.1527e-02,\n         -3.1042e-02,  1.5367e-02, -1.5218e-02, -4.2219e-02,  3.4638e-03,\n         -6.1562e-02,  1.8113e-02,  2.7047e-02, -6.0515e-02, -1.9570e-04,\n          4.1359e-02,  1.4679e-02, -3.2822e-02, -2.3895e-02, -3.7231e-02,\n         -4.6841e-02,  5.4524e-02,  2.1658e-02, -2.6191e-02, -5.0055e-02,\n          3.3266e-02, -4.4339e-02,  6.2350e-03, -5.2591e-02, -2.8909e-03,\n          5.7354e-02, -3.2398e-02, -6.1121e-02,  2.1703e-02,  1.3556e-02,\n          4.6202e-02, -4.0231e-02,  3.3896e-04, -2.7437e-02,  1.8636e-02,\n         -4.5120e-02, -1.5158e-02, -4.2555e-02,  8.8862e-03, -2.6450e-02,\n          4.1052e-02],\n        [ 5.7454e-02,  4.5058e-02, -2.8317e-02,  9.6026e-03, -3.3439e-02,\n         -2.1535e-02,  6.1609e-03, -6.4634e-03,  4.8397e-02, -8.0976e-04,\n          2.9914e-02, -5.8263e-02,  4.5082e-02, -2.9109e-02, -3.0090e-02,\n         -6.2373e-02, -6.2219e-02,  4.8708e-03, -3.6894e-02,  2.0139e-02,\n          5.9661e-02,  2.2438e-02, -6.0632e-02, -4.7058e-02,  2.8859e-02,\n         -4.8921e-02, -5.3941e-02,  1.0461e-02, -1.4912e-03,  4.7038e-02,\n          4.9554e-02, -2.5301e-02, -1.7063e-02, -1.2578e-02,  3.3010e-02,\n          1.4477e-02,  3.8827e-02, -2.4149e-02, -5.1312e-02, -3.3827e-02,\n         -5.8316e-02, -4.6354e-02, -5.2413e-02,  4.2478e-02,  1.3623e-02,\n          5.2481e-02,  3.1054e-03, -2.7862e-02,  1.0981e-02,  1.6863e-02,\n         -1.1249e-02, -1.3443e-02, -3.1842e-02, -3.0497e-02,  1.2903e-03,\n         -1.8698e-02,  2.3219e-02, -1.3956e-02,  3.4970e-02, -1.2143e-02,\n          2.8276e-02,  3.1505e-03,  4.3355e-02, -1.3152e-02,  2.8764e-02,\n          1.8895e-02,  5.9398e-02,  2.3092e-02,  5.5753e-02, -2.3797e-02,\n          1.2399e-02,  3.0812e-02,  2.3646e-02, -1.7164e-03, -2.3159e-02,\n         -2.1681e-02, -4.8665e-02,  9.4970e-03,  1.0137e-02,  2.0323e-02,\n          4.8283e-02,  3.3770e-03, -4.7562e-02,  5.1089e-02, -8.3045e-03,\n          1.8764e-02, -5.0342e-02, -4.8200e-03, -2.6801e-02, -2.9844e-03,\n         -2.7471e-02,  3.0838e-02, -2.5140e-02, -3.1490e-03, -5.0561e-02,\n          5.0871e-03, -2.4195e-02, -3.8189e-02,  5.0358e-05,  5.0408e-02,\n         -1.9806e-02, -7.6828e-03,  2.5709e-02,  5.2703e-02,  5.3084e-02,\n          7.4778e-04,  1.1595e-02, -5.5334e-02, -1.7039e-02,  5.8033e-02,\n          4.6508e-02, -4.8204e-02, -5.1268e-02, -3.9107e-02,  1.9972e-02,\n          2.9479e-02, -4.3707e-02,  1.0844e-03,  9.5288e-03,  3.3115e-02,\n          2.9815e-02,  5.1017e-02, -6.0316e-02, -2.2462e-02,  2.4875e-02,\n          1.7425e-03, -1.3190e-02, -1.1203e-02,  4.6913e-02, -8.9444e-03,\n          1.8103e-02,  8.7861e-03, -4.5732e-02, -3.2436e-02,  5.4780e-03,\n          4.6254e-02,  4.4766e-02, -1.4231e-02,  3.3950e-02,  3.8489e-02,\n         -1.9364e-02,  3.9205e-02, -3.0073e-02,  5.1559e-02,  5.0060e-02,\n         -3.8754e-02, -5.5984e-02, -5.7404e-02,  5.0497e-02, -4.8585e-02,\n         -5.7034e-02,  6.3831e-03, -3.6545e-02,  3.1704e-02,  5.4925e-02,\n          6.5841e-03,  3.4278e-02,  4.9688e-03,  5.8060e-02, -3.6803e-02,\n          1.1048e-02, -6.7351e-03,  2.8072e-02, -8.3644e-03,  4.3363e-02,\n          3.2519e-03, -5.1070e-02, -3.0732e-02, -5.6665e-02, -4.3732e-02,\n          2.2879e-02, -6.1774e-02,  3.3243e-02,  9.0315e-03, -4.7999e-02,\n         -2.2573e-02, -5.9884e-02, -1.2378e-02,  5.9045e-02,  2.9512e-02,\n          4.6932e-02,  1.0502e-02,  1.3195e-02,  2.8691e-02, -4.7618e-02,\n          5.3908e-03,  3.6562e-02,  5.5809e-02, -5.4790e-02, -1.4019e-02,\n         -2.9631e-02,  1.0266e-02,  2.2250e-02, -5.2885e-02, -3.9302e-02,\n          1.0473e-02, -1.9716e-02, -3.0295e-02, -6.2168e-02, -2.0362e-02,\n          1.1706e-02, -5.5644e-02,  3.4809e-02,  8.0311e-04,  5.6560e-02,\n         -4.4043e-02, -2.7580e-02,  2.5577e-02,  4.3626e-02,  3.1293e-02,\n         -8.8088e-03, -3.8444e-02,  3.5484e-02,  1.0399e-02,  5.4511e-02,\n         -5.2267e-03,  2.1604e-02,  2.0689e-02,  5.6147e-02,  3.4622e-02,\n         -6.4848e-03, -4.7649e-02, -2.4433e-02, -2.1759e-02, -4.0691e-02,\n          2.2269e-02, -2.5158e-02,  3.8042e-02, -4.2510e-02,  2.7479e-02,\n          5.6316e-03,  4.0246e-03,  1.5221e-03, -9.1264e-03, -3.0843e-02,\n         -1.6612e-02,  1.8427e-02, -4.4932e-02, -1.6035e-02,  3.8048e-02,\n         -8.3792e-03, -5.1971e-02, -5.6108e-02,  1.3894e-02, -5.9453e-02,\n         -5.5200e-02, -5.6137e-03,  1.2901e-02,  3.7651e-02, -5.3007e-02,\n          3.7677e-02,  3.7266e-02, -4.8865e-02, -1.6006e-02,  1.6093e-02,\n          5.7319e-02]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "q2":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=4, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=2, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0290, -0.1145, -0.0660, -0.0373, -0.3267,  0.0126, -0.4886, -0.2750,\n        -0.3283, -0.0967,  0.0219, -0.2301,  0.2991,  0.2299,  0.1215,  0.2964,\n        -0.3071, -0.3243,  0.0457,  0.2193, -0.4251, -0.0467,  0.0990,  0.3500,\n        -0.3833, -0.0221, -0.4643, -0.1733,  0.2285,  0.2291,  0.0031, -0.4485,\n        -0.4698,  0.4632,  0.0316, -0.3789,  0.1312, -0.0713,  0.4102,  0.1044,\n         0.2670, -0.4494, -0.1593,  0.1233, -0.5000,  0.0557, -0.4926, -0.3504,\n         0.2960, -0.1449,  0.2107, -0.2437,  0.2563, -0.1217,  0.2817,  0.0793,\n        -0.2548, -0.4924, -0.2933, -0.1720,  0.0268,  0.0075,  0.4960,  0.0385,\n         0.1497, -0.1715,  0.1861,  0.1153,  0.0072, -0.2398, -0.2796,  0.3501,\n        -0.2943, -0.4778, -0.2045, -0.1804, -0.0870,  0.1673,  0.3141, -0.2550,\n        -0.2367,  0.1137, -0.3174, -0.1768,  0.2714,  0.3668, -0.0391, -0.3422,\n         0.2964, -0.2188,  0.3997,  0.1952,  0.4604,  0.1389, -0.0988,  0.0154,\n        -0.1831, -0.3675,  0.0690, -0.4550,  0.0651, -0.1407, -0.0886, -0.4227,\n         0.2116,  0.4604, -0.1755, -0.1853, -0.3510,  0.0673, -0.3130, -0.1118,\n         0.4197,  0.2596,  0.1203,  0.1568, -0.3339, -0.0598, -0.1860,  0.0378,\n         0.1695,  0.3859,  0.2167, -0.1848,  0.0865, -0.1485, -0.4984, -0.4224,\n         0.4365,  0.3388,  0.0624,  0.3922,  0.2480, -0.1169,  0.0464, -0.1335,\n        -0.2286,  0.0164, -0.4118, -0.3478, -0.3522, -0.2627, -0.3254, -0.1034,\n         0.3458,  0.0475, -0.2511,  0.4250,  0.1684, -0.1452, -0.2503, -0.3781,\n        -0.4330, -0.3379,  0.1563, -0.0775, -0.3200, -0.0937, -0.3742, -0.2946,\n        -0.3419, -0.0227,  0.3673, -0.0395,  0.4269,  0.2444, -0.1320,  0.0528,\n        -0.4629, -0.3743,  0.2453,  0.4376,  0.0904, -0.1283,  0.1650,  0.3082,\n         0.1688, -0.2560,  0.2868, -0.0032, -0.1436, -0.2712, -0.3660,  0.0670,\n         0.0665,  0.4443, -0.3624,  0.0670, -0.3484,  0.0629, -0.4814, -0.0782,\n        -0.0981, -0.3608, -0.4695,  0.2772,  0.1644, -0.3063, -0.1772,  0.1063,\n         0.2820, -0.4574,  0.1419,  0.0131, -0.2264, -0.1254, -0.3272, -0.3202,\n         0.2530, -0.2182,  0.2519,  0.2208, -0.4772,  0.0964,  0.0487, -0.3381,\n        -0.4866,  0.1433,  0.3350,  0.0771, -0.2538,  0.3221, -0.1189,  0.0796,\n        -0.0331,  0.0524,  0.1004, -0.2211, -0.4443, -0.3033, -0.3381,  0.2769,\n        -0.3335,  0.3241, -0.1402, -0.0296, -0.0858, -0.4495,  0.3946, -0.3463,\n        -0.0769,  0.4904, -0.1490, -0.3573,  0.1338, -0.3741,  0.4622, -0.4332,\n         0.2613, -0.0756,  0.1712,  0.4687, -0.1898, -0.3281, -0.2226, -0.1625],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1298, -0.2212, -0.2846,  0.1385],\n        [ 0.2766,  0.1821, -0.4600,  0.1437],\n        [-0.4907,  0.2830,  0.2819,  0.0194],\n        ...,\n        [ 0.2698, -0.0346, -0.2598, -0.1458],\n        [ 0.2572, -0.0251, -0.1817,  0.2091],\n        [ 0.4902,  0.2523, -0.2817, -0.0128]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0180,  0.0571,  0.0068, -0.0161,  0.0036,  0.0566,  0.0062,  0.0115,\n         0.0406,  0.0254, -0.0129, -0.0160,  0.0178,  0.0407,  0.0533,  0.0237,\n         0.0471,  0.0523,  0.0361,  0.0424,  0.0359, -0.0036, -0.0304,  0.0131,\n        -0.0394, -0.0452, -0.0605, -0.0502,  0.0364, -0.0304, -0.0521, -0.0011,\n        -0.0337, -0.0368,  0.0584, -0.0407,  0.0208,  0.0177,  0.0596,  0.0474,\n         0.0509, -0.0625, -0.0621, -0.0268, -0.0623, -0.0172,  0.0607,  0.0171,\n        -0.0305, -0.0203, -0.0474, -0.0219,  0.0005, -0.0617, -0.0067,  0.0114,\n         0.0255, -0.0121, -0.0496, -0.0573,  0.0348, -0.0033,  0.0135,  0.0607,\n         0.0200, -0.0583, -0.0126,  0.0289,  0.0192, -0.0046, -0.0443, -0.0599,\n         0.0528,  0.0366, -0.0612, -0.0187,  0.0112,  0.0592,  0.0524,  0.0537,\n         0.0520, -0.0201, -0.0599,  0.0064,  0.0411, -0.0029, -0.0339, -0.0481,\n        -0.0402, -0.0160,  0.0595,  0.0030,  0.0437, -0.0299,  0.0273,  0.0511,\n        -0.0395,  0.0165,  0.0315, -0.0132,  0.0544, -0.0275,  0.0602, -0.0200,\n        -0.0269, -0.0229,  0.0623, -0.0275,  0.0330,  0.0175, -0.0356, -0.0234,\n        -0.0243, -0.0259,  0.0067, -0.0454, -0.0201,  0.0376, -0.0509, -0.0467,\n        -0.0355,  0.0335, -0.0600, -0.0513, -0.0414, -0.0532, -0.0081, -0.0175,\n         0.0610,  0.0118,  0.0105,  0.0011, -0.0597, -0.0330, -0.0435,  0.0485,\n        -0.0623, -0.0400,  0.0614, -0.0363,  0.0258, -0.0516,  0.0511,  0.0450,\n        -0.0165, -0.0482, -0.0072, -0.0199, -0.0611, -0.0060, -0.0187, -0.0558,\n        -0.0434, -0.0180,  0.0412, -0.0129, -0.0456, -0.0066,  0.0436, -0.0263,\n         0.0566, -0.0327,  0.0300, -0.0443, -0.0008, -0.0486, -0.0476,  0.0225,\n        -0.0333,  0.0495, -0.0441, -0.0563, -0.0379,  0.0114, -0.0322,  0.0435,\n        -0.0446,  0.0322,  0.0589, -0.0338,  0.0161, -0.0387,  0.0426,  0.0599,\n         0.0228, -0.0504,  0.0528, -0.0176,  0.0490, -0.0396,  0.0326,  0.0363,\n        -0.0489,  0.0003,  0.0231, -0.0006,  0.0443, -0.0197, -0.0419,  0.0312,\n        -0.0133, -0.0398, -0.0478, -0.0232, -0.0338, -0.0291,  0.0204,  0.0197,\n         0.0118, -0.0202,  0.0264, -0.0625, -0.0403,  0.0294, -0.0111, -0.0415,\n         0.0347, -0.0541, -0.0285, -0.0039, -0.0373, -0.0104, -0.0010,  0.0565,\n        -0.0145,  0.0020, -0.0295, -0.0320,  0.0459, -0.0353,  0.0484,  0.0083,\n        -0.0183,  0.0029,  0.0448, -0.0398,  0.0560,  0.0298, -0.0464,  0.0342,\n         0.0409,  0.0378, -0.0458, -0.0399, -0.0591, -0.0200, -0.0488,  0.0191,\n         0.0382,  0.0555, -0.0350, -0.0478, -0.0054,  0.0189, -0.0342, -0.0517],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-1.2573e-02, -3.0363e-02,  3.4008e-02,  ...,  8.6647e-03,\n          1.1560e-02, -1.4140e-02],\n        [-3.9068e-02, -2.2558e-02,  5.5355e-03,  ...,  2.0758e-02,\n         -3.2366e-02,  3.4633e-02],\n        [ 1.2757e-02, -2.7424e-02,  2.8040e-02,  ..., -5.8893e-02,\n         -3.1864e-02, -1.3186e-02],\n        ...,\n        [ 2.1602e-02,  1.1588e-02,  4.5458e-03,  ...,  1.2327e-02,\n          4.8816e-02, -3.2194e-02],\n        [-4.3114e-02,  6.0637e-02,  1.1496e-05,  ...,  3.1135e-02,\n         -1.3356e-02, -3.2217e-02],\n        [-2.7925e-02,  2.4817e-03, -5.8972e-02,  ..., -1.5074e-02,\n         -5.7299e-02, -1.9535e-02]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=2, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0513, -0.0575], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-4.5320e-02, -4.3285e-02,  3.9831e-02,  3.5646e-02,  4.3496e-04,\n          4.5331e-02,  5.9911e-02,  3.2141e-04,  2.0202e-02,  3.0322e-02,\n          1.1896e-02,  5.0360e-02, -2.9928e-02,  4.3472e-03, -6.0561e-02,\n          1.5946e-02,  4.9403e-02,  2.9060e-02,  1.6339e-02, -1.0013e-02,\n          4.3396e-02,  4.7619e-02, -4.4034e-02,  4.6203e-02,  5.0311e-02,\n         -5.9997e-02,  5.9593e-02,  7.6818e-03,  1.7997e-02,  2.2810e-02,\n         -3.2233e-02,  4.0730e-02,  3.2331e-02,  1.6433e-02, -2.2317e-03,\n         -3.0240e-02, -5.5449e-02, -4.1709e-02, -1.8044e-02,  3.0528e-02,\n         -4.5471e-02,  9.0617e-03, -3.9050e-02, -1.5672e-02, -4.6976e-02,\n         -1.9595e-02, -4.3725e-02, -4.9003e-02,  6.2764e-03,  9.3671e-03,\n         -2.2823e-02,  1.6382e-02,  2.9085e-02,  3.0590e-03,  4.9841e-02,\n          3.3353e-02, -3.4112e-02, -4.7911e-02, -5.7419e-02, -1.4643e-02,\n         -2.0989e-02,  2.7641e-03,  1.1842e-02, -1.9344e-02,  3.3124e-02,\n          4.2960e-02,  1.6693e-02, -4.5054e-02, -1.5038e-02, -6.8432e-03,\n          5.2325e-03, -1.6878e-02,  3.2655e-02, -4.9473e-02, -3.9289e-02,\n          4.8467e-02, -5.6936e-02,  2.6813e-02, -5.2174e-02, -7.8691e-03,\n          2.4432e-02,  2.9676e-02, -1.3208e-02, -4.4179e-02,  2.5774e-02,\n         -3.1245e-02, -1.2471e-02, -2.8358e-02, -3.8136e-02,  5.7951e-02,\n         -4.4963e-02,  8.2170e-04, -5.6718e-02,  3.0459e-02,  5.3141e-03,\n          4.4787e-02,  5.6498e-02,  3.3972e-02, -2.4048e-02, -5.9263e-03,\n          5.4981e-03, -1.4650e-02,  4.9056e-03, -7.8577e-03,  2.4069e-02,\n         -1.3624e-02, -5.3591e-02,  3.2923e-02,  4.5546e-02,  4.9713e-02,\n          1.2761e-02, -3.3219e-02,  5.1345e-02,  3.4908e-02,  3.6084e-02,\n          3.0883e-02, -5.0442e-02,  6.0378e-02,  2.4006e-02, -4.2679e-02,\n          5.4741e-02,  4.9416e-02, -4.6410e-02, -2.4330e-02,  4.1201e-02,\n          5.3309e-02,  4.2248e-02,  4.4630e-02, -4.9638e-02, -2.6197e-02,\n          5.0665e-02,  1.0157e-02, -1.9666e-02, -2.3535e-03, -3.8100e-02,\n         -3.0332e-02, -3.7852e-02,  5.3157e-02, -6.0544e-02,  2.7405e-02,\n          4.4898e-02,  2.6490e-02,  4.8072e-02, -5.4813e-02,  1.1396e-02,\n         -1.1630e-02,  5.3641e-02,  1.8908e-02, -3.7403e-02, -1.0188e-02,\n         -3.7711e-02, -8.7358e-04,  4.6326e-02,  6.1561e-03, -1.4242e-02,\n          1.9100e-02, -3.3535e-02,  4.1680e-02, -3.8657e-02,  6.0534e-02,\n          5.3726e-02,  3.2471e-02,  3.7761e-02,  4.7851e-02,  2.7681e-02,\n         -1.5360e-02, -3.7640e-02, -5.7792e-02,  1.0835e-02,  3.9421e-02,\n          3.3378e-02, -3.6482e-02,  1.9653e-02, -3.4163e-02,  5.8173e-02,\n         -3.5044e-02,  2.9626e-02, -4.1131e-02,  5.8608e-02, -2.2617e-02,\n         -1.8576e-02,  5.8734e-02,  2.2270e-02, -2.4208e-02, -1.1179e-02,\n          1.2145e-02, -1.6433e-02,  1.9029e-02,  1.6702e-02, -5.5701e-02,\n          2.9336e-02,  3.5507e-02,  3.5825e-02,  4.6501e-02,  3.9044e-02,\n          5.6934e-02,  5.8284e-03, -4.4347e-02, -5.7323e-02,  2.6777e-02,\n         -2.7898e-02,  7.4982e-03,  2.7456e-02, -4.8860e-02, -1.0909e-02,\n          2.5413e-04,  2.4200e-02,  2.2069e-02,  4.3434e-02,  2.3006e-02,\n          3.9480e-02, -7.7999e-03,  4.4995e-02,  4.6018e-03, -1.7064e-02,\n         -5.3319e-02, -1.0883e-02,  4.5776e-02, -5.8425e-02,  4.8154e-02,\n         -1.4999e-02, -2.5724e-02, -2.3181e-02,  4.3677e-02, -5.4947e-02,\n          1.7388e-02, -2.7722e-02, -5.6883e-02, -5.8093e-04,  2.8396e-02,\n          6.2952e-03,  1.2465e-03,  3.1102e-02, -2.1257e-02,  5.8814e-02,\n         -1.2635e-02, -4.1419e-02, -3.2427e-03,  3.5820e-02, -2.3744e-02,\n         -2.1826e-02, -3.8083e-04,  2.5404e-02, -4.0319e-03, -6.6040e-04,\n         -5.0947e-02, -4.7234e-02, -4.9268e-02,  3.4094e-02, -1.9747e-03,\n          2.4816e-02, -8.2143e-05, -2.5160e-02, -1.4989e-02, -5.9384e-02,\n          1.8326e-03],\n        [-5.3580e-02, -7.6978e-03, -2.0866e-02,  1.6719e-02, -1.6956e-02,\n          3.8104e-02, -6.1697e-02,  8.3346e-03,  3.7452e-02,  4.3413e-02,\n          3.9356e-02,  3.5525e-03,  4.4565e-02, -5.2745e-02,  3.2745e-02,\n         -5.2167e-04, -2.3373e-02,  9.5391e-03,  4.1961e-02, -3.3728e-02,\n          2.5912e-02, -1.8922e-02, -7.1048e-03,  4.6341e-02,  6.8856e-03,\n          6.5757e-03, -4.9498e-02,  5.5083e-02,  1.9236e-02,  3.6218e-02,\n         -5.1799e-02,  3.0335e-02,  3.5281e-02,  3.6199e-02, -7.2493e-03,\n          5.4088e-02, -6.0521e-02,  8.2754e-05, -2.8085e-02,  1.2285e-02,\n         -4.7847e-02, -2.4299e-02, -6.0272e-02, -5.7520e-02, -4.9323e-02,\n          4.8360e-02,  3.9737e-02,  2.3570e-03,  3.2809e-03,  3.6694e-02,\n         -2.3566e-02,  1.6804e-02, -6.2031e-02, -1.2891e-02, -9.3096e-03,\n         -1.0324e-02,  1.2324e-02,  1.0243e-02,  1.4787e-02,  1.0888e-02,\n          5.6204e-02,  5.9298e-02, -1.8818e-02,  5.2134e-02, -4.7078e-02,\n          1.7681e-02, -4.2611e-03,  5.5445e-02,  3.3658e-02, -5.6581e-02,\n         -5.8154e-02,  4.0322e-02, -5.5973e-02, -1.7193e-03,  1.0708e-02,\n          1.6799e-02, -4.7714e-02,  3.5961e-02,  6.0243e-02,  1.1119e-02,\n         -5.7433e-02, -4.1154e-02, -5.6147e-02,  3.8439e-02, -2.6060e-02,\n         -4.3853e-02,  3.1502e-03, -1.0103e-02, -2.4678e-02,  3.8755e-02,\n          1.0089e-02, -1.5827e-02,  4.0332e-03, -5.0306e-03,  2.9502e-02,\n         -7.0741e-03,  1.8133e-02,  7.3761e-03, -3.0817e-03,  4.6040e-02,\n          2.0858e-02,  3.9110e-02,  5.5519e-02, -5.3168e-02, -5.0600e-03,\n         -2.0244e-02,  3.5218e-02, -5.3613e-02,  2.0115e-02,  1.9626e-02,\n          3.4896e-03, -3.1369e-02, -4.3026e-02, -1.6815e-02,  5.2387e-02,\n         -2.4194e-02, -1.5073e-02,  5.3163e-03,  1.3406e-02,  1.9487e-02,\n          2.2957e-02,  3.4846e-02, -3.0049e-02,  9.3546e-03,  2.6198e-02,\n          2.2760e-02,  4.6307e-02,  5.6098e-02,  3.4952e-02,  1.2398e-02,\n          3.9067e-02, -4.6304e-03,  5.0569e-02, -1.4478e-02, -3.2022e-02,\n         -2.3514e-02,  3.5755e-02,  5.1459e-02,  4.3608e-02,  1.9900e-02,\n         -5.8269e-02,  5.7878e-02, -3.8815e-02,  1.2587e-02, -2.9434e-02,\n         -1.8371e-02,  6.8510e-03, -5.7422e-02, -3.1840e-02, -6.7899e-04,\n         -5.8167e-05,  1.5687e-02, -1.2836e-02,  3.7322e-02,  3.1165e-02,\n         -5.3349e-02, -5.5576e-02,  1.7756e-02,  1.2865e-02,  2.5265e-02,\n         -9.0838e-03, -4.1317e-02, -3.3871e-02,  1.1511e-03, -4.6128e-02,\n          5.9619e-02, -1.7614e-02,  1.8629e-02,  2.6520e-02, -6.0923e-02,\n          3.9699e-02, -3.0792e-02,  5.2315e-02,  6.1510e-02, -5.8246e-02,\n         -5.7492e-02,  5.7301e-02, -1.0059e-02,  6.1893e-03,  4.5890e-02,\n         -3.6105e-02, -4.9430e-02,  5.6902e-02,  2.0788e-02, -2.4791e-02,\n          1.3720e-02,  4.9924e-02,  5.7998e-02,  5.0396e-02,  8.9931e-03,\n          3.8658e-02, -3.3123e-03,  5.3835e-02,  3.6809e-02,  2.9982e-02,\n          1.3040e-02,  1.4449e-02, -4.4134e-03,  6.2828e-03,  5.9483e-02,\n         -5.8289e-02, -5.6318e-03, -3.6926e-03,  2.9829e-02, -1.1631e-02,\n         -3.0765e-02, -4.3862e-02, -6.1831e-03,  1.3510e-03,  5.8283e-02,\n         -1.2201e-02,  5.8510e-02, -6.1373e-02, -4.7874e-02,  4.5690e-02,\n         -3.7745e-03, -2.9547e-02, -2.4893e-02,  3.0861e-02, -9.3280e-03,\n         -1.1658e-02,  4.8747e-02, -2.3986e-02, -2.3798e-02, -2.5947e-02,\n         -4.9524e-02, -1.6577e-02, -3.3801e-02,  2.4912e-02,  1.1998e-02,\n          4.2159e-03,  3.5738e-03, -5.8949e-02,  2.2693e-02, -1.2792e-02,\n         -2.3228e-02, -4.8938e-02, -2.4337e-02, -4.9047e-02, -6.2425e-02,\n          9.0554e-03,  4.4007e-02, -1.7237e-03, -3.0090e-02,  5.5654e-02,\n         -5.1312e-02,  2.4862e-02,  1.9600e-02,  7.4906e-03, -6.1055e-02,\n          4.1439e-02,  5.9419e-02, -5.6514e-02,  5.2410e-02,  3.3153e-02,\n         -4.1536e-02]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	2,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "act_dim":	2,
            "alpha":	"tensor(-1.6094, device='cuda:0', dtype=torch.float64, requires_grad=True)",
            "alpha_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "tensor(-1.6094, device='cuda:0', dtype=torch.float64, requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "buffer":	{
                "<spinup.alogos.sac_discrete.sac_discrete.ReplayBuffer object at 0x7fe2284b6dd0>":	{
                    "act_buf":	"[[0]\n [0]\n [0]\n ...\n [0]\n [0]\n [0]]",
                    "device":	"cuda:0",
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "max_size":	5000,
                    "obs2_buf":	"[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n ...\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n ...\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "size":	0
                }
            },
            "delay_up":	0.995,
            "device":	"cuda:0",
            "env":	{
                "<TimeLimit<CartPoleEnv<CartPole-v0>>>":	{
                    "_action_space":	null,
                    "_elapsed_steps":	null,
                    "_max_episode_steps":	200,
                    "_metadata":	null,
                    "_observation_space":	null,
                    "_reward_range":	null,
                    "env":	{
                        "<CartPoleEnv<CartPole-v0>>":	{
                            "action_space":	{
                                "Discrete(2)":	{
                                    "_np_random":	null,
                                    "_shape":	[],
                                    "dtype":	"int64",
                                    "n":	2
                                }
                            },
                            "force_mag":	10.0,
                            "gravity":	9.8,
                            "kinematics_integrator":	"euler",
                            "length":	0.5,
                            "masscart":	1.0,
                            "masspole":	0.1,
                            "np_random":	"RandomState(MT19937)",
                            "observation_space":	{
                                "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)":	{
                                    "_np_random":	null,
                                    "_shape":	[
                                        4
                                    ],
                                    "bounded_above":	"[ True  True  True  True]",
                                    "bounded_below":	"[ True  True  True  True]",
                                    "dtype":	"float32",
                                    "high":	"[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]",
                                    "low":	"[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]"
                                }
                            },
                            "polemass_length":	0.05,
                            "spec":	{
                                "EnvSpec(CartPole-v0)":	{
                                    "_env_name":	"CartPole",
                                    "_kwargs":	{},
                                    "entry_point":	"gym.envs.classic_control:CartPoleEnv",
                                    "id":	"CartPole-v0",
                                    "max_episode_steps":	200,
                                    "nondeterministic":	false,
                                    "order_enforce":	true,
                                    "reward_threshold":	195.0
                                }
                            },
                            "state":	null,
                            "steps_beyond_done":	null,
                            "tau":	0.02,
                            "theta_threshold_radians":	0.20943951023931953,
                            "total_mass":	1.1,
                            "viewer":	null,
                            "x_threshold":	2.4
                        }
                    }
                }
            },
            "gamma":	0.99,
            "log_alpha":	"tensor(-1.6094, device='cuda:0', dtype=torch.float64, requires_grad=True)",
            "logger":	{
                "<spinup.utils.logx.EpochLogger object at 0x7fe228ba7410>":	{
                    "epoch_dict":	{},
                    "exp_name":	"sac_discrete",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/zp/deeplearning/spinningup_project/data/sac_discrete/sac_discrete_s0",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/zp/deeplearning/spinningup_project/data/sac_discrete/sac_discrete_s0/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "max_ep_len":	200,
            "num_test_epsodes":	10,
            "obs_dim":	[
                4
            ],
            "pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.4290, -0.1058,  0.4743, -0.1028],\n        [ 0.2531, -0.4780,  0.1732, -0.4999],\n        [ 0.0339,  0.0157,  0.2901, -0.2286],\n        ...,\n        [-0.0745, -0.1397, -0.1894,  0.4891],\n        [-0.0853, -0.2386,  0.3482,  0.0950],\n        [ 0.2819,  0.4207,  0.3679, -0.3548]], device='cuda:0',\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1541, -0.4159,  0.3853,  0.4909, -0.1822,  0.2241,  0.0790,  0.4716,\n        -0.0851, -0.4201,  0.4691,  0.3279,  0.1977, -0.3808, -0.2493, -0.0974,\n         0.1907, -0.1346, -0.2550,  0.0028,  0.3137, -0.3281,  0.3892, -0.3942,\n        -0.1578, -0.3482, -0.1839, -0.1785,  0.3096, -0.4544, -0.0559, -0.0329,\n         0.2175,  0.2057,  0.1354,  0.4713, -0.2613, -0.1574, -0.0184,  0.0499,\n        -0.1615, -0.1994,  0.3056,  0.3308, -0.0904, -0.3837, -0.3643, -0.4495,\n        -0.2535,  0.2318,  0.4125,  0.1745,  0.3060, -0.2390, -0.2896, -0.0022,\n         0.4859,  0.0916,  0.0431, -0.4949,  0.4407,  0.0937, -0.2983,  0.0932,\n         0.3823,  0.3002,  0.3597,  0.3885, -0.3056,  0.1730,  0.0912,  0.4607,\n        -0.1155, -0.1826,  0.2963,  0.2815, -0.2779, -0.2819, -0.0942,  0.1194,\n        -0.3230, -0.1076,  0.2892,  0.1770, -0.3554,  0.3223,  0.3673, -0.3316,\n        -0.1575,  0.1628,  0.1424, -0.0615,  0.2566, -0.2889, -0.1131,  0.0411,\n         0.4378,  0.1474,  0.2161,  0.1242, -0.3460,  0.4658,  0.3356, -0.1140,\n        -0.1447,  0.0533,  0.0561, -0.1323,  0.4937, -0.0492, -0.2637,  0.1563,\n        -0.4334, -0.3190, -0.3294, -0.3876, -0.2595, -0.3287,  0.0521, -0.3565,\n        -0.4516,  0.0241, -0.4528, -0.4785, -0.3299, -0.2054,  0.4456,  0.0314,\n         0.2575,  0.2961, -0.0574,  0.1288, -0.3652, -0.1092, -0.2511, -0.1517,\n        -0.1428, -0.3170, -0.0636, -0.4711,  0.2585,  0.0537, -0.0280,  0.2702,\n        -0.1270, -0.2970, -0.0441, -0.3504, -0.0158,  0.2653,  0.1672, -0.4291,\n        -0.2718, -0.1302, -0.4594,  0.1485,  0.3876,  0.1043,  0.1029, -0.0941,\n         0.4854, -0.1430,  0.1418,  0.3379,  0.0219,  0.2282, -0.3402,  0.1435,\n        -0.4495,  0.3182, -0.2586,  0.0080, -0.0707, -0.1093,  0.1884,  0.3559,\n         0.1060, -0.3599,  0.2154,  0.2876,  0.3600, -0.4414,  0.1092, -0.3698,\n        -0.4709, -0.2815, -0.2144, -0.0020,  0.3811,  0.4574, -0.0452, -0.4172,\n         0.1605,  0.1199, -0.2493,  0.0941,  0.0513, -0.1973,  0.3298,  0.3019,\n         0.1807, -0.3165,  0.3916,  0.2440, -0.0787, -0.0737, -0.3538,  0.4308,\n         0.1346,  0.3063, -0.4400,  0.3356,  0.0176,  0.0928, -0.1947, -0.1292,\n         0.4845,  0.3905, -0.3184,  0.3226, -0.4356,  0.3759, -0.2887,  0.2277,\n        -0.4938,  0.3111, -0.0172,  0.3766,  0.3298,  0.3606, -0.2939,  0.2581,\n         0.0993,  0.3365, -0.1031, -0.1453,  0.2812, -0.4781,  0.4312, -0.3871,\n        -0.3865,  0.4090,  0.0550,  0.4060, -0.4014,  0.1968, -0.0704,  0.0931,\n         0.2417, -0.4376, -0.3782, -0.0060,  0.4483,  0.2144,  0.2118, -0.1602],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0567,  0.0051, -0.0064,  ..., -0.0003, -0.0510, -0.0299],\n        [-0.0563,  0.0271, -0.0128,  ..., -0.0542, -0.0206,  0.0111],\n        [ 0.0124, -0.0209, -0.0301,  ...,  0.0117, -0.0340,  0.0066],\n        ...,\n        [-0.0330, -0.0120,  0.0465,  ...,  0.0598, -0.0344,  0.0237],\n        [ 0.0014, -0.0141,  0.0435,  ..., -0.0568, -0.0229, -0.0330],\n        [-0.0034, -0.0281,  0.0468,  ..., -0.0276, -0.0483,  0.0426]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 6.0913e-02, -3.4626e-02,  4.4969e-02, -2.3780e-02,  3.5794e-02,\n        -5.5496e-02,  2.1002e-02,  5.9911e-02, -9.2531e-03, -4.9601e-02,\n        -6.0456e-02, -2.7516e-02, -5.7320e-02, -5.7427e-02, -2.9750e-02,\n        -6.0037e-03, -3.9257e-02, -2.7400e-02, -7.5555e-03, -8.1710e-03,\n         3.6639e-02, -3.0473e-02, -4.1667e-02, -5.1269e-02,  4.2324e-02,\n         1.2772e-02, -3.1106e-03, -4.4313e-02, -1.4366e-02,  2.8707e-05,\n         4.9017e-02, -2.4572e-02,  5.9941e-02, -3.1341e-02,  4.5435e-02,\n         3.9680e-03,  3.6046e-02, -5.2321e-02,  1.4783e-02, -1.3904e-02,\n        -2.4301e-02,  2.8245e-02, -6.0579e-02, -1.6902e-02, -5.3758e-02,\n        -5.2327e-02, -5.5550e-03, -4.5158e-02,  3.3012e-02, -4.6085e-02,\n        -1.1712e-02,  8.2660e-03,  7.2619e-03,  5.7591e-02, -4.5676e-02,\n        -4.6310e-02,  3.8462e-02,  2.1397e-02, -4.9478e-02,  2.8170e-02,\n        -1.4347e-02, -4.0269e-02,  3.9209e-02, -4.0345e-05,  3.4664e-02,\n        -2.8357e-02, -5.0968e-02,  6.2614e-03, -4.3510e-02, -3.3587e-02,\n         4.0547e-02, -3.0356e-02,  4.2414e-02, -7.9272e-03,  3.1174e-02,\n         4.9423e-02, -4.0581e-02, -4.0482e-02,  2.9091e-02,  5.0387e-02,\n         1.2945e-03,  2.2616e-02,  1.5659e-02, -4.1182e-02, -3.4933e-02,\n         4.7361e-03,  5.3783e-02,  4.5305e-02, -3.8264e-02, -6.0913e-02,\n         6.0611e-02, -5.4911e-02, -3.5395e-02,  5.6411e-02, -3.8706e-02,\n        -1.8125e-02, -2.5594e-03, -4.7945e-02, -3.3631e-02, -3.5977e-02,\n         2.4727e-02,  2.5808e-02,  5.9960e-02, -3.3034e-02,  5.9527e-02,\n        -1.3264e-02, -5.0596e-02, -4.8315e-03, -6.6214e-03, -3.6731e-02,\n         1.5343e-02, -3.1068e-02, -7.0883e-03,  5.1601e-03,  3.2882e-02,\n         2.6287e-02, -2.8058e-03, -1.5868e-02, -1.6833e-02,  2.5641e-02,\n         7.3576e-03,  5.6714e-02,  2.0377e-02,  3.4872e-02,  1.5106e-02,\n         5.9687e-02,  1.3695e-02,  2.3007e-02,  1.0371e-02,  3.7556e-02,\n        -2.8821e-02,  4.9481e-03, -3.0349e-02,  1.8002e-02, -6.0813e-03,\n        -9.2954e-03,  4.4846e-02, -5.2925e-02,  2.1532e-02, -2.2245e-02,\n        -5.5667e-02,  9.6197e-03,  9.1972e-03,  5.9052e-02, -4.6993e-02,\n        -5.1885e-02,  2.0214e-02,  5.5119e-02,  2.1642e-02, -5.5193e-02,\n        -5.9041e-02, -1.1775e-02,  3.3470e-02, -3.8805e-02, -5.8032e-03,\n         3.9051e-02,  1.9301e-02, -4.0188e-02,  1.6646e-02, -5.4245e-02,\n         1.5857e-02, -3.9512e-02,  5.5565e-02, -2.2895e-02,  1.3024e-02,\n         2.5005e-02,  5.8054e-04, -8.7451e-03,  3.2832e-02, -3.0688e-02,\n        -1.4325e-02,  5.2305e-02,  5.9901e-02, -5.1228e-02, -3.4108e-02,\n        -5.6050e-03, -1.6375e-02,  3.8231e-03,  9.1362e-03, -5.6739e-02,\n        -2.3406e-02, -5.8379e-02, -3.0658e-04, -3.0870e-02,  1.2085e-02,\n         2.8206e-02,  6.2357e-02,  1.1117e-02,  2.9934e-02,  5.2959e-02,\n         1.7304e-03, -1.3512e-02, -3.4765e-02, -2.5731e-02, -4.8099e-02,\n        -4.6679e-03,  4.1993e-02, -1.0396e-02, -6.9333e-03,  2.6476e-02,\n         1.3559e-02, -1.1189e-02, -4.2326e-02,  3.8801e-02,  4.9281e-02,\n         1.7189e-02, -4.2487e-02,  3.4443e-02, -5.1766e-03,  5.4068e-02,\n        -2.9003e-02,  5.4127e-02,  3.5559e-02, -5.3971e-02,  8.2017e-03,\n         2.9802e-02,  3.6643e-02, -1.9452e-02, -2.1991e-02,  2.3713e-02,\n        -6.1883e-02, -8.7566e-03, -4.1851e-02,  6.8833e-03,  2.9856e-02,\n         4.3381e-02,  4.1761e-02,  2.9507e-02, -4.3322e-04, -3.8456e-02,\n         1.0690e-02, -3.3456e-02,  2.3969e-02,  4.8107e-02,  1.3027e-02,\n         2.5272e-02, -5.8870e-02,  2.8631e-02, -6.9940e-03, -1.7893e-02,\n        -4.0558e-02, -3.4221e-02, -6.1249e-02,  4.9052e-02, -4.0314e-03,\n         5.7556e-02, -1.7077e-03,  3.9282e-02, -2.1724e-02, -5.9710e-02,\n        -4.4200e-04, -6.1539e-03, -5.9075e-02, -1.7899e-02,  1.4553e-02,\n        -2.0001e-02], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0097, -0.0180, -0.0193,  0.0276,  0.0150,  0.0457, -0.0304, -0.0543,\n          0.0339,  0.0306, -0.0527, -0.0610,  0.0604, -0.0020, -0.0395,  0.0295,\n         -0.0074, -0.0542, -0.0490, -0.0233, -0.0513,  0.0517,  0.0422, -0.0301,\n         -0.0111, -0.0369,  0.0204, -0.0130,  0.0563, -0.0196,  0.0558,  0.0038,\n          0.0536, -0.0493,  0.0275, -0.0129,  0.0124,  0.0218, -0.0144, -0.0267,\n         -0.0530, -0.0317,  0.0541, -0.0318,  0.0502, -0.0553,  0.0303, -0.0120,\n         -0.0409, -0.0311, -0.0206, -0.0012, -0.0013, -0.0329, -0.0563,  0.0579,\n         -0.0265,  0.0165, -0.0450, -0.0062,  0.0057, -0.0381, -0.0189, -0.0248,\n         -0.0560, -0.0132,  0.0254, -0.0490, -0.0148,  0.0074,  0.0132,  0.0539,\n          0.0464, -0.0539,  0.0198,  0.0003,  0.0498,  0.0624, -0.0100,  0.0309,\n          0.0391,  0.0028, -0.0386,  0.0359, -0.0402,  0.0452, -0.0277,  0.0382,\n          0.0495, -0.0307,  0.0220,  0.0304,  0.0414,  0.0463,  0.0539, -0.0007,\n         -0.0623,  0.0029, -0.0290,  0.0392, -0.0221,  0.0302,  0.0516,  0.0022,\n          0.0543, -0.0157,  0.0476, -0.0596,  0.0559,  0.0427, -0.0319,  0.0303,\n         -0.0603,  0.0138,  0.0278, -0.0140, -0.0245,  0.0472, -0.0427,  0.0367,\n          0.0459, -0.0367,  0.0120, -0.0333, -0.0031,  0.0121,  0.0440,  0.0077,\n         -0.0566, -0.0380, -0.0542,  0.0166,  0.0427,  0.0250, -0.0350, -0.0134,\n         -0.0412, -0.0462, -0.0552, -0.0035, -0.0155,  0.0398,  0.0496, -0.0016,\n          0.0102, -0.0180, -0.0356,  0.0152,  0.0379,  0.0099,  0.0399,  0.0238,\n          0.0005, -0.0192,  0.0011, -0.0348,  0.0603, -0.0023,  0.0582, -0.0538,\n         -0.0623, -0.0009,  0.0118, -0.0131, -0.0516, -0.0007,  0.0151,  0.0625,\n         -0.0136,  0.0450, -0.0016, -0.0444,  0.0274,  0.0344,  0.0425,  0.0283,\n          0.0535,  0.0454,  0.0272, -0.0554, -0.0521, -0.0138,  0.0553,  0.0157,\n          0.0121,  0.0077,  0.0264,  0.0361, -0.0369, -0.0249, -0.0466, -0.0211,\n         -0.0456, -0.0439, -0.0087,  0.0403,  0.0021,  0.0238, -0.0187,  0.0368,\n         -0.0160, -0.0182, -0.0161, -0.0200,  0.0107, -0.0032, -0.0607, -0.0015,\n          0.0275,  0.0575,  0.0514, -0.0603, -0.0017, -0.0071, -0.0419, -0.0336,\n          0.0214, -0.0587,  0.0587,  0.0479,  0.0268,  0.0223, -0.0119, -0.0486,\n          0.0540, -0.0399, -0.0296, -0.0006,  0.0392,  0.0533,  0.0137, -0.0512,\n          0.0429, -0.0162, -0.0120,  0.0593, -0.0094, -0.0129,  0.0365,  0.0167,\n         -0.0409, -0.0079, -0.0026, -0.0430,  0.0004, -0.0503,  0.0138, -0.0325,\n         -0.0459, -0.0076,  0.0494, -0.0126,  0.0471,  0.0007, -0.0414,  0.0195],\n        [ 0.0266,  0.0261, -0.0105, -0.0487,  0.0470,  0.0283,  0.0126, -0.0094,\n         -0.0508, -0.0049,  0.0287,  0.0504,  0.0450, -0.0105, -0.0545, -0.0489,\n         -0.0344, -0.0096, -0.0605,  0.0402, -0.0377, -0.0381,  0.0121, -0.0483,\n          0.0488, -0.0099,  0.0103,  0.0483, -0.0092,  0.0234, -0.0314,  0.0304,\n          0.0383,  0.0102, -0.0239,  0.0310, -0.0168,  0.0112, -0.0588, -0.0012,\n         -0.0286,  0.0283,  0.0576,  0.0480, -0.0048, -0.0377,  0.0076, -0.0466,\n         -0.0458,  0.0099, -0.0591, -0.0210,  0.0232, -0.0131,  0.0609, -0.0518,\n          0.0563, -0.0322,  0.0002, -0.0215, -0.0397, -0.0450, -0.0260,  0.0021,\n         -0.0460, -0.0176,  0.0493, -0.0358, -0.0434,  0.0301,  0.0264,  0.0021,\n          0.0281,  0.0548, -0.0301, -0.0217,  0.0387,  0.0079, -0.0196,  0.0197,\n         -0.0163, -0.0258, -0.0513,  0.0070,  0.0537, -0.0377,  0.0539,  0.0522,\n          0.0050,  0.0509, -0.0123,  0.0248,  0.0171, -0.0204, -0.0242, -0.0303,\n         -0.0170,  0.0387,  0.0028,  0.0200, -0.0250,  0.0215, -0.0449, -0.0027,\n         -0.0404,  0.0450, -0.0230, -0.0591, -0.0236,  0.0290,  0.0045,  0.0227,\n         -0.0586, -0.0209, -0.0504, -0.0212, -0.0517, -0.0504,  0.0514, -0.0094,\n          0.0506,  0.0316,  0.0348, -0.0592, -0.0244, -0.0583, -0.0315, -0.0445,\n         -0.0598,  0.0263,  0.0538,  0.0556,  0.0278,  0.0314,  0.0053,  0.0617,\n          0.0276,  0.0283,  0.0509,  0.0237,  0.0131, -0.0198, -0.0269,  0.0315,\n          0.0317, -0.0503, -0.0316,  0.0102,  0.0063,  0.0219, -0.0541, -0.0508,\n         -0.0113,  0.0156,  0.0264, -0.0066,  0.0528,  0.0074,  0.0048,  0.0267,\n         -0.0511,  0.0098,  0.0185, -0.0205, -0.0293, -0.0540,  0.0600,  0.0180,\n         -0.0308, -0.0355,  0.0396, -0.0054, -0.0078, -0.0616,  0.0038, -0.0041,\n         -0.0009, -0.0119, -0.0543,  0.0283,  0.0422, -0.0311, -0.0058,  0.0623,\n         -0.0364,  0.0423, -0.0254,  0.0411,  0.0240, -0.0333,  0.0143,  0.0423,\n         -0.0428, -0.0020,  0.0297,  0.0350,  0.0345,  0.0041, -0.0504, -0.0514,\n         -0.0462, -0.0198, -0.0298, -0.0028,  0.0249, -0.0021, -0.0573, -0.0166,\n         -0.0524,  0.0327,  0.0228,  0.0624, -0.0057, -0.0142, -0.0514, -0.0237,\n         -0.0069, -0.0553, -0.0339,  0.0106,  0.0453,  0.0454, -0.0366, -0.0160,\n         -0.0307,  0.0601,  0.0432,  0.0197,  0.0312, -0.0426, -0.0610,  0.0426,\n         -0.0284, -0.0442,  0.0612,  0.0093,  0.0021, -0.0188,  0.0071,  0.0080,\n         -0.0096,  0.0140,  0.0135, -0.0257,  0.0312,  0.0105,  0.0101, -0.0056,\n         -0.0389, -0.0294,  0.0448,  0.0559, -0.0542, -0.0520,  0.0392,  0.0516]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0578,  0.0395], device='cuda:0', requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3650,  0.1926,  0.3665, -0.4551],\n        [-0.4671,  0.0869, -0.1379, -0.4116],\n        [-0.0655,  0.3748, -0.2167, -0.2616],\n        ...,\n        [ 0.1532,  0.1845,  0.2320,  0.1809],\n        [-0.3210,  0.0358, -0.2053, -0.0046],\n        [ 0.1897, -0.4997,  0.0539, -0.3697]], device='cuda:0',\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-1.9962e-01,  1.2976e-01,  2.7294e-01, -5.7560e-02,  4.3497e-01,\n         2.3543e-01,  3.6013e-02,  5.3409e-02, -3.3610e-01, -3.6582e-01,\n         4.3450e-01,  4.7132e-01,  1.4130e-02, -1.9506e-02, -1.8033e-01,\n         3.7473e-01, -2.3706e-01, -6.9214e-02,  3.4421e-01, -1.7500e-01,\n         6.3653e-02, -4.7311e-01,  1.9863e-01,  3.3056e-01, -2.8121e-01,\n        -2.0563e-01,  3.4080e-01,  1.9393e-01,  3.2922e-01,  2.2447e-01,\n         2.4548e-01, -1.3538e-01,  1.0371e-01, -2.3775e-01, -3.8911e-01,\n        -3.2659e-01,  4.4025e-01, -1.2251e-01, -4.2622e-01,  3.2950e-01,\n        -2.8402e-01,  1.0951e-01, -4.7868e-01,  1.6723e-01,  2.7159e-01,\n        -4.6678e-01,  3.9085e-01, -1.0209e-01,  4.1880e-01, -1.7394e-01,\n        -2.4641e-01, -3.8244e-01, -4.3572e-01,  1.0206e-01, -3.6070e-01,\n        -1.1019e-01,  3.5549e-02,  6.9859e-03, -2.5251e-01,  9.6788e-02,\n        -2.0265e-01, -4.0044e-01, -1.5973e-01,  4.8261e-01, -1.2343e-01,\n         3.2452e-01,  2.7381e-02, -3.5123e-01, -3.5580e-02, -3.0196e-02,\n         3.9375e-01, -3.5212e-02,  3.4686e-02, -8.7625e-03, -4.6724e-01,\n         6.3440e-02,  2.8392e-01, -2.9722e-01,  4.8024e-01, -9.0158e-04,\n         1.5095e-01,  4.4028e-01, -3.3151e-01,  2.0686e-02, -3.1721e-01,\n         1.5876e-01, -3.0394e-01,  6.5505e-02,  1.6096e-02, -1.5596e-01,\n        -6.6804e-02,  1.3482e-01, -4.4710e-01,  3.9394e-01, -1.2698e-01,\n         1.8031e-01,  4.6012e-01,  2.1281e-01,  2.4823e-01, -3.0084e-01,\n         2.2770e-01,  4.9406e-01,  4.3865e-01, -4.7583e-01,  2.5661e-01,\n        -5.0738e-02, -2.8174e-01, -9.4003e-02,  2.1648e-01, -2.6443e-01,\n         2.2057e-01,  3.2453e-01,  1.5271e-01,  4.1228e-01, -3.8116e-02,\n         2.9939e-03, -4.6855e-01,  4.8571e-01,  3.9091e-01, -4.4468e-01,\n         2.4410e-01, -2.9081e-02, -2.4988e-01, -3.7520e-01, -4.3670e-01,\n        -2.6576e-01,  2.4013e-01, -1.8935e-01, -4.5507e-01,  3.1774e-01,\n         3.7077e-01, -3.0619e-01, -3.6326e-02, -2.0766e-01, -2.2440e-01,\n         3.7366e-01,  2.5821e-03,  2.6856e-01,  4.8135e-01,  4.3445e-01,\n         3.9880e-03,  2.0563e-01,  2.5620e-01, -2.0266e-01, -4.2443e-01,\n         4.4976e-01,  4.3077e-01, -2.6392e-01, -4.4410e-01,  4.0813e-01,\n         2.9686e-01,  1.0877e-01, -2.1348e-01,  1.1285e-01,  4.4605e-01,\n        -5.4893e-02, -1.8589e-02,  1.7188e-01, -4.2742e-01,  2.4292e-01,\n         1.2697e-01, -2.1291e-01, -3.5114e-01, -2.8034e-01, -3.3928e-01,\n         6.1714e-02, -2.1038e-01,  1.0554e-01, -5.6190e-02,  4.3339e-02,\n         4.7976e-02,  2.2437e-01,  3.8838e-01,  2.1905e-01, -1.8607e-01,\n         4.9909e-02, -4.2789e-01,  4.1267e-01,  1.9608e-01,  3.0970e-02,\n        -1.7694e-01,  4.2423e-01, -3.7706e-01,  7.4076e-02, -2.0542e-01,\n         3.5590e-01, -1.8422e-01, -1.7219e-01,  4.1969e-01,  1.6671e-01,\n        -4.1719e-01,  4.7291e-01, -1.6880e-01,  2.4419e-01, -2.1781e-01,\n         4.3933e-01,  1.0093e-01,  3.7270e-01,  4.9201e-01, -1.4436e-01,\n         2.8692e-01,  1.7837e-01, -1.4133e-01, -4.0764e-01,  5.2528e-02,\n        -2.5284e-01,  2.7737e-01,  4.9643e-01,  5.9057e-02, -2.7105e-01,\n        -4.4060e-02,  6.0942e-03,  7.2555e-02, -9.1431e-02, -1.5090e-01,\n        -2.1872e-01, -4.1075e-01,  3.8461e-01, -4.5157e-03, -4.9067e-01,\n         4.6612e-01,  2.5406e-01,  4.2418e-01, -4.0354e-01, -4.8299e-01,\n         2.2403e-01, -2.1654e-02,  3.3083e-01, -4.7570e-01, -4.1944e-01,\n        -7.7381e-02, -1.5930e-01,  4.7680e-01, -4.0373e-01, -3.9075e-01,\n        -2.8293e-01,  3.7644e-01, -7.9051e-03, -1.9506e-01, -3.2510e-01,\n        -4.7790e-01, -2.1574e-01,  4.6893e-01, -1.5588e-01,  4.5955e-05,\n         8.2703e-02,  4.3051e-01, -1.1578e-01,  2.7984e-01,  3.7855e-01,\n         4.8422e-01,  3.8446e-01,  1.3210e-01, -3.4336e-01,  8.0217e-02,\n         3.3007e-01], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0183, -0.0330,  0.0475,  ..., -0.0102,  0.0508, -0.0552],\n        [ 0.0230,  0.0404, -0.0175,  ...,  0.0610, -0.0133,  0.0342],\n        [-0.0116,  0.0319, -0.0504,  ...,  0.0063, -0.0390,  0.0021],\n        ...,\n        [-0.0481, -0.0069, -0.0012,  ...,  0.0447, -0.0473,  0.0456],\n        [-0.0011, -0.0501,  0.0077,  ...,  0.0340,  0.0290,  0.0382],\n        [-0.0072, -0.0250,  0.0189,  ..., -0.0423, -0.0489, -0.0230]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-2.2604e-02,  3.1567e-02, -4.7032e-02, -1.3071e-02, -3.1565e-02,\n         5.1928e-02,  1.1242e-03, -1.0280e-02,  4.1787e-02, -3.4881e-02,\n         4.8470e-02,  3.3419e-02, -3.1485e-03,  3.7777e-02, -5.9138e-02,\n        -4.0488e-02,  3.6577e-02,  4.9368e-02, -2.1430e-02, -1.2739e-02,\n         6.4866e-03,  5.4008e-03,  2.4772e-02,  2.6358e-02, -3.4074e-02,\n        -4.1407e-02, -5.9629e-02, -5.8664e-02,  3.4731e-02,  8.8219e-03,\n         1.5506e-02,  4.8163e-02,  2.5956e-02,  5.4496e-02,  2.7068e-02,\n        -4.0188e-02, -4.5402e-03, -5.5804e-02,  7.0584e-03,  2.3410e-02,\n        -4.8404e-02, -4.0739e-02,  2.2476e-03, -2.3985e-02, -4.0246e-02,\n        -1.4682e-02,  4.1274e-03, -4.6117e-02, -6.8751e-04,  6.2484e-02,\n        -5.2852e-02,  9.7730e-03,  4.8335e-02, -4.0360e-02,  6.6055e-03,\n         1.4531e-02,  5.9382e-02, -3.2185e-03,  3.2042e-02,  2.0246e-02,\n         9.9710e-03,  2.9443e-02, -6.0054e-02,  5.6436e-02,  4.7874e-02,\n         2.1782e-02,  2.4294e-02,  6.6594e-03, -8.4765e-03, -1.5208e-02,\n        -5.6865e-02,  3.8000e-02, -6.0692e-03,  4.2630e-02, -5.7178e-02,\n         4.6558e-02, -9.2130e-03, -2.9130e-02,  3.7176e-02, -2.6513e-02,\n        -3.1311e-02, -1.3649e-02, -4.9194e-03, -2.5279e-02,  1.3388e-03,\n        -1.3581e-02, -2.1734e-02, -2.3988e-02, -3.9658e-02,  3.9210e-02,\n         1.1916e-02,  4.0918e-02,  5.2344e-02, -9.3701e-03,  1.5082e-02,\n        -4.8007e-02,  5.8493e-02, -3.6079e-02,  5.0136e-02,  4.3922e-02,\n        -2.8601e-02,  3.5702e-03, -2.1551e-02,  2.3366e-02, -5.2549e-02,\n        -1.2403e-02,  8.4423e-05, -2.8221e-02,  2.1658e-03, -3.5255e-02,\n         8.0655e-03,  1.5776e-02,  3.0857e-02,  5.1387e-02, -2.6135e-02,\n         4.0753e-02,  4.9788e-02,  4.9571e-02,  5.2945e-02,  3.9130e-02,\n        -3.3891e-02, -4.1595e-02, -2.8531e-02, -5.4222e-03,  1.1716e-02,\n         3.4571e-02,  4.8683e-02,  4.3623e-02,  2.7669e-03,  9.6493e-03,\n         3.5790e-02,  1.0275e-02,  4.4709e-02, -5.4412e-02,  4.9899e-02,\n        -1.5718e-02,  4.1906e-03,  5.6973e-02, -3.0233e-03,  2.1672e-02,\n         3.8345e-02,  2.7300e-02,  4.9417e-03,  5.5755e-02, -2.9071e-02,\n        -4.7819e-02,  1.3359e-03,  4.3200e-02,  4.1314e-02, -6.2012e-02,\n         8.3524e-03,  2.5685e-02,  5.7996e-03, -4.9345e-02, -2.9467e-03,\n        -5.9417e-02,  4.6109e-02,  1.8613e-02, -5.0013e-03, -4.5992e-02,\n         4.6029e-02,  1.2358e-02,  2.4165e-02, -5.2408e-02,  2.6222e-02,\n        -4.5874e-02,  1.2107e-03,  2.3497e-02, -2.3079e-02,  3.1804e-02,\n         3.7814e-02, -2.8218e-02, -1.7235e-02,  4.2929e-02,  5.4327e-02,\n         3.4098e-02, -6.1104e-02,  1.6557e-02, -1.2751e-02, -4.7365e-02,\n         5.5777e-02,  4.7833e-05,  2.6629e-02, -5.4816e-02, -3.2067e-02,\n        -5.0143e-02,  3.2576e-03,  4.4309e-02,  4.1694e-02,  4.0892e-02,\n        -5.8621e-02,  6.0942e-02, -5.1636e-02,  5.0797e-02, -2.7219e-02,\n        -1.3578e-02,  5.2339e-02, -9.9539e-04,  5.8648e-02,  6.0967e-02,\n        -4.9219e-02, -4.0899e-02, -1.3053e-02,  3.2349e-02, -2.4511e-02,\n        -5.9191e-02, -3.9231e-02,  7.6393e-04, -1.0076e-02,  8.2299e-03,\n        -1.2487e-02,  5.2082e-02,  6.1497e-02, -6.0370e-02,  5.9855e-02,\n         8.8103e-03, -1.7743e-03, -6.3060e-03,  8.3604e-03, -5.1302e-02,\n        -7.1222e-04,  4.1206e-03,  2.7157e-02, -5.2260e-02, -4.9903e-02,\n         4.8954e-02, -1.0563e-02, -5.4621e-02, -4.4943e-02, -5.9938e-02,\n        -5.6685e-02,  5.3392e-02,  1.5170e-02,  1.8297e-02,  1.4722e-02,\n        -4.1134e-02, -3.2979e-02,  3.6884e-02,  1.2875e-02,  2.8458e-02,\n         2.6316e-02, -2.7398e-02, -5.8625e-02,  5.4713e-02,  3.5349e-02,\n        -4.4725e-02,  3.6600e-02, -4.2638e-02,  2.6515e-03,  6.2422e-02,\n        -9.3373e-03,  6.9790e-03,  6.1502e-02, -4.2043e-02, -2.3079e-02,\n         6.1346e-02], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-5.1386e-03, -3.6500e-02, -4.5660e-02, -5.7929e-02,  5.7241e-02,\n         -1.4348e-02,  5.8078e-02,  1.3565e-02, -4.4403e-02,  5.0631e-02,\n          3.3267e-02,  2.0705e-02,  5.1059e-02, -3.1209e-02,  2.6400e-03,\n         -4.5928e-02, -4.5103e-02,  2.4290e-02, -1.6746e-02,  4.4139e-02,\n         -1.7876e-02,  3.2466e-02,  3.8775e-02,  4.3882e-02,  4.9926e-02,\n          2.5948e-02,  1.1067e-02, -5.2174e-02,  4.9200e-02,  4.4737e-02,\n         -2.5652e-02, -3.2573e-02, -2.3861e-03,  2.7533e-02,  4.5714e-02,\n          5.9700e-02, -5.8999e-02, -4.8578e-02, -3.3012e-02, -4.0647e-02,\n          2.4606e-02,  2.8370e-02, -4.0493e-02, -4.8130e-02, -5.6823e-03,\n          2.2402e-02,  5.3185e-02,  6.7808e-03,  6.0597e-02, -4.1758e-02,\n          1.5805e-02, -1.5054e-02,  4.2120e-02, -2.7022e-02,  5.8519e-02,\n          6.0667e-02,  4.8642e-02, -3.0237e-02, -2.1638e-02, -1.7833e-02,\n          2.3787e-02, -4.1359e-02, -4.3630e-02, -3.7798e-02,  2.0184e-02,\n         -2.8839e-02, -3.1096e-02,  1.9031e-02,  2.4672e-02,  2.5068e-02,\n         -4.9902e-02, -2.3427e-02,  3.6031e-02, -2.3276e-02,  5.5070e-02,\n          4.8558e-02, -2.7940e-02,  2.1498e-02, -4.1303e-02,  3.4286e-02,\n          5.3664e-02,  4.4376e-02,  5.0474e-03, -1.9207e-02,  2.9926e-02,\n         -5.5592e-02,  2.6029e-02, -1.0144e-02,  9.1866e-06,  3.6897e-02,\n         -1.6283e-02,  2.8397e-02,  4.6940e-02,  4.4245e-02,  6.1046e-02,\n          5.8959e-02,  3.3180e-02, -3.5616e-02,  9.6771e-03, -2.7611e-02,\n         -6.2753e-03, -3.9665e-02, -4.3359e-02, -4.2270e-02, -4.3682e-02,\n          3.2047e-02,  1.7213e-03,  2.1672e-02,  4.9777e-02, -1.8996e-02,\n          1.8557e-03,  2.3308e-02,  1.7778e-02,  5.3154e-02, -2.2372e-02,\n          3.5463e-02, -1.9317e-03, -1.2226e-02, -1.4400e-02, -6.0124e-03,\n         -1.3936e-02,  4.1061e-02,  5.1002e-02, -1.2609e-02,  1.4679e-02,\n          3.3463e-02,  4.1305e-02, -3.4433e-02,  4.8141e-02, -2.2699e-02,\n         -4.3505e-02,  5.4451e-02, -1.0238e-02, -5.7694e-02, -1.2353e-02,\n         -4.3291e-02,  2.8926e-02,  3.1781e-02, -3.0289e-02,  5.8222e-02,\n         -5.8108e-02, -1.0935e-02, -5.1726e-02,  2.2265e-02, -2.0251e-02,\n          8.5905e-03,  4.4099e-03, -1.6824e-02,  6.7532e-03,  4.8639e-02,\n         -1.1607e-02,  2.0699e-02, -3.1267e-02,  3.8250e-02, -4.6874e-02,\n          6.0836e-02,  9.4357e-03, -3.9092e-02, -2.3922e-02,  5.0376e-02,\n         -4.1962e-02,  2.1529e-02,  1.0412e-02,  1.6689e-02,  4.6943e-02,\n         -2.8955e-02,  1.1092e-02,  4.0190e-02, -6.1299e-02,  4.1534e-03,\n          4.2600e-02,  1.3020e-02, -3.6156e-02, -2.3985e-02, -5.2355e-02,\n          4.3914e-04,  2.6606e-02, -2.7612e-02,  2.1861e-02,  4.8673e-03,\n         -4.5080e-02,  3.2328e-02, -2.7480e-02, -1.4795e-03, -2.8557e-02,\n          3.3459e-02,  8.8954e-03, -6.0928e-02, -1.4938e-04,  3.9835e-03,\n         -4.0394e-02,  1.5224e-02, -4.8976e-02, -9.0517e-03,  3.5259e-02,\n         -4.4643e-02, -4.4473e-02,  3.3178e-02, -2.0099e-02, -7.1318e-03,\n          7.3179e-03, -5.6166e-03,  4.8161e-02,  1.8558e-02, -2.1767e-02,\n         -7.0796e-03, -2.8087e-02,  6.0145e-02, -3.5429e-02, -4.6039e-02,\n         -2.4594e-02, -4.9719e-02, -2.5513e-02,  2.8310e-02, -3.1527e-02,\n         -3.1042e-02,  1.5367e-02, -1.5218e-02, -4.2219e-02,  3.4638e-03,\n         -6.1562e-02,  1.8113e-02,  2.7047e-02, -6.0515e-02, -1.9570e-04,\n          4.1359e-02,  1.4679e-02, -3.2822e-02, -2.3895e-02, -3.7231e-02,\n         -4.6841e-02,  5.4524e-02,  2.1658e-02, -2.6191e-02, -5.0055e-02,\n          3.3266e-02, -4.4339e-02,  6.2350e-03, -5.2591e-02, -2.8909e-03,\n          5.7354e-02, -3.2398e-02, -6.1121e-02,  2.1703e-02,  1.3556e-02,\n          4.6202e-02, -4.0231e-02,  3.3896e-04, -2.7437e-02,  1.8636e-02,\n         -4.5120e-02, -1.5158e-02, -4.2555e-02,  8.8862e-03, -2.6450e-02,\n          4.1052e-02],\n        [ 5.7454e-02,  4.5058e-02, -2.8317e-02,  9.6026e-03, -3.3439e-02,\n         -2.1535e-02,  6.1609e-03, -6.4634e-03,  4.8397e-02, -8.0976e-04,\n          2.9914e-02, -5.8263e-02,  4.5082e-02, -2.9109e-02, -3.0090e-02,\n         -6.2373e-02, -6.2219e-02,  4.8708e-03, -3.6894e-02,  2.0139e-02,\n          5.9661e-02,  2.2438e-02, -6.0632e-02, -4.7058e-02,  2.8859e-02,\n         -4.8921e-02, -5.3941e-02,  1.0461e-02, -1.4912e-03,  4.7038e-02,\n          4.9554e-02, -2.5301e-02, -1.7063e-02, -1.2578e-02,  3.3010e-02,\n          1.4477e-02,  3.8827e-02, -2.4149e-02, -5.1312e-02, -3.3827e-02,\n         -5.8316e-02, -4.6354e-02, -5.2413e-02,  4.2478e-02,  1.3623e-02,\n          5.2481e-02,  3.1054e-03, -2.7862e-02,  1.0981e-02,  1.6863e-02,\n         -1.1249e-02, -1.3443e-02, -3.1842e-02, -3.0497e-02,  1.2903e-03,\n         -1.8698e-02,  2.3219e-02, -1.3956e-02,  3.4970e-02, -1.2143e-02,\n          2.8276e-02,  3.1505e-03,  4.3355e-02, -1.3152e-02,  2.8764e-02,\n          1.8895e-02,  5.9398e-02,  2.3092e-02,  5.5753e-02, -2.3797e-02,\n          1.2399e-02,  3.0812e-02,  2.3646e-02, -1.7164e-03, -2.3159e-02,\n         -2.1681e-02, -4.8665e-02,  9.4970e-03,  1.0137e-02,  2.0323e-02,\n          4.8283e-02,  3.3770e-03, -4.7562e-02,  5.1089e-02, -8.3045e-03,\n          1.8764e-02, -5.0342e-02, -4.8200e-03, -2.6801e-02, -2.9844e-03,\n         -2.7471e-02,  3.0838e-02, -2.5140e-02, -3.1490e-03, -5.0561e-02,\n          5.0871e-03, -2.4195e-02, -3.8189e-02,  5.0358e-05,  5.0408e-02,\n         -1.9806e-02, -7.6828e-03,  2.5709e-02,  5.2703e-02,  5.3084e-02,\n          7.4778e-04,  1.1595e-02, -5.5334e-02, -1.7039e-02,  5.8033e-02,\n          4.6508e-02, -4.8204e-02, -5.1268e-02, -3.9107e-02,  1.9972e-02,\n          2.9479e-02, -4.3707e-02,  1.0844e-03,  9.5288e-03,  3.3115e-02,\n          2.9815e-02,  5.1017e-02, -6.0316e-02, -2.2462e-02,  2.4875e-02,\n          1.7425e-03, -1.3190e-02, -1.1203e-02,  4.6913e-02, -8.9444e-03,\n          1.8103e-02,  8.7861e-03, -4.5732e-02, -3.2436e-02,  5.4780e-03,\n          4.6254e-02,  4.4766e-02, -1.4231e-02,  3.3950e-02,  3.8489e-02,\n         -1.9364e-02,  3.9205e-02, -3.0073e-02,  5.1559e-02,  5.0060e-02,\n         -3.8754e-02, -5.5984e-02, -5.7404e-02,  5.0497e-02, -4.8585e-02,\n         -5.7034e-02,  6.3831e-03, -3.6545e-02,  3.1704e-02,  5.4925e-02,\n          6.5841e-03,  3.4278e-02,  4.9688e-03,  5.8060e-02, -3.6803e-02,\n          1.1048e-02, -6.7351e-03,  2.8072e-02, -8.3644e-03,  4.3363e-02,\n          3.2519e-03, -5.1070e-02, -3.0732e-02, -5.6665e-02, -4.3732e-02,\n          2.2879e-02, -6.1774e-02,  3.3243e-02,  9.0315e-03, -4.7999e-02,\n         -2.2573e-02, -5.9884e-02, -1.2378e-02,  5.9045e-02,  2.9512e-02,\n          4.6932e-02,  1.0502e-02,  1.3195e-02,  2.8691e-02, -4.7618e-02,\n          5.3908e-03,  3.6562e-02,  5.5809e-02, -5.4790e-02, -1.4019e-02,\n         -2.9631e-02,  1.0266e-02,  2.2250e-02, -5.2885e-02, -3.9302e-02,\n          1.0473e-02, -1.9716e-02, -3.0295e-02, -6.2168e-02, -2.0362e-02,\n          1.1706e-02, -5.5644e-02,  3.4809e-02,  8.0311e-04,  5.6560e-02,\n         -4.4043e-02, -2.7580e-02,  2.5577e-02,  4.3626e-02,  3.1293e-02,\n         -8.8088e-03, -3.8444e-02,  3.5484e-02,  1.0399e-02,  5.4511e-02,\n         -5.2267e-03,  2.1604e-02,  2.0689e-02,  5.6147e-02,  3.4622e-02,\n         -6.4848e-03, -4.7649e-02, -2.4433e-02, -2.1759e-02, -4.0691e-02,\n          2.2269e-02, -2.5158e-02,  3.8042e-02, -4.2510e-02,  2.7479e-02,\n          5.6316e-03,  4.0246e-03,  1.5221e-03, -9.1264e-03, -3.0843e-02,\n         -1.6612e-02,  1.8427e-02, -4.4932e-02, -1.6035e-02,  3.8048e-02,\n         -8.3792e-03, -5.1971e-02, -5.6108e-02,  1.3894e-02, -5.9453e-02,\n         -5.5200e-02, -5.6137e-03,  1.2901e-02,  3.7651e-02, -5.3007e-02,\n          3.7677e-02,  3.7266e-02, -4.8865e-02, -1.6006e-02,  1.6093e-02,\n          5.7319e-02]], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0339, -0.0256], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1298, -0.2212, -0.2846,  0.1385],\n        [ 0.2766,  0.1821, -0.4600,  0.1437],\n        [-0.4907,  0.2830,  0.2819,  0.0194],\n        ...,\n        [ 0.2698, -0.0346, -0.2598, -0.1458],\n        [ 0.2572, -0.0251, -0.1817,  0.2091],\n        [ 0.4902,  0.2523, -0.2817, -0.0128]], device='cuda:0',\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0290, -0.1145, -0.0660, -0.0373, -0.3267,  0.0126, -0.4886, -0.2750,\n        -0.3283, -0.0967,  0.0219, -0.2301,  0.2991,  0.2299,  0.1215,  0.2964,\n        -0.3071, -0.3243,  0.0457,  0.2193, -0.4251, -0.0467,  0.0990,  0.3500,\n        -0.3833, -0.0221, -0.4643, -0.1733,  0.2285,  0.2291,  0.0031, -0.4485,\n        -0.4698,  0.4632,  0.0316, -0.3789,  0.1312, -0.0713,  0.4102,  0.1044,\n         0.2670, -0.4494, -0.1593,  0.1233, -0.5000,  0.0557, -0.4926, -0.3504,\n         0.2960, -0.1449,  0.2107, -0.2437,  0.2563, -0.1217,  0.2817,  0.0793,\n        -0.2548, -0.4924, -0.2933, -0.1720,  0.0268,  0.0075,  0.4960,  0.0385,\n         0.1497, -0.1715,  0.1861,  0.1153,  0.0072, -0.2398, -0.2796,  0.3501,\n        -0.2943, -0.4778, -0.2045, -0.1804, -0.0870,  0.1673,  0.3141, -0.2550,\n        -0.2367,  0.1137, -0.3174, -0.1768,  0.2714,  0.3668, -0.0391, -0.3422,\n         0.2964, -0.2188,  0.3997,  0.1952,  0.4604,  0.1389, -0.0988,  0.0154,\n        -0.1831, -0.3675,  0.0690, -0.4550,  0.0651, -0.1407, -0.0886, -0.4227,\n         0.2116,  0.4604, -0.1755, -0.1853, -0.3510,  0.0673, -0.3130, -0.1118,\n         0.4197,  0.2596,  0.1203,  0.1568, -0.3339, -0.0598, -0.1860,  0.0378,\n         0.1695,  0.3859,  0.2167, -0.1848,  0.0865, -0.1485, -0.4984, -0.4224,\n         0.4365,  0.3388,  0.0624,  0.3922,  0.2480, -0.1169,  0.0464, -0.1335,\n        -0.2286,  0.0164, -0.4118, -0.3478, -0.3522, -0.2627, -0.3254, -0.1034,\n         0.3458,  0.0475, -0.2511,  0.4250,  0.1684, -0.1452, -0.2503, -0.3781,\n        -0.4330, -0.3379,  0.1563, -0.0775, -0.3200, -0.0937, -0.3742, -0.2946,\n        -0.3419, -0.0227,  0.3673, -0.0395,  0.4269,  0.2444, -0.1320,  0.0528,\n        -0.4629, -0.3743,  0.2453,  0.4376,  0.0904, -0.1283,  0.1650,  0.3082,\n         0.1688, -0.2560,  0.2868, -0.0032, -0.1436, -0.2712, -0.3660,  0.0670,\n         0.0665,  0.4443, -0.3624,  0.0670, -0.3484,  0.0629, -0.4814, -0.0782,\n        -0.0981, -0.3608, -0.4695,  0.2772,  0.1644, -0.3063, -0.1772,  0.1063,\n         0.2820, -0.4574,  0.1419,  0.0131, -0.2264, -0.1254, -0.3272, -0.3202,\n         0.2530, -0.2182,  0.2519,  0.2208, -0.4772,  0.0964,  0.0487, -0.3381,\n        -0.4866,  0.1433,  0.3350,  0.0771, -0.2538,  0.3221, -0.1189,  0.0796,\n        -0.0331,  0.0524,  0.1004, -0.2211, -0.4443, -0.3033, -0.3381,  0.2769,\n        -0.3335,  0.3241, -0.1402, -0.0296, -0.0858, -0.4495,  0.3946, -0.3463,\n        -0.0769,  0.4904, -0.1490, -0.3573,  0.1338, -0.3741,  0.4622, -0.4332,\n         0.2613, -0.0756,  0.1712,  0.4687, -0.1898, -0.3281, -0.2226, -0.1625],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.2573e-02, -3.0363e-02,  3.4008e-02,  ...,  8.6647e-03,\n          1.1560e-02, -1.4140e-02],\n        [-3.9068e-02, -2.2558e-02,  5.5355e-03,  ...,  2.0758e-02,\n         -3.2366e-02,  3.4633e-02],\n        [ 1.2757e-02, -2.7424e-02,  2.8040e-02,  ..., -5.8893e-02,\n         -3.1864e-02, -1.3186e-02],\n        ...,\n        [ 2.1602e-02,  1.1588e-02,  4.5458e-03,  ...,  1.2327e-02,\n          4.8816e-02, -3.2194e-02],\n        [-4.3114e-02,  6.0637e-02,  1.1496e-05,  ...,  3.1135e-02,\n         -1.3356e-02, -3.2217e-02],\n        [-2.7925e-02,  2.4817e-03, -5.8972e-02,  ..., -1.5074e-02,\n         -5.7299e-02, -1.9535e-02]], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0180,  0.0571,  0.0068, -0.0161,  0.0036,  0.0566,  0.0062,  0.0115,\n         0.0406,  0.0254, -0.0129, -0.0160,  0.0178,  0.0407,  0.0533,  0.0237,\n         0.0471,  0.0523,  0.0361,  0.0424,  0.0359, -0.0036, -0.0304,  0.0131,\n        -0.0394, -0.0452, -0.0605, -0.0502,  0.0364, -0.0304, -0.0521, -0.0011,\n        -0.0337, -0.0368,  0.0584, -0.0407,  0.0208,  0.0177,  0.0596,  0.0474,\n         0.0509, -0.0625, -0.0621, -0.0268, -0.0623, -0.0172,  0.0607,  0.0171,\n        -0.0305, -0.0203, -0.0474, -0.0219,  0.0005, -0.0617, -0.0067,  0.0114,\n         0.0255, -0.0121, -0.0496, -0.0573,  0.0348, -0.0033,  0.0135,  0.0607,\n         0.0200, -0.0583, -0.0126,  0.0289,  0.0192, -0.0046, -0.0443, -0.0599,\n         0.0528,  0.0366, -0.0612, -0.0187,  0.0112,  0.0592,  0.0524,  0.0537,\n         0.0520, -0.0201, -0.0599,  0.0064,  0.0411, -0.0029, -0.0339, -0.0481,\n        -0.0402, -0.0160,  0.0595,  0.0030,  0.0437, -0.0299,  0.0273,  0.0511,\n        -0.0395,  0.0165,  0.0315, -0.0132,  0.0544, -0.0275,  0.0602, -0.0200,\n        -0.0269, -0.0229,  0.0623, -0.0275,  0.0330,  0.0175, -0.0356, -0.0234,\n        -0.0243, -0.0259,  0.0067, -0.0454, -0.0201,  0.0376, -0.0509, -0.0467,\n        -0.0355,  0.0335, -0.0600, -0.0513, -0.0414, -0.0532, -0.0081, -0.0175,\n         0.0610,  0.0118,  0.0105,  0.0011, -0.0597, -0.0330, -0.0435,  0.0485,\n        -0.0623, -0.0400,  0.0614, -0.0363,  0.0258, -0.0516,  0.0511,  0.0450,\n        -0.0165, -0.0482, -0.0072, -0.0199, -0.0611, -0.0060, -0.0187, -0.0558,\n        -0.0434, -0.0180,  0.0412, -0.0129, -0.0456, -0.0066,  0.0436, -0.0263,\n         0.0566, -0.0327,  0.0300, -0.0443, -0.0008, -0.0486, -0.0476,  0.0225,\n        -0.0333,  0.0495, -0.0441, -0.0563, -0.0379,  0.0114, -0.0322,  0.0435,\n        -0.0446,  0.0322,  0.0589, -0.0338,  0.0161, -0.0387,  0.0426,  0.0599,\n         0.0228, -0.0504,  0.0528, -0.0176,  0.0490, -0.0396,  0.0326,  0.0363,\n        -0.0489,  0.0003,  0.0231, -0.0006,  0.0443, -0.0197, -0.0419,  0.0312,\n        -0.0133, -0.0398, -0.0478, -0.0232, -0.0338, -0.0291,  0.0204,  0.0197,\n         0.0118, -0.0202,  0.0264, -0.0625, -0.0403,  0.0294, -0.0111, -0.0415,\n         0.0347, -0.0541, -0.0285, -0.0039, -0.0373, -0.0104, -0.0010,  0.0565,\n        -0.0145,  0.0020, -0.0295, -0.0320,  0.0459, -0.0353,  0.0484,  0.0083,\n        -0.0183,  0.0029,  0.0448, -0.0398,  0.0560,  0.0298, -0.0464,  0.0342,\n         0.0409,  0.0378, -0.0458, -0.0399, -0.0591, -0.0200, -0.0488,  0.0191,\n         0.0382,  0.0555, -0.0350, -0.0478, -0.0054,  0.0189, -0.0342, -0.0517],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-4.5320e-02, -4.3285e-02,  3.9831e-02,  3.5646e-02,  4.3496e-04,\n          4.5331e-02,  5.9911e-02,  3.2141e-04,  2.0202e-02,  3.0322e-02,\n          1.1896e-02,  5.0360e-02, -2.9928e-02,  4.3472e-03, -6.0561e-02,\n          1.5946e-02,  4.9403e-02,  2.9060e-02,  1.6339e-02, -1.0013e-02,\n          4.3396e-02,  4.7619e-02, -4.4034e-02,  4.6203e-02,  5.0311e-02,\n         -5.9997e-02,  5.9593e-02,  7.6818e-03,  1.7997e-02,  2.2810e-02,\n         -3.2233e-02,  4.0730e-02,  3.2331e-02,  1.6433e-02, -2.2317e-03,\n         -3.0240e-02, -5.5449e-02, -4.1709e-02, -1.8044e-02,  3.0528e-02,\n         -4.5471e-02,  9.0617e-03, -3.9050e-02, -1.5672e-02, -4.6976e-02,\n         -1.9595e-02, -4.3725e-02, -4.9003e-02,  6.2764e-03,  9.3671e-03,\n         -2.2823e-02,  1.6382e-02,  2.9085e-02,  3.0590e-03,  4.9841e-02,\n          3.3353e-02, -3.4112e-02, -4.7911e-02, -5.7419e-02, -1.4643e-02,\n         -2.0989e-02,  2.7641e-03,  1.1842e-02, -1.9344e-02,  3.3124e-02,\n          4.2960e-02,  1.6693e-02, -4.5054e-02, -1.5038e-02, -6.8432e-03,\n          5.2325e-03, -1.6878e-02,  3.2655e-02, -4.9473e-02, -3.9289e-02,\n          4.8467e-02, -5.6936e-02,  2.6813e-02, -5.2174e-02, -7.8691e-03,\n          2.4432e-02,  2.9676e-02, -1.3208e-02, -4.4179e-02,  2.5774e-02,\n         -3.1245e-02, -1.2471e-02, -2.8358e-02, -3.8136e-02,  5.7951e-02,\n         -4.4963e-02,  8.2170e-04, -5.6718e-02,  3.0459e-02,  5.3141e-03,\n          4.4787e-02,  5.6498e-02,  3.3972e-02, -2.4048e-02, -5.9263e-03,\n          5.4981e-03, -1.4650e-02,  4.9056e-03, -7.8577e-03,  2.4069e-02,\n         -1.3624e-02, -5.3591e-02,  3.2923e-02,  4.5546e-02,  4.9713e-02,\n          1.2761e-02, -3.3219e-02,  5.1345e-02,  3.4908e-02,  3.6084e-02,\n          3.0883e-02, -5.0442e-02,  6.0378e-02,  2.4006e-02, -4.2679e-02,\n          5.4741e-02,  4.9416e-02, -4.6410e-02, -2.4330e-02,  4.1201e-02,\n          5.3309e-02,  4.2248e-02,  4.4630e-02, -4.9638e-02, -2.6197e-02,\n          5.0665e-02,  1.0157e-02, -1.9666e-02, -2.3535e-03, -3.8100e-02,\n         -3.0332e-02, -3.7852e-02,  5.3157e-02, -6.0544e-02,  2.7405e-02,\n          4.4898e-02,  2.6490e-02,  4.8072e-02, -5.4813e-02,  1.1396e-02,\n         -1.1630e-02,  5.3641e-02,  1.8908e-02, -3.7403e-02, -1.0188e-02,\n         -3.7711e-02, -8.7358e-04,  4.6326e-02,  6.1561e-03, -1.4242e-02,\n          1.9100e-02, -3.3535e-02,  4.1680e-02, -3.8657e-02,  6.0534e-02,\n          5.3726e-02,  3.2471e-02,  3.7761e-02,  4.7851e-02,  2.7681e-02,\n         -1.5360e-02, -3.7640e-02, -5.7792e-02,  1.0835e-02,  3.9421e-02,\n          3.3378e-02, -3.6482e-02,  1.9653e-02, -3.4163e-02,  5.8173e-02,\n         -3.5044e-02,  2.9626e-02, -4.1131e-02,  5.8608e-02, -2.2617e-02,\n         -1.8576e-02,  5.8734e-02,  2.2270e-02, -2.4208e-02, -1.1179e-02,\n          1.2145e-02, -1.6433e-02,  1.9029e-02,  1.6702e-02, -5.5701e-02,\n          2.9336e-02,  3.5507e-02,  3.5825e-02,  4.6501e-02,  3.9044e-02,\n          5.6934e-02,  5.8284e-03, -4.4347e-02, -5.7323e-02,  2.6777e-02,\n         -2.7898e-02,  7.4982e-03,  2.7456e-02, -4.8860e-02, -1.0909e-02,\n          2.5413e-04,  2.4200e-02,  2.2069e-02,  4.3434e-02,  2.3006e-02,\n          3.9480e-02, -7.7999e-03,  4.4995e-02,  4.6018e-03, -1.7064e-02,\n         -5.3319e-02, -1.0883e-02,  4.5776e-02, -5.8425e-02,  4.8154e-02,\n         -1.4999e-02, -2.5724e-02, -2.3181e-02,  4.3677e-02, -5.4947e-02,\n          1.7388e-02, -2.7722e-02, -5.6883e-02, -5.8093e-04,  2.8396e-02,\n          6.2952e-03,  1.2465e-03,  3.1102e-02, -2.1257e-02,  5.8814e-02,\n         -1.2635e-02, -4.1419e-02, -3.2427e-03,  3.5820e-02, -2.3744e-02,\n         -2.1826e-02, -3.8083e-04,  2.5404e-02, -4.0319e-03, -6.6040e-04,\n         -5.0947e-02, -4.7234e-02, -4.9268e-02,  3.4094e-02, -1.9747e-03,\n          2.4816e-02, -8.2143e-05, -2.5160e-02, -1.4989e-02, -5.9384e-02,\n          1.8326e-03],\n        [-5.3580e-02, -7.6978e-03, -2.0866e-02,  1.6719e-02, -1.6956e-02,\n          3.8104e-02, -6.1697e-02,  8.3346e-03,  3.7452e-02,  4.3413e-02,\n          3.9356e-02,  3.5525e-03,  4.4565e-02, -5.2745e-02,  3.2745e-02,\n         -5.2167e-04, -2.3373e-02,  9.5391e-03,  4.1961e-02, -3.3728e-02,\n          2.5912e-02, -1.8922e-02, -7.1048e-03,  4.6341e-02,  6.8856e-03,\n          6.5757e-03, -4.9498e-02,  5.5083e-02,  1.9236e-02,  3.6218e-02,\n         -5.1799e-02,  3.0335e-02,  3.5281e-02,  3.6199e-02, -7.2493e-03,\n          5.4088e-02, -6.0521e-02,  8.2754e-05, -2.8085e-02,  1.2285e-02,\n         -4.7847e-02, -2.4299e-02, -6.0272e-02, -5.7520e-02, -4.9323e-02,\n          4.8360e-02,  3.9737e-02,  2.3570e-03,  3.2809e-03,  3.6694e-02,\n         -2.3566e-02,  1.6804e-02, -6.2031e-02, -1.2891e-02, -9.3096e-03,\n         -1.0324e-02,  1.2324e-02,  1.0243e-02,  1.4787e-02,  1.0888e-02,\n          5.6204e-02,  5.9298e-02, -1.8818e-02,  5.2134e-02, -4.7078e-02,\n          1.7681e-02, -4.2611e-03,  5.5445e-02,  3.3658e-02, -5.6581e-02,\n         -5.8154e-02,  4.0322e-02, -5.5973e-02, -1.7193e-03,  1.0708e-02,\n          1.6799e-02, -4.7714e-02,  3.5961e-02,  6.0243e-02,  1.1119e-02,\n         -5.7433e-02, -4.1154e-02, -5.6147e-02,  3.8439e-02, -2.6060e-02,\n         -4.3853e-02,  3.1502e-03, -1.0103e-02, -2.4678e-02,  3.8755e-02,\n          1.0089e-02, -1.5827e-02,  4.0332e-03, -5.0306e-03,  2.9502e-02,\n         -7.0741e-03,  1.8133e-02,  7.3761e-03, -3.0817e-03,  4.6040e-02,\n          2.0858e-02,  3.9110e-02,  5.5519e-02, -5.3168e-02, -5.0600e-03,\n         -2.0244e-02,  3.5218e-02, -5.3613e-02,  2.0115e-02,  1.9626e-02,\n          3.4896e-03, -3.1369e-02, -4.3026e-02, -1.6815e-02,  5.2387e-02,\n         -2.4194e-02, -1.5073e-02,  5.3163e-03,  1.3406e-02,  1.9487e-02,\n          2.2957e-02,  3.4846e-02, -3.0049e-02,  9.3546e-03,  2.6198e-02,\n          2.2760e-02,  4.6307e-02,  5.6098e-02,  3.4952e-02,  1.2398e-02,\n          3.9067e-02, -4.6304e-03,  5.0569e-02, -1.4478e-02, -3.2022e-02,\n         -2.3514e-02,  3.5755e-02,  5.1459e-02,  4.3608e-02,  1.9900e-02,\n         -5.8269e-02,  5.7878e-02, -3.8815e-02,  1.2587e-02, -2.9434e-02,\n         -1.8371e-02,  6.8510e-03, -5.7422e-02, -3.1840e-02, -6.7899e-04,\n         -5.8167e-05,  1.5687e-02, -1.2836e-02,  3.7322e-02,  3.1165e-02,\n         -5.3349e-02, -5.5576e-02,  1.7756e-02,  1.2865e-02,  2.5265e-02,\n         -9.0838e-03, -4.1317e-02, -3.3871e-02,  1.1511e-03, -4.6128e-02,\n          5.9619e-02, -1.7614e-02,  1.8629e-02,  2.6520e-02, -6.0923e-02,\n          3.9699e-02, -3.0792e-02,  5.2315e-02,  6.1510e-02, -5.8246e-02,\n         -5.7492e-02,  5.7301e-02, -1.0059e-02,  6.1893e-03,  4.5890e-02,\n         -3.6105e-02, -4.9430e-02,  5.6902e-02,  2.0788e-02, -2.4791e-02,\n          1.3720e-02,  4.9924e-02,  5.7998e-02,  5.0396e-02,  8.9931e-03,\n          3.8658e-02, -3.3123e-03,  5.3835e-02,  3.6809e-02,  2.9982e-02,\n          1.3040e-02,  1.4449e-02, -4.4134e-03,  6.2828e-03,  5.9483e-02,\n         -5.8289e-02, -5.6318e-03, -3.6926e-03,  2.9829e-02, -1.1631e-02,\n         -3.0765e-02, -4.3862e-02, -6.1831e-03,  1.3510e-03,  5.8283e-02,\n         -1.2201e-02,  5.8510e-02, -6.1373e-02, -4.7874e-02,  4.5690e-02,\n         -3.7745e-03, -2.9547e-02, -2.4893e-02,  3.0861e-02, -9.3280e-03,\n         -1.1658e-02,  4.8747e-02, -2.3986e-02, -2.3798e-02, -2.5947e-02,\n         -4.9524e-02, -1.6577e-02, -3.3801e-02,  2.4912e-02,  1.1998e-02,\n          4.2159e-03,  3.5738e-03, -5.8949e-02,  2.2693e-02, -1.2792e-02,\n         -2.3228e-02, -4.8938e-02, -2.4337e-02, -4.9047e-02, -6.2425e-02,\n          9.0554e-03,  4.4007e-02, -1.7237e-03, -3.0090e-02,  5.5654e-02,\n         -5.1312e-02,  2.4862e-02,  1.9600e-02,  7.4906e-03, -6.1055e-02,\n          4.1439e-02,  5.9419e-02, -5.6514e-02,  5.2410e-02,  3.3153e-02,\n         -4.1536e-02]], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0513, -0.0575], device='cuda:0', requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "q_params":	"<itertools.chain object at 0x7fe2284b68d0>",
            "target_entropy":	0.6792842369487464,
            "test_env":	{
                "<TimeLimit<CartPoleEnv<CartPole-v0>>>":	{
                    "_action_space":	null,
                    "_elapsed_steps":	null,
                    "_max_episode_steps":	200,
                    "_metadata":	null,
                    "_observation_space":	null,
                    "_reward_range":	null,
                    "env":	{
                        "<CartPoleEnv<CartPole-v0>>":	{
                            "action_space":	{
                                "Discrete(2)":	{
                                    "_np_random":	null,
                                    "_shape":	[],
                                    "dtype":	"int64",
                                    "n":	2
                                }
                            },
                            "force_mag":	10.0,
                            "gravity":	9.8,
                            "kinematics_integrator":	"euler",
                            "length":	0.5,
                            "masscart":	1.0,
                            "masspole":	0.1,
                            "np_random":	"RandomState(MT19937)",
                            "observation_space":	{
                                "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)":	{
                                    "_np_random":	null,
                                    "_shape":	[
                                        4
                                    ],
                                    "bounded_above":	"[ True  True  True  True]",
                                    "bounded_below":	"[ True  True  True  True]",
                                    "dtype":	"float32",
                                    "high":	"[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]",
                                    "low":	"[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]"
                                }
                            },
                            "polemass_length":	0.05,
                            "spec":	{
                                "EnvSpec(CartPole-v0)":	{
                                    "_env_name":	"CartPole",
                                    "_kwargs":	{},
                                    "entry_point":	"gym.envs.classic_control:CartPoleEnv",
                                    "id":	"CartPole-v0",
                                    "max_episode_steps":	200,
                                    "nondeterministic":	false,
                                    "order_enforce":	true,
                                    "reward_threshold":	195.0
                                }
                            },
                            "state":	null,
                            "steps_beyond_done":	null,
                            "tau":	0.02,
                            "theta_threshold_radians":	0.20943951023931953,
                            "total_mass":	1.1,
                            "viewer":	null,
                            "x_threshold":	2.4
                        }
                    }
                }
            }
        }
    }
}