{
    "ac_kwargs":	{
        "hidden_sizes":	[
            256,
            256
        ]
    },
    "actor_critic":	"MLPActorCritic",
    "alpha":	0.2,
    "delayup":	0.995,
    "device":	"cuda:0",
    "env_fn":	"<function <lambda> at 0x7fe2aa2f8a70>",
    "exp_name":	"sac_hopper",
    "gamma":	0.99,
    "logger_kwargs":	{
        "exp_name":	"sac_hopper",
        "output_dir":	"/home/cxliu/deeplearning_zp/spinningup_project/data/sac_hopper/sac_hopper_s0"
    },
    "max_ep_len":	1000,
    "num_test_episodes":	10,
    "p":	"Parameter containing:\ntensor([0.0242], device='cuda:0')",
    "pi_lr":	0.001,
    "q_lr":	0.001,
    "replay_size":	1000000,
    "self":	{
        "<spinup.alogos.sac.sac.sac object at 0x7fe2a923cb50>":	{
            "ac":	{
                "MLPActorCritic(\n  (pi): SquashedGaussianMLPActor(\n    (net): Sequential(\n      (0): Linear(in_features=11, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu_layer): Linear(in_features=256, out_features=3, bias=True)\n    (log_std_layer): Linear(in_features=256, out_features=3, bias=True)\n  )\n  (q1): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=14, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n      (5): Identity()\n    )\n  )\n  (q2): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=14, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n      (5): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "SquashedGaussianMLPActor(\n  (net): Sequential(\n    (0): Linear(in_features=11, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu_layer): Linear(in_features=256, out_features=3, bias=True)\n  (log_std_layer): Linear(in_features=256, out_features=3, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "log_std_layer":	{
                                        "Linear(in_features=256, out_features=3, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0445, -0.0330, -0.0369], device='cuda:0', requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0563,  0.0496,  0.0195,  0.0203, -0.0011,  0.0380, -0.0097,  0.0317,\n         -0.0462, -0.0538, -0.0289,  0.0383, -0.0025, -0.0546,  0.0145, -0.0118,\n          0.0444,  0.0108,  0.0052, -0.0580,  0.0158, -0.0621, -0.0299,  0.0412,\n         -0.0406,  0.0239,  0.0578,  0.0084,  0.0291, -0.0384,  0.0056, -0.0492,\n          0.0560, -0.0148,  0.0322, -0.0418, -0.0121, -0.0526,  0.0309,  0.0024,\n         -0.0211, -0.0452,  0.0610, -0.0270,  0.0519, -0.0538, -0.0339,  0.0341,\n         -0.0218,  0.0385, -0.0374,  0.0202, -0.0085,  0.0566, -0.0339, -0.0025,\n          0.0184, -0.0416, -0.0270,  0.0282, -0.0111, -0.0437, -0.0022, -0.0563,\n          0.0276,  0.0355, -0.0483,  0.0610,  0.0231,  0.0229,  0.0312,  0.0506,\n         -0.0619,  0.0551, -0.0439, -0.0312, -0.0496, -0.0030, -0.0261,  0.0610,\n         -0.0279, -0.0556, -0.0514, -0.0016, -0.0476,  0.0093, -0.0451,  0.0348,\n          0.0427,  0.0543, -0.0537, -0.0232,  0.0508,  0.0276, -0.0039, -0.0018,\n         -0.0332, -0.0366,  0.0225, -0.0516, -0.0252, -0.0044,  0.0476, -0.0199,\n          0.0061, -0.0324, -0.0513, -0.0417, -0.0270,  0.0142,  0.0150, -0.0613,\n         -0.0489,  0.0117,  0.0611, -0.0405, -0.0564, -0.0496,  0.0551,  0.0115,\n         -0.0464,  0.0308,  0.0567,  0.0538,  0.0096, -0.0452, -0.0252, -0.0354,\n          0.0040,  0.0004,  0.0478, -0.0591,  0.0351,  0.0389,  0.0075, -0.0101,\n          0.0136, -0.0458, -0.0513, -0.0231,  0.0089, -0.0234,  0.0198,  0.0563,\n         -0.0440, -0.0316, -0.0258,  0.0469,  0.0027, -0.0213, -0.0003, -0.0478,\n         -0.0416,  0.0557,  0.0605, -0.0152,  0.0190, -0.0189,  0.0356,  0.0508,\n         -0.0397,  0.0406, -0.0338,  0.0045,  0.0404,  0.0270,  0.0572, -0.0104,\n          0.0247, -0.0057,  0.0573, -0.0290,  0.0363, -0.0362,  0.0226,  0.0259,\n         -0.0192,  0.0250, -0.0438, -0.0314, -0.0422, -0.0435, -0.0304, -0.0190,\n         -0.0297, -0.0043, -0.0433,  0.0488, -0.0113,  0.0202,  0.0027, -0.0569,\n         -0.0477, -0.0609,  0.0051,  0.0330, -0.0090, -0.0351, -0.0527,  0.0325,\n         -0.0445, -0.0507, -0.0264, -0.0164,  0.0083,  0.0102,  0.0166,  0.0124,\n         -0.0096,  0.0385,  0.0083,  0.0572, -0.0518,  0.0263,  0.0455,  0.0407,\n          0.0470,  0.0355,  0.0343,  0.0080, -0.0547,  0.0140, -0.0423,  0.0342,\n         -0.0463,  0.0274, -0.0518, -0.0556, -0.0475, -0.0530, -0.0505,  0.0278,\n          0.0472, -0.0207,  0.0307, -0.0621, -0.0110,  0.0051,  0.0006, -0.0423,\n         -0.0145,  0.0329, -0.0028, -0.0579, -0.0142, -0.0473, -0.0236, -0.0501,\n          0.0620,  0.0026, -0.0306, -0.0076, -0.0174,  0.0455, -0.0010,  0.0287],\n        [-0.0385,  0.0224, -0.0323, -0.0375, -0.0288, -0.0282,  0.0267,  0.0350,\n          0.0332, -0.0031,  0.0397,  0.0275, -0.0242,  0.0253,  0.0399, -0.0095,\n          0.0179, -0.0161, -0.0143, -0.0490, -0.0139, -0.0314, -0.0457, -0.0007,\n         -0.0516,  0.0624, -0.0227,  0.0563,  0.0078, -0.0552, -0.0431,  0.0587,\n         -0.0119,  0.0558,  0.0392, -0.0224,  0.0214,  0.0484,  0.0332,  0.0007,\n         -0.0561,  0.0152,  0.0497,  0.0006, -0.0517,  0.0217, -0.0563,  0.0618,\n         -0.0609, -0.0559,  0.0621,  0.0335, -0.0569, -0.0186,  0.0072, -0.0514,\n          0.0346, -0.0022,  0.0020,  0.0554,  0.0511,  0.0326, -0.0612,  0.0510,\n         -0.0325,  0.0051,  0.0247,  0.0588,  0.0603, -0.0138, -0.0188, -0.0537,\n         -0.0311,  0.0167, -0.0334, -0.0358,  0.0097,  0.0337,  0.0257, -0.0562,\n          0.0076,  0.0313, -0.0260, -0.0358,  0.0136,  0.0062, -0.0326,  0.0548,\n          0.0457,  0.0155, -0.0201,  0.0313, -0.0453, -0.0088,  0.0569, -0.0353,\n          0.0127,  0.0163,  0.0016,  0.0048,  0.0557, -0.0361,  0.0481,  0.0073,\n         -0.0311,  0.0106,  0.0288,  0.0491, -0.0099,  0.0134, -0.0393,  0.0256,\n          0.0173, -0.0412,  0.0338,  0.0228, -0.0469, -0.0181, -0.0261, -0.0473,\n         -0.0536, -0.0161,  0.0094, -0.0335, -0.0384,  0.0439,  0.0029, -0.0172,\n         -0.0585, -0.0587, -0.0567,  0.0442,  0.0225, -0.0005, -0.0415, -0.0180,\n         -0.0017,  0.0560, -0.0178, -0.0431,  0.0551, -0.0226, -0.0146,  0.0389,\n          0.0223, -0.0498, -0.0480,  0.0450,  0.0472, -0.0610,  0.0602, -0.0328,\n         -0.0435, -0.0599,  0.0250,  0.0110, -0.0447,  0.0158, -0.0331,  0.0511,\n          0.0429, -0.0386, -0.0094,  0.0365,  0.0017, -0.0298, -0.0117,  0.0044,\n          0.0127,  0.0326,  0.0317,  0.0291,  0.0415,  0.0047, -0.0076,  0.0462,\n          0.0495, -0.0091, -0.0008,  0.0415,  0.0447,  0.0332, -0.0606,  0.0198,\n          0.0548, -0.0097,  0.0082,  0.0242, -0.0546,  0.0318, -0.0483, -0.0073,\n          0.0331,  0.0500,  0.0395, -0.0613,  0.0589, -0.0265,  0.0465,  0.0490,\n          0.0356, -0.0037,  0.0137,  0.0050, -0.0434, -0.0059,  0.0222, -0.0107,\n         -0.0097,  0.0152,  0.0545,  0.0382,  0.0099,  0.0508, -0.0145,  0.0390,\n         -0.0379,  0.0250,  0.0102, -0.0361,  0.0224,  0.0307,  0.0303,  0.0156,\n         -0.0120, -0.0372, -0.0190, -0.0434, -0.0107, -0.0119,  0.0462, -0.0545,\n          0.0477,  0.0382, -0.0449,  0.0388, -0.0336,  0.0089,  0.0031, -0.0049,\n         -0.0188, -0.0400,  0.0145, -0.0033,  0.0349, -0.0595,  0.0078,  0.0443,\n         -0.0379, -0.0206, -0.0558, -0.0003,  0.0284, -0.0154, -0.0390, -0.0066],\n        [ 0.0327, -0.0039,  0.0018, -0.0564, -0.0256, -0.0048,  0.0308,  0.0506,\n          0.0446, -0.0566,  0.0440, -0.0316,  0.0367, -0.0099,  0.0467, -0.0202,\n          0.0109,  0.0234,  0.0010, -0.0202, -0.0284, -0.0511, -0.0024, -0.0592,\n         -0.0127,  0.0080,  0.0323,  0.0175,  0.0091,  0.0253, -0.0609, -0.0371,\n          0.0518,  0.0566,  0.0410,  0.0329,  0.0007, -0.0439, -0.0310, -0.0516,\n         -0.0430,  0.0192,  0.0290,  0.0575,  0.0477, -0.0546, -0.0135, -0.0586,\n          0.0232, -0.0014,  0.0130, -0.0327, -0.0431,  0.0101, -0.0187,  0.0014,\n          0.0320, -0.0618,  0.0187,  0.0158,  0.0397, -0.0043,  0.0248, -0.0124,\n         -0.0344, -0.0583,  0.0556,  0.0611,  0.0360, -0.0316,  0.0078,  0.0019,\n          0.0247,  0.0223, -0.0391,  0.0546,  0.0228, -0.0500,  0.0318,  0.0590,\n          0.0116, -0.0289,  0.0012, -0.0304, -0.0442, -0.0303, -0.0236, -0.0027,\n         -0.0317, -0.0424, -0.0012, -0.0108, -0.0456,  0.0392, -0.0167, -0.0368,\n          0.0025,  0.0406,  0.0234,  0.0272,  0.0130,  0.0437, -0.0570, -0.0074,\n          0.0263, -0.0448,  0.0196, -0.0402,  0.0220,  0.0115, -0.0420,  0.0134,\n          0.0058, -0.0047, -0.0605,  0.0311, -0.0328, -0.0501,  0.0383, -0.0542,\n          0.0494,  0.0543, -0.0088,  0.0375,  0.0345,  0.0395, -0.0480,  0.0290,\n         -0.0337,  0.0569, -0.0392, -0.0452,  0.0305,  0.0173, -0.0399, -0.0474,\n          0.0276, -0.0548,  0.0432,  0.0037, -0.0571, -0.0532,  0.0113, -0.0009,\n          0.0585,  0.0278, -0.0025, -0.0202, -0.0186, -0.0456,  0.0432, -0.0117,\n          0.0443,  0.0309,  0.0189,  0.0432, -0.0405, -0.0443,  0.0489,  0.0177,\n          0.0484,  0.0290, -0.0472, -0.0555, -0.0407,  0.0072, -0.0222, -0.0276,\n         -0.0417, -0.0500, -0.0535,  0.0159, -0.0458,  0.0521,  0.0333,  0.0621,\n         -0.0362,  0.0540, -0.0525,  0.0285,  0.0115,  0.0333,  0.0532, -0.0615,\n          0.0084,  0.0341, -0.0514,  0.0219,  0.0122,  0.0164,  0.0596,  0.0441,\n          0.0327,  0.0577,  0.0502, -0.0311, -0.0036,  0.0143, -0.0098, -0.0257,\n         -0.0005, -0.0466, -0.0146,  0.0259,  0.0509, -0.0580, -0.0623,  0.0411,\n         -0.0222, -0.0399,  0.0208, -0.0381,  0.0004,  0.0244,  0.0468, -0.0352,\n         -0.0091,  0.0346,  0.0562,  0.0349, -0.0517, -0.0540,  0.0439, -0.0391,\n         -0.0476, -0.0384,  0.0122,  0.0478,  0.0616,  0.0328, -0.0399, -0.0300,\n          0.0607, -0.0353,  0.0523, -0.0483,  0.0480,  0.0184, -0.0209,  0.0256,\n         -0.0156, -0.0147, -0.0100,  0.0289,  0.0173,  0.0228,  0.0155, -0.0195,\n          0.0582,  0.0034, -0.0013, -0.0218,  0.0052,  0.0088, -0.0071, -0.0269]],\n       device='cuda:0', requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	256,
                                            "out_features":	3,
                                            "training":	true
                                        }
                                    },
                                    "mu_layer":	{
                                        "Linear(in_features=256, out_features=3, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0597,  0.0137,  0.0032], device='cuda:0', requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0056,  0.0561,  0.0589, -0.0065,  0.0556,  0.0223, -0.0463,  0.0330,\n         -0.0069,  0.0560, -0.0072,  0.0354,  0.0273, -0.0108, -0.0544,  0.0034,\n         -0.0073,  0.0294,  0.0025,  0.0331, -0.0106,  0.0118, -0.0584, -0.0353,\n          0.0291, -0.0313, -0.0553,  0.0581,  0.0494,  0.0623, -0.0229,  0.0168,\n          0.0106, -0.0269,  0.0534, -0.0575,  0.0598, -0.0386,  0.0315, -0.0032,\n          0.0591,  0.0589, -0.0335, -0.0380, -0.0243,  0.0012,  0.0135, -0.0178,\n          0.0452,  0.0147, -0.0530,  0.0295,  0.0515, -0.0520, -0.0285, -0.0164,\n          0.0173,  0.0423, -0.0273,  0.0327, -0.0558,  0.0616,  0.0585, -0.0262,\n         -0.0304, -0.0506,  0.0245,  0.0573, -0.0221, -0.0537,  0.0497, -0.0236,\n          0.0548, -0.0264, -0.0428, -0.0596, -0.0177, -0.0326, -0.0217,  0.0222,\n          0.0281,  0.0289, -0.0085,  0.0030, -0.0487,  0.0554,  0.0055,  0.0435,\n         -0.0394, -0.0414,  0.0478,  0.0398,  0.0389,  0.0252,  0.0427,  0.0580,\n          0.0587,  0.0112, -0.0101,  0.0553,  0.0232, -0.0535, -0.0264, -0.0004,\n          0.0377,  0.0028, -0.0145, -0.0206,  0.0124, -0.0063,  0.0426,  0.0306,\n         -0.0597,  0.0096, -0.0210, -0.0457,  0.0448,  0.0062,  0.0155, -0.0352,\n          0.0244, -0.0131, -0.0368,  0.0434, -0.0351,  0.0059,  0.0536, -0.0589,\n         -0.0411,  0.0320,  0.0365, -0.0076, -0.0533,  0.0188,  0.0073,  0.0292,\n         -0.0141, -0.0112, -0.0345,  0.0427, -0.0312, -0.0598, -0.0190, -0.0221,\n          0.0577,  0.0033,  0.0156,  0.0221, -0.0532, -0.0282,  0.0099, -0.0421,\n          0.0227,  0.0438,  0.0446,  0.0206, -0.0602,  0.0469,  0.0608, -0.0287,\n          0.0357, -0.0301, -0.0177, -0.0554, -0.0343, -0.0191,  0.0473,  0.0447,\n          0.0235,  0.0109,  0.0067, -0.0475, -0.0375, -0.0264, -0.0277, -0.0522,\n         -0.0298, -0.0372, -0.0191,  0.0384, -0.0002,  0.0118, -0.0458,  0.0581,\n         -0.0483,  0.0550,  0.0043,  0.0485, -0.0095,  0.0211,  0.0521, -0.0005,\n          0.0519, -0.0617,  0.0392, -0.0409, -0.0267, -0.0623, -0.0472, -0.0186,\n         -0.0368, -0.0108,  0.0609, -0.0118,  0.0012,  0.0438,  0.0371, -0.0026,\n         -0.0416,  0.0146,  0.0280, -0.0056, -0.0003,  0.0150, -0.0293, -0.0457,\n          0.0552, -0.0173, -0.0372, -0.0515, -0.0506,  0.0569, -0.0363, -0.0617,\n         -0.0362,  0.0546, -0.0261,  0.0448,  0.0092,  0.0080,  0.0412, -0.0539,\n         -0.0446,  0.0111,  0.0543, -0.0548,  0.0064, -0.0162,  0.0125, -0.0139,\n         -0.0458,  0.0109,  0.0502,  0.0168,  0.0592, -0.0257, -0.0608, -0.0479,\n          0.0018, -0.0322, -0.0271, -0.0044,  0.0087, -0.0122, -0.0112, -0.0581],\n        [-0.0151,  0.0022,  0.0048,  0.0454,  0.0432, -0.0490,  0.0471, -0.0133,\n          0.0333, -0.0519, -0.0049, -0.0050,  0.0172,  0.0405,  0.0025, -0.0216,\n          0.0012, -0.0130, -0.0274,  0.0004,  0.0009,  0.0458, -0.0557, -0.0240,\n         -0.0097,  0.0192, -0.0612,  0.0577, -0.0106,  0.0501,  0.0331,  0.0068,\n          0.0188,  0.0488,  0.0577,  0.0467, -0.0410, -0.0211, -0.0011, -0.0211,\n          0.0505, -0.0049, -0.0137, -0.0361, -0.0541,  0.0208,  0.0181,  0.0487,\n         -0.0436,  0.0479,  0.0379, -0.0244,  0.0343, -0.0148,  0.0388, -0.0269,\n         -0.0361, -0.0393,  0.0007, -0.0429, -0.0211,  0.0141,  0.0528,  0.0063,\n          0.0281,  0.0411,  0.0396, -0.0213,  0.0376,  0.0134, -0.0304, -0.0026,\n          0.0151,  0.0403, -0.0049,  0.0483, -0.0596, -0.0488, -0.0191, -0.0255,\n          0.0101, -0.0278, -0.0463, -0.0509,  0.0039,  0.0526, -0.0157, -0.0507,\n         -0.0497, -0.0604, -0.0550, -0.0614,  0.0017, -0.0170,  0.0564,  0.0121,\n          0.0288, -0.0288, -0.0326,  0.0515, -0.0371, -0.0361,  0.0448,  0.0145,\n          0.0041,  0.0593,  0.0018, -0.0577, -0.0502,  0.0264,  0.0210, -0.0589,\n          0.0153,  0.0041,  0.0163, -0.0476,  0.0188,  0.0478, -0.0050, -0.0396,\n          0.0581, -0.0467,  0.0497, -0.0202, -0.0598, -0.0319, -0.0259,  0.0569,\n         -0.0553,  0.0387,  0.0576, -0.0450,  0.0306,  0.0292,  0.0182, -0.0108,\n         -0.0570,  0.0550,  0.0481,  0.0289, -0.0569,  0.0037, -0.0456, -0.0271,\n         -0.0364, -0.0393, -0.0302, -0.0387,  0.0042,  0.0015,  0.0553,  0.0361,\n          0.0509,  0.0103,  0.0263, -0.0197, -0.0185, -0.0541,  0.0495,  0.0375,\n          0.0120,  0.0455, -0.0037,  0.0101, -0.0360,  0.0624,  0.0425,  0.0487,\n         -0.0420,  0.0305,  0.0443, -0.0174, -0.0596,  0.0440,  0.0223, -0.0420,\n          0.0438, -0.0231,  0.0282, -0.0310, -0.0606, -0.0406, -0.0418,  0.0348,\n          0.0295,  0.0216,  0.0227,  0.0244, -0.0521,  0.0618, -0.0182, -0.0261,\n          0.0017,  0.0403, -0.0365,  0.0470, -0.0168,  0.0006,  0.0560,  0.0244,\n         -0.0215,  0.0600,  0.0272, -0.0592, -0.0154,  0.0622, -0.0494, -0.0581,\n         -0.0108,  0.0560,  0.0495,  0.0367,  0.0471,  0.0367,  0.0511, -0.0128,\n         -0.0423,  0.0473,  0.0113,  0.0472,  0.0465, -0.0610,  0.0319, -0.0481,\n         -0.0089,  0.0154, -0.0182, -0.0266,  0.0499,  0.0293, -0.0065, -0.0167,\n          0.0564,  0.0618,  0.0129, -0.0500,  0.0102,  0.0198,  0.0490, -0.0252,\n          0.0588, -0.0307,  0.0134, -0.0603,  0.0498, -0.0316,  0.0390, -0.0037,\n         -0.0256, -0.0267,  0.0408,  0.0091,  0.0411, -0.0442, -0.0052,  0.0106],\n        [-0.0143, -0.0619, -0.0251,  0.0522, -0.0436, -0.0514,  0.0469, -0.0177,\n         -0.0108, -0.0009,  0.0573,  0.0261, -0.0424, -0.0129, -0.0065, -0.0618,\n          0.0336,  0.0397,  0.0151,  0.0356,  0.0135, -0.0227,  0.0465,  0.0220,\n         -0.0351,  0.0226, -0.0296,  0.0140, -0.0004,  0.0387,  0.0413, -0.0349,\n          0.0344, -0.0504, -0.0180, -0.0287,  0.0254, -0.0060,  0.0368,  0.0222,\n          0.0537,  0.0528,  0.0521, -0.0161, -0.0551, -0.0564,  0.0457,  0.0266,\n          0.0580,  0.0078, -0.0148, -0.0030,  0.0467, -0.0525,  0.0505,  0.0476,\n         -0.0122, -0.0560, -0.0266, -0.0148, -0.0159,  0.0410, -0.0049, -0.0068,\n          0.0292,  0.0388,  0.0486, -0.0145, -0.0583,  0.0311,  0.0160, -0.0118,\n          0.0029, -0.0430, -0.0506,  0.0247, -0.0073, -0.0458,  0.0263, -0.0209,\n          0.0487,  0.0260, -0.0563, -0.0228, -0.0316,  0.0172,  0.0068, -0.0412,\n         -0.0120, -0.0575, -0.0200,  0.0281, -0.0469, -0.0314,  0.0541,  0.0506,\n         -0.0354,  0.0469,  0.0143,  0.0307,  0.0057, -0.0451,  0.0481,  0.0024,\n          0.0016, -0.0290,  0.0383, -0.0233,  0.0508, -0.0583,  0.0491,  0.0003,\n         -0.0201,  0.0027,  0.0148,  0.0261,  0.0605, -0.0056, -0.0568,  0.0164,\n         -0.0050,  0.0300,  0.0188,  0.0621, -0.0562,  0.0610, -0.0177, -0.0330,\n         -0.0190, -0.0074, -0.0398, -0.0403,  0.0504,  0.0125, -0.0541, -0.0122,\n          0.0455, -0.0320,  0.0157, -0.0465, -0.0404,  0.0062, -0.0020,  0.0293,\n         -0.0267, -0.0165, -0.0503, -0.0426,  0.0614, -0.0255,  0.0235, -0.0134,\n          0.0321, -0.0472, -0.0308, -0.0068, -0.0063,  0.0502,  0.0250,  0.0050,\n         -0.0380,  0.0051,  0.0594,  0.0379,  0.0517, -0.0375, -0.0264,  0.0384,\n         -0.0542,  0.0061,  0.0045,  0.0391, -0.0342, -0.0079,  0.0194, -0.0194,\n         -0.0304, -0.0462, -0.0346,  0.0161, -0.0506,  0.0373,  0.0268,  0.0542,\n         -0.0479, -0.0053,  0.0563,  0.0106, -0.0336, -0.0488, -0.0020, -0.0561,\n          0.0411, -0.0041,  0.0298,  0.0276, -0.0282, -0.0281, -0.0373,  0.0340,\n         -0.0338, -0.0018,  0.0101, -0.0246,  0.0061,  0.0438, -0.0309,  0.0277,\n          0.0608,  0.0163, -0.0406, -0.0145,  0.0098,  0.0074, -0.0042, -0.0179,\n          0.0101, -0.0089,  0.0360, -0.0389, -0.0233,  0.0442, -0.0245,  0.0170,\n          0.0621, -0.0523,  0.0156,  0.0582, -0.0326, -0.0581, -0.0235,  0.0300,\n         -0.0128,  0.0383, -0.0121,  0.0557,  0.0164,  0.0016,  0.0596, -0.0170,\n          0.0577,  0.0107, -0.0008, -0.0031, -0.0507,  0.0421, -0.0029, -0.0432,\n         -0.0596, -0.0337, -0.0422, -0.0049,  0.0231, -0.0438,  0.0472,  0.0131]],\n       device='cuda:0', requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	256,
                                            "out_features":	3,
                                            "training":	true
                                        }
                                    },
                                    "net":	{
                                        "Sequential(\n  (0): Linear(in_features=11, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=11, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 2.3528e-01, -1.1756e-01, -2.1102e-01,  1.9181e-01, -4.6902e-02,\n         5.1993e-02,  2.9176e-02, -4.0808e-02,  1.9807e-01, -8.0414e-02,\n         1.5549e-01, -2.6027e-01,  1.1759e-01, -8.9729e-02,  3.1262e-02,\n        -3.5751e-02,  1.0693e-01,  1.4222e-01, -2.1302e-01, -9.1505e-02,\n         2.1113e-01, -1.5893e-01, -2.5049e-01,  2.6801e-01, -2.8664e-01,\n         2.5989e-01,  9.0804e-02, -1.3338e-01,  1.7688e-02, -1.4658e-02,\n         3.6991e-02, -1.1118e-01,  1.1465e-01, -8.5246e-02,  2.5624e-01,\n         2.4020e-02, -2.2129e-01,  2.8736e-01,  1.3636e-01,  1.2980e-01,\n         2.8984e-01,  2.8675e-01, -2.9858e-01, -2.9201e-01,  2.8634e-01,\n        -8.1378e-02, -1.6173e-01,  2.1146e-01, -5.8019e-02, -5.6801e-02,\n        -1.7768e-01, -8.0472e-03, -2.3783e-01,  2.6249e-01, -1.6454e-01,\n         1.3382e-01,  2.7190e-01, -2.0419e-01,  2.5857e-01,  1.8407e-01,\n         2.2776e-01,  5.1021e-02,  1.1875e-01, -2.8891e-01,  2.1369e-01,\n        -2.5593e-01, -3.7154e-02,  1.8676e-01, -2.2017e-01, -2.9591e-01,\n        -9.3203e-02, -1.2008e-01, -5.5501e-02,  2.0166e-01,  1.9397e-01,\n         2.6689e-01,  1.4112e-01, -7.3737e-02,  4.8376e-02,  1.4414e-01,\n         2.5733e-01, -9.3608e-02,  1.2342e-01, -2.4346e-02, -5.5531e-02,\n        -2.3966e-01, -6.1610e-02,  2.9740e-01,  2.0008e-01, -2.3372e-01,\n        -1.0931e-01,  4.5191e-02, -2.9062e-01, -8.4785e-03, -1.5176e-01,\n        -8.6061e-02,  2.8338e-01,  7.9164e-02,  2.5453e-01,  3.9063e-02,\n         1.9278e-01,  2.1812e-01, -2.1576e-01, -2.2757e-01,  8.2260e-02,\n         2.1218e-01, -2.1015e-02,  2.9678e-01,  7.3834e-02,  1.7103e-01,\n        -1.5547e-01, -1.2860e-01,  8.1478e-02,  1.1830e-01,  1.8509e-01,\n         9.6655e-02,  2.5262e-01,  4.0178e-03,  1.4149e-02,  2.1101e-01,\n        -2.2166e-02,  1.3612e-02, -1.3057e-01, -8.2893e-02,  2.9207e-01,\n         7.9276e-02, -9.9322e-02,  5.2722e-02, -1.4787e-01, -1.2038e-01,\n         9.3370e-02,  2.2819e-01, -7.8597e-02,  1.3932e-01,  2.8072e-02,\n         7.7293e-02, -2.7251e-01, -2.9239e-01, -8.0606e-02, -2.8401e-01,\n        -7.9695e-02, -2.0172e-01,  3.7758e-02,  2.3895e-01, -2.3319e-01,\n        -1.3098e-01,  1.3061e-01, -1.0944e-01, -4.1687e-02, -2.4275e-01,\n         1.3633e-01,  1.1173e-01, -1.3405e-01,  2.3542e-01,  5.1754e-02,\n        -2.3945e-01,  1.0521e-02,  1.9292e-01,  2.6847e-01, -2.8062e-01,\n         1.8994e-01,  6.6108e-02, -1.1905e-01, -3.1608e-02, -5.6367e-03,\n         1.8586e-01,  2.5025e-01,  1.0908e-01, -2.3524e-01,  1.3617e-01,\n         1.2392e-01, -1.6711e-01, -1.7319e-01, -2.2005e-01, -1.8671e-01,\n         2.5458e-01,  9.5314e-02, -2.7858e-01,  2.3945e-01, -2.2350e-01,\n        -1.4468e-01, -2.0225e-01,  1.2305e-01,  2.4167e-01, -2.7924e-01,\n        -2.6793e-01,  2.7063e-01,  3.7430e-02,  9.9614e-02, -1.1852e-01,\n        -2.4071e-01,  3.9331e-02,  2.7131e-02,  2.2383e-03,  7.0100e-02,\n         9.5716e-02,  1.0438e-01, -1.4502e-01, -1.1321e-01,  2.1810e-01,\n        -5.1150e-03,  2.1371e-01,  2.1812e-01,  2.4069e-01,  7.3489e-02,\n        -2.2153e-01,  1.3785e-01, -2.8645e-02, -2.2433e-01,  2.7354e-01,\n        -2.4482e-01, -1.6868e-01, -1.7754e-01, -1.8218e-02,  9.3894e-04,\n        -1.1549e-01, -1.4346e-01, -6.7244e-02,  1.7396e-01,  1.2952e-02,\n         6.4056e-02,  1.5566e-01, -2.6454e-01, -4.1963e-02, -1.2937e-01,\n        -2.4078e-01,  8.8560e-02, -2.4987e-01,  1.4266e-01, -1.6436e-01,\n        -3.8392e-02,  3.2850e-02, -8.0605e-02,  1.0449e-02, -2.6906e-02,\n        -2.5154e-02, -1.3813e-01, -1.8100e-01,  7.0266e-02,  2.0095e-01,\n        -5.2479e-02,  5.0345e-02,  8.9551e-02, -4.9288e-02,  9.3552e-02,\n        -2.6084e-01,  2.3340e-01,  2.4582e-01,  2.2462e-01,  1.3845e-01,\n        -2.9290e-04, -1.6319e-01,  1.9023e-01, -2.8132e-01,  2.1850e-02,\n         1.2003e-01], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1886,  0.2749,  0.1040,  ..., -0.2965, -0.2526,  0.2289],\n        [ 0.0466,  0.0334, -0.2213,  ...,  0.1429,  0.0910, -0.1780],\n        [ 0.2549,  0.2367, -0.1734,  ...,  0.1845,  0.1106,  0.2380],\n        ...,\n        [-0.2161,  0.1044,  0.2802,  ...,  0.1007,  0.0116,  0.2316],\n        [ 0.1474,  0.1873, -0.0499,  ..., -0.1511,  0.0026, -0.1289],\n        [-0.0322,  0.2597,  0.2477,  ..., -0.2148, -0.1052,  0.0456]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	11,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0540, -0.0608,  0.0283, -0.0066, -0.0555,  0.0547, -0.0424, -0.0292,\n        -0.0482,  0.0451, -0.0118, -0.0293,  0.0213, -0.0557,  0.0323, -0.0369,\n         0.0467,  0.0624,  0.0014,  0.0128,  0.0160, -0.0593,  0.0028, -0.0269,\n        -0.0246, -0.0494, -0.0536, -0.0201,  0.0080,  0.0257,  0.0474, -0.0017,\n         0.0027,  0.0582,  0.0404,  0.0051,  0.0242,  0.0185, -0.0295,  0.0361,\n         0.0343,  0.0230, -0.0425,  0.0315, -0.0370,  0.0009, -0.0331,  0.0195,\n        -0.0069, -0.0225,  0.0160,  0.0177, -0.0612,  0.0486, -0.0442, -0.0198,\n         0.0363,  0.0579,  0.0605, -0.0420, -0.0199,  0.0314, -0.0551,  0.0491,\n        -0.0602,  0.0447, -0.0181,  0.0546,  0.0187,  0.0257, -0.0440, -0.0478,\n         0.0216, -0.0394,  0.0236,  0.0251, -0.0476, -0.0296, -0.0051, -0.0385,\n         0.0192,  0.0305,  0.0594, -0.0178, -0.0169, -0.0443, -0.0547, -0.0233,\n         0.0072,  0.0264, -0.0175,  0.0054,  0.0169, -0.0615,  0.0072,  0.0104,\n         0.0520,  0.0040,  0.0409,  0.0084,  0.0359,  0.0533,  0.0499,  0.0009,\n        -0.0311, -0.0526, -0.0073,  0.0560, -0.0081,  0.0127, -0.0531, -0.0411,\n        -0.0314,  0.0462,  0.0283, -0.0451, -0.0444,  0.0155,  0.0429,  0.0197,\n         0.0052,  0.0147,  0.0511,  0.0349,  0.0183,  0.0450, -0.0369, -0.0477,\n         0.0310,  0.0010, -0.0229,  0.0601, -0.0158,  0.0379,  0.0085, -0.0456,\n         0.0519, -0.0593, -0.0586,  0.0521, -0.0007, -0.0137,  0.0447, -0.0128,\n        -0.0138, -0.0471, -0.0077,  0.0072,  0.0194,  0.0151,  0.0394,  0.0097,\n        -0.0478,  0.0559,  0.0321,  0.0272,  0.0016, -0.0530,  0.0063, -0.0081,\n        -0.0289,  0.0145, -0.0605, -0.0300,  0.0172, -0.0391, -0.0427, -0.0493,\n        -0.0260,  0.0306,  0.0582, -0.0334,  0.0503,  0.0264,  0.0241, -0.0157,\n        -0.0428,  0.0561,  0.0556, -0.0087,  0.0587, -0.0519, -0.0323,  0.0409,\n        -0.0318, -0.0155, -0.0599, -0.0064,  0.0517,  0.0381, -0.0139,  0.0405,\n         0.0276,  0.0186, -0.0540, -0.0621,  0.0530,  0.0253, -0.0566,  0.0263,\n         0.0417,  0.0602, -0.0529,  0.0270,  0.0056, -0.0485,  0.0035, -0.0033,\n         0.0298,  0.0531, -0.0580,  0.0599,  0.0304, -0.0553,  0.0543,  0.0043,\n        -0.0040, -0.0466,  0.0143,  0.0099, -0.0071,  0.0357,  0.0482, -0.0130,\n         0.0179,  0.0602, -0.0066, -0.0111, -0.0040,  0.0535, -0.0431, -0.0158,\n        -0.0593,  0.0302,  0.0187, -0.0547,  0.0486,  0.0497, -0.0237, -0.0434,\n         0.0212,  0.0063,  0.0055,  0.0588,  0.0331, -0.0285, -0.0544, -0.0258,\n        -0.0190,  0.0378, -0.0581, -0.0447, -0.0391,  0.0127,  0.0400,  0.0023],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0036, -0.0020,  0.0583,  ...,  0.0112, -0.0419, -0.0308],\n        [-0.0168, -0.0059,  0.0166,  ..., -0.0585,  0.0295, -0.0605],\n        [-0.0254,  0.0565,  0.0432,  ...,  0.0213, -0.0463, -0.0407],\n        ...,\n        [ 0.0492, -0.0475,  0.0324,  ..., -0.0347,  0.0382,  0.0276],\n        [-0.0357, -0.0522, -0.0239,  ..., -0.0195,  0.0468, -0.0235],\n        [-0.0612,  0.0447,  0.0446,  ..., -0.0427, -0.0603,  0.0252]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "act_limit":	"1.0",
                                "training":	true
                            }
                        },
                        "q1":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=14, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=14, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=1, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=14, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1187, -0.0145,  0.0472, -0.1500,  0.0601,  0.2632,  0.0794,  0.2635,\n         0.2590, -0.1685, -0.1216,  0.2111,  0.1390,  0.2431,  0.0578, -0.0703,\n        -0.2669,  0.2300,  0.1892, -0.0359,  0.1561,  0.1278,  0.0980,  0.0430,\n         0.0278,  0.2356,  0.1864,  0.0366, -0.0021,  0.2648,  0.0503, -0.1045,\n         0.2375,  0.1275, -0.2135, -0.2219,  0.0610,  0.1196, -0.1942,  0.1406,\n        -0.0023,  0.0892, -0.1256, -0.2571,  0.0010, -0.0347, -0.1354,  0.2448,\n         0.1359,  0.1352,  0.1868, -0.1998, -0.1041, -0.1653, -0.1015, -0.0908,\n         0.2137,  0.2440, -0.0337,  0.2118, -0.2102,  0.0444,  0.0698, -0.0797,\n        -0.2558,  0.1812, -0.2474,  0.1147, -0.0201,  0.1998, -0.0704,  0.1224,\n         0.0079,  0.0169, -0.0843,  0.1925,  0.1529,  0.1960, -0.2108,  0.2457,\n         0.1134,  0.2635,  0.1764,  0.1829,  0.2066, -0.1859, -0.0211, -0.1288,\n         0.1730,  0.0334, -0.1024, -0.2556, -0.0807,  0.1364,  0.0903,  0.0243,\n         0.0169, -0.0635,  0.2378,  0.1600, -0.0249, -0.1315,  0.2648,  0.1173,\n         0.0646,  0.1192, -0.1863,  0.2147, -0.1889, -0.0822,  0.1517, -0.0861,\n        -0.2594, -0.1170, -0.1198,  0.1011,  0.0909, -0.1318, -0.0579,  0.2178,\n         0.0536,  0.1578,  0.1079,  0.2422, -0.1871, -0.1156, -0.0560, -0.0194,\n        -0.1179, -0.1240,  0.0265,  0.2196, -0.2269,  0.1812, -0.2381, -0.1853,\n         0.1541,  0.0747,  0.0456,  0.0907, -0.0716,  0.2380,  0.1666,  0.0769,\n        -0.2177,  0.0687, -0.0033,  0.2397,  0.0850, -0.1259, -0.2130, -0.1403,\n        -0.0627, -0.0112,  0.0158,  0.0590,  0.2606,  0.1373, -0.1481, -0.0768,\n        -0.1176, -0.2616, -0.1427,  0.0392, -0.0765, -0.2561, -0.1658, -0.0670,\n        -0.0896,  0.1721, -0.0049,  0.1459, -0.2168,  0.2293,  0.1679,  0.2153,\n        -0.0464, -0.0898,  0.0510, -0.1421, -0.1843, -0.2579,  0.0663,  0.2005,\n         0.0410,  0.0805,  0.2412,  0.1143,  0.1473,  0.0856,  0.2177, -0.2107,\n         0.1164, -0.1962, -0.1871,  0.2315, -0.2654,  0.1796,  0.1334, -0.1346,\n        -0.0602, -0.2296, -0.2404,  0.0463, -0.2165, -0.2610,  0.0967, -0.0258,\n         0.2468,  0.0411, -0.2633,  0.2437, -0.0163, -0.1576,  0.2194, -0.1359,\n        -0.0019, -0.0553, -0.1896,  0.2638, -0.0884, -0.1851,  0.1906,  0.1083,\n        -0.0356, -0.0145,  0.0043,  0.2652,  0.1696,  0.1438,  0.0136, -0.1383,\n        -0.1451, -0.1022,  0.0974,  0.0780,  0.0478,  0.0823,  0.1098, -0.1671,\n        -0.1036, -0.2430, -0.2483, -0.1689, -0.0668,  0.2102,  0.1385,  0.0409,\n         0.2138, -0.0240, -0.0433,  0.1185,  0.2244, -0.2578, -0.1149, -0.1302],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1768,  0.0056, -0.1600,  ..., -0.2328, -0.0894, -0.0372],\n        [ 0.1734, -0.2291, -0.1992,  ..., -0.0255, -0.1920, -0.0404],\n        [ 0.2403, -0.0665, -0.1089,  ...,  0.0583,  0.1886,  0.0925],\n        ...,\n        [ 0.0321,  0.0782, -0.2351,  ..., -0.0112,  0.0600, -0.2255],\n        [-0.2544, -0.0527,  0.0382,  ..., -0.0369,  0.0429, -0.0143],\n        [ 0.1640,  0.0818,  0.1031,  ...,  0.2423,  0.0885, -0.2002]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	14,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0500,  0.0459,  0.0394,  0.0578, -0.0265, -0.0122, -0.0218, -0.0005,\n        -0.0517,  0.0352, -0.0560,  0.0334,  0.0548,  0.0417, -0.0503,  0.0620,\n        -0.0428, -0.0035,  0.0239, -0.0527, -0.0226,  0.0373,  0.0440,  0.0146,\n         0.0297, -0.0137,  0.0594,  0.0066, -0.0563,  0.0070, -0.0001, -0.0559,\n        -0.0431, -0.0406, -0.0332,  0.0485,  0.0544, -0.0261,  0.0282,  0.0217,\n         0.0387, -0.0035, -0.0168, -0.0237,  0.0240, -0.0403,  0.0483,  0.0196,\n         0.0069, -0.0136, -0.0023, -0.0249, -0.0180,  0.0107,  0.0129,  0.0031,\n         0.0403, -0.0128, -0.0360,  0.0430,  0.0430,  0.0427, -0.0214,  0.0344,\n        -0.0153,  0.0153,  0.0452, -0.0384, -0.0159, -0.0600,  0.0064, -0.0154,\n        -0.0030,  0.0048,  0.0318,  0.0429,  0.0157,  0.0108,  0.0228, -0.0100,\n         0.0064,  0.0049,  0.0025, -0.0161, -0.0195,  0.0397,  0.0272, -0.0411,\n        -0.0042,  0.0384,  0.0482, -0.0279, -0.0418, -0.0138, -0.0404,  0.0168,\n        -0.0500, -0.0219, -0.0539,  0.0256,  0.0302, -0.0083,  0.0118,  0.0592,\n        -0.0616,  0.0266,  0.0330,  0.0176,  0.0565, -0.0589,  0.0465,  0.0207,\n        -0.0097,  0.0325, -0.0359, -0.0500,  0.0425, -0.0356, -0.0150,  0.0312,\n         0.0577,  0.0221, -0.0239, -0.0446, -0.0023, -0.0416, -0.0618,  0.0035,\n         0.0003,  0.0476, -0.0571, -0.0504, -0.0435,  0.0002,  0.0536, -0.0527,\n        -0.0056, -0.0575, -0.0515, -0.0299,  0.0558, -0.0297,  0.0078, -0.0420,\n         0.0056,  0.0092,  0.0451,  0.0258,  0.0125, -0.0574, -0.0269,  0.0209,\n         0.0318, -0.0355, -0.0362,  0.0565, -0.0347, -0.0531, -0.0074, -0.0234,\n        -0.0465, -0.0398, -0.0340,  0.0320,  0.0130, -0.0256,  0.0451,  0.0120,\n         0.0301,  0.0466,  0.0441, -0.0458, -0.0559, -0.0491, -0.0607,  0.0601,\n         0.0574, -0.0135,  0.0583, -0.0002, -0.0585,  0.0623,  0.0417,  0.0281,\n        -0.0450,  0.0511, -0.0393,  0.0040, -0.0574,  0.0532,  0.0153,  0.0289,\n        -0.0074, -0.0599,  0.0037,  0.0261,  0.0175, -0.0142,  0.0197,  0.0453,\n         0.0018,  0.0448,  0.0323,  0.0123, -0.0071,  0.0442, -0.0497,  0.0535,\n        -0.0507,  0.0394,  0.0407,  0.0343, -0.0405,  0.0355,  0.0199, -0.0350,\n        -0.0621,  0.0426,  0.0050, -0.0213,  0.0470, -0.0118, -0.0508,  0.0221,\n         0.0330, -0.0226,  0.0006, -0.0381,  0.0522, -0.0392, -0.0008, -0.0302,\n        -0.0235,  0.0384,  0.0193,  0.0349, -0.0558,  0.0353,  0.0014,  0.0331,\n         0.0465,  0.0482,  0.0071, -0.0235,  0.0420, -0.0139, -0.0378, -0.0112,\n        -0.0110,  0.0388,  0.0064, -0.0414, -0.0127,  0.0277, -0.0226, -0.0171],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0504, -0.0328, -0.0041,  ..., -0.0570,  0.0604,  0.0232],\n        [-0.0472,  0.0321,  0.0306,  ..., -0.0569, -0.0160,  0.0162],\n        [-0.0048,  0.0235, -0.0493,  ..., -0.0485,  0.0614,  0.0435],\n        ...,\n        [ 0.0381,  0.0577,  0.0287,  ...,  0.0430, -0.0070, -0.0096],\n        [-0.0040, -0.0513,  0.0272,  ...,  0.0581,  0.0084, -0.0518],\n        [ 0.0022,  0.0086, -0.0461,  ..., -0.0057, -0.0220, -0.0236]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0057], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0590,  0.0474, -0.0397, -0.0094,  0.0033, -0.0367,  0.0077,  0.0620,\n         -0.0234,  0.0170, -0.0078, -0.0070,  0.0120,  0.0037, -0.0300, -0.0341,\n          0.0440,  0.0029, -0.0441, -0.0583, -0.0546, -0.0554, -0.0112, -0.0069,\n          0.0267,  0.0480, -0.0412,  0.0240,  0.0439,  0.0094,  0.0294, -0.0299,\n          0.0287, -0.0174, -0.0125, -0.0232, -0.0447, -0.0554,  0.0590,  0.0459,\n         -0.0297,  0.0553,  0.0339,  0.0327, -0.0155,  0.0190, -0.0247, -0.0327,\n          0.0004,  0.0605, -0.0142, -0.0173, -0.0006,  0.0592,  0.0199, -0.0062,\n         -0.0006,  0.0295, -0.0373,  0.0223, -0.0474, -0.0215, -0.0203, -0.0322,\n         -0.0465,  0.0047, -0.0156, -0.0463,  0.0453, -0.0402,  0.0148,  0.0334,\n          0.0130, -0.0394,  0.0608,  0.0504,  0.0449,  0.0420, -0.0318, -0.0153,\n         -0.0007, -0.0414, -0.0307,  0.0565,  0.0363, -0.0365, -0.0505,  0.0606,\n         -0.0203, -0.0422,  0.0476, -0.0345,  0.0323,  0.0233,  0.0516,  0.0500,\n          0.0380, -0.0230,  0.0490,  0.0142,  0.0423, -0.0533, -0.0300,  0.0066,\n          0.0095, -0.0199,  0.0378,  0.0608,  0.0620,  0.0455, -0.0338,  0.0063,\n         -0.0035, -0.0034,  0.0559, -0.0384,  0.0352, -0.0284,  0.0417, -0.0142,\n         -0.0371,  0.0590, -0.0278,  0.0096,  0.0021, -0.0271, -0.0083,  0.0381,\n          0.0023, -0.0417,  0.0544,  0.0463, -0.0326,  0.0223,  0.0345,  0.0467,\n         -0.0234,  0.0378, -0.0242,  0.0242,  0.0213, -0.0207, -0.0074, -0.0623,\n          0.0206, -0.0096, -0.0481,  0.0340,  0.0105, -0.0576,  0.0033,  0.0117,\n          0.0262, -0.0012,  0.0591, -0.0281,  0.0064, -0.0399,  0.0428, -0.0173,\n         -0.0014,  0.0019,  0.0621, -0.0086,  0.0179,  0.0362, -0.0336,  0.0386,\n          0.0483,  0.0161, -0.0204, -0.0563,  0.0005, -0.0170,  0.0009,  0.0145,\n         -0.0104,  0.0409, -0.0198,  0.0515,  0.0400, -0.0459, -0.0010,  0.0008,\n          0.0251, -0.0112, -0.0334,  0.0048, -0.0501,  0.0029,  0.0599, -0.0586,\n         -0.0250, -0.0086, -0.0449,  0.0057,  0.0145,  0.0042,  0.0556, -0.0450,\n         -0.0537, -0.0322,  0.0193, -0.0527,  0.0006, -0.0407,  0.0147,  0.0104,\n         -0.0174,  0.0040,  0.0182,  0.0071, -0.0188,  0.0521, -0.0123,  0.0387,\n          0.0615, -0.0316, -0.0281, -0.0448, -0.0414, -0.0623,  0.0384,  0.0581,\n         -0.0162, -0.0191,  0.0460, -0.0279,  0.0456,  0.0114,  0.0234,  0.0211,\n         -0.0593, -0.0341, -0.0460,  0.0392,  0.0512,  0.0163,  0.0096,  0.0156,\n          0.0454,  0.0384, -0.0256, -0.0561,  0.0305, -0.0312, -0.0479, -0.0448,\n          0.0271,  0.0314,  0.0285,  0.0397, -0.0062,  0.0141, -0.0335, -0.0462]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "q2":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=14, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=14, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=1, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=14, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.2032,  0.1033,  0.0146,  0.1174,  0.2221, -0.0170, -0.2266,  0.0460,\n         0.1687, -0.2493, -0.1780,  0.0422,  0.0139,  0.1795, -0.0274,  0.1105,\n         0.2447, -0.2287, -0.0254, -0.1112,  0.0935, -0.0604, -0.2165, -0.2348,\n        -0.0739,  0.1766, -0.2289, -0.1103, -0.2085,  0.2507,  0.0773, -0.0032,\n        -0.2415,  0.1284, -0.0926, -0.2465,  0.0949, -0.0274, -0.2665, -0.2268,\n         0.1219,  0.0713, -0.0425,  0.1274, -0.1318,  0.0403, -0.0677, -0.1599,\n        -0.0442, -0.1798, -0.1062, -0.0513,  0.0827,  0.2231, -0.0754,  0.1773,\n         0.1280,  0.1007,  0.1004,  0.1427, -0.0326,  0.1999, -0.1815, -0.1373,\n        -0.0983, -0.1201,  0.2469,  0.1166, -0.1803,  0.2008, -0.2350,  0.1539,\n        -0.0096, -0.1768,  0.0046,  0.0657,  0.0348, -0.1833, -0.1977, -0.1395,\n        -0.0021,  0.0656,  0.2488, -0.0722, -0.1850,  0.1612,  0.1828,  0.0423,\n        -0.1406, -0.1220,  0.1332,  0.1295, -0.0005,  0.0364,  0.1262, -0.0765,\n        -0.0469, -0.2306, -0.2509, -0.1462,  0.0808, -0.0757,  0.1172,  0.1691,\n         0.2123,  0.0919, -0.1003,  0.2207, -0.1481,  0.2560, -0.1489,  0.1745,\n        -0.0043,  0.1214, -0.2078, -0.2349, -0.0078, -0.2502,  0.1371,  0.1664,\n        -0.2535,  0.2278,  0.0473,  0.1590,  0.1921, -0.2473, -0.1460, -0.0328,\n         0.0023,  0.2395,  0.1857, -0.1186, -0.0286, -0.2376,  0.1053, -0.2543,\n        -0.0946, -0.2631, -0.1980, -0.0935,  0.2508, -0.0004, -0.1723, -0.1293,\n         0.1148, -0.0571,  0.2159, -0.0394, -0.1759,  0.1327, -0.0061, -0.1728,\n        -0.0070,  0.0265, -0.2391,  0.0311, -0.1826, -0.1239, -0.1390, -0.1259,\n         0.1512, -0.2465, -0.2576,  0.0004,  0.1257, -0.0679, -0.1699,  0.2622,\n        -0.2229,  0.2190, -0.0431,  0.1943, -0.1537, -0.2355, -0.2116,  0.0416,\n        -0.2431, -0.1208, -0.1634,  0.2389,  0.2564, -0.2199, -0.0410,  0.1425,\n        -0.0596, -0.1789, -0.2402, -0.0679, -0.1505,  0.1571,  0.1226,  0.1883,\n         0.2012,  0.0607,  0.0843, -0.1298,  0.0106,  0.1701,  0.0492,  0.2527,\n         0.2212,  0.1765, -0.1075,  0.0468,  0.0386,  0.2602, -0.0949,  0.0126,\n         0.0044, -0.1364,  0.1590, -0.2197,  0.0184, -0.0685,  0.0977, -0.1258,\n         0.0233, -0.1609,  0.2367, -0.0860,  0.0185, -0.1846, -0.2642, -0.1020,\n        -0.1930, -0.1098,  0.1648, -0.1336, -0.0261,  0.2115,  0.0964,  0.1986,\n        -0.0089, -0.2480,  0.1327, -0.1179, -0.2090,  0.1410,  0.0165,  0.2406,\n        -0.0479, -0.1536,  0.2495,  0.0790, -0.2205, -0.1235,  0.0635,  0.2191,\n         0.1709, -0.1656, -0.1424, -0.0169, -0.2439,  0.0067,  0.2386, -0.2451],\n       device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0198,  0.0509,  0.1029,  ..., -0.0809,  0.0448, -0.0199],\n        [ 0.0793, -0.2493, -0.0495,  ...,  0.0817,  0.2073, -0.2551],\n        [-0.2489, -0.2074,  0.2519,  ...,  0.1753,  0.0644,  0.0788],\n        ...,\n        [ 0.0461,  0.0036,  0.0340,  ..., -0.1588, -0.0558,  0.0228],\n        [ 0.2110, -0.1540,  0.0049,  ...,  0.0580,  0.1851, -0.2029],\n        [ 0.0175, -0.1501,  0.1571,  ...,  0.1391, -0.1945, -0.0671]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	14,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 3.9048e-03,  2.1574e-02, -1.1005e-02,  2.4183e-02,  3.2534e-02,\n        -3.3743e-02, -4.0422e-03, -5.3024e-02, -1.4131e-02, -4.9334e-02,\n        -2.3312e-02,  5.4515e-02, -4.7153e-02,  4.5458e-02, -3.9268e-02,\n         8.3877e-03, -7.3382e-03,  1.6383e-02, -2.8477e-02,  2.2241e-02,\n        -3.8105e-02, -4.7430e-02, -2.3048e-02,  1.8019e-02, -3.3381e-02,\n        -3.1290e-02,  5.8679e-02, -1.2932e-02,  1.3860e-02, -5.5323e-03,\n        -1.6675e-02,  3.0720e-02, -9.0352e-03, -2.6343e-02,  5.2876e-02,\n        -3.0360e-02, -4.4997e-02, -1.3136e-02, -7.3841e-04, -3.0139e-02,\n         2.7645e-03, -7.5837e-03,  3.5965e-02,  1.8923e-02, -5.5858e-02,\n        -3.1186e-02, -2.9359e-02,  6.1492e-02,  3.2940e-03, -3.4747e-02,\n        -3.5472e-02, -1.3977e-02,  3.7621e-02,  6.2461e-02, -2.9364e-02,\n        -3.2132e-02,  1.1491e-02,  7.9730e-03, -4.6148e-02,  3.8341e-02,\n         2.0482e-02,  1.7033e-02,  5.3329e-02, -2.7434e-02,  7.4931e-03,\n        -5.5484e-02,  5.4683e-02, -3.6156e-02,  2.0895e-02,  5.8426e-02,\n        -5.8538e-02, -2.3072e-02, -5.1497e-02, -5.1776e-02, -2.9869e-02,\n        -4.8895e-02,  2.4200e-02, -5.0240e-02, -1.9605e-02, -2.9475e-02,\n         3.9443e-05, -1.3211e-02,  5.7421e-02, -1.9668e-02, -7.8719e-03,\n        -5.5853e-03,  6.7320e-04, -2.2309e-02, -3.6204e-02, -1.0454e-02,\n        -3.7717e-02,  1.4182e-02, -1.8460e-03, -3.2889e-02,  4.8449e-02,\n         2.6050e-02, -6.2479e-02,  3.8324e-03, -2.7123e-02, -1.1528e-02,\n         1.0323e-03,  3.5475e-02,  2.6622e-02,  3.8778e-02, -3.4551e-02,\n         3.3271e-02,  1.6628e-02, -5.6607e-02, -1.7540e-02,  5.3056e-02,\n         2.3654e-02,  2.0510e-02, -1.4940e-02,  3.5134e-02, -6.0713e-02,\n        -5.3427e-02, -5.7889e-03, -4.0597e-02, -1.4364e-02, -6.1374e-02,\n         5.7555e-03,  4.8226e-02,  1.8347e-03, -6.2276e-02,  1.6883e-02,\n        -1.3041e-02,  5.4609e-02, -5.1981e-02, -5.7395e-02, -6.2205e-02,\n         5.0269e-02, -5.5210e-02, -6.0732e-02,  5.9687e-02,  3.0275e-02,\n        -5.6525e-02, -2.1263e-02, -2.3915e-02, -2.9648e-02, -3.8705e-02,\n         2.7335e-03,  3.9414e-02, -1.4854e-02,  9.3599e-03, -9.0421e-03,\n         1.9945e-02, -1.4221e-02,  4.7112e-02, -1.9347e-02,  3.6835e-02,\n        -2.1495e-02,  6.1693e-02, -3.3383e-03, -5.7891e-02, -5.3921e-02,\n         5.8997e-02,  8.8001e-03, -1.6484e-02, -4.7432e-02, -2.5082e-02,\n         4.6924e-03,  1.5771e-02,  3.5383e-03,  4.9198e-02, -2.1220e-02,\n        -4.8849e-02,  4.1869e-04,  9.6992e-03, -3.6853e-02,  3.8505e-03,\n        -2.4716e-02,  3.5932e-02,  9.0228e-03,  2.9376e-02, -3.5010e-02,\n         4.5773e-03, -3.8382e-02,  1.4425e-02, -4.2902e-02, -1.0590e-03,\n        -1.2679e-02,  3.4802e-03, -5.6717e-02,  1.2632e-02, -2.6073e-02,\n        -4.7833e-02, -3.9666e-02,  4.1066e-02,  5.3430e-02, -4.6832e-02,\n        -5.7929e-02, -5.8264e-04, -1.4093e-02,  2.1208e-02,  3.8703e-02,\n         2.9370e-03,  9.1674e-03,  3.0681e-04, -1.0884e-02,  1.2379e-02,\n         3.6347e-03, -1.1364e-03,  4.8373e-02,  2.9317e-02,  5.1176e-02,\n        -3.0153e-02, -2.8935e-03,  1.1227e-02, -5.8618e-02,  1.1969e-02,\n         7.7420e-03,  2.9972e-02,  2.4609e-04,  4.4606e-02, -2.5356e-02,\n         5.6037e-02,  6.3339e-03,  3.4087e-03,  5.6976e-02, -4.1888e-02,\n        -5.7119e-03, -7.6832e-03, -5.3568e-02, -5.4952e-02,  3.9376e-03,\n        -5.8436e-02,  5.6198e-02,  3.4100e-02,  1.7658e-02, -3.2102e-02,\n        -2.1439e-02, -5.5724e-02,  2.1767e-02, -1.8205e-02,  4.8394e-02,\n         1.6337e-02,  7.5377e-03,  1.6566e-02, -2.7799e-02, -5.6529e-02,\n         8.2166e-03, -3.8752e-03, -1.8406e-02, -5.3407e-02, -1.8497e-02,\n         4.3667e-02, -2.1424e-02,  3.4502e-02,  2.0564e-02, -3.2415e-02,\n         3.1211e-02,  3.7426e-02, -4.5413e-02, -8.6662e-03,  4.3584e-02,\n         3.1396e-02], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0398,  0.0204, -0.0081,  ...,  0.0245,  0.0541,  0.0451],\n        [ 0.0604,  0.0507, -0.0585,  ...,  0.0513,  0.0532,  0.0288],\n        [-0.0058, -0.0493,  0.0111,  ...,  0.0608,  0.0396,  0.0344],\n        ...,\n        [-0.0241, -0.0415,  0.0262,  ...,  0.0446, -0.0456, -0.0063],\n        [-0.0394,  0.0555,  0.0034,  ..., -0.0139,  0.0185,  0.0283],\n        [-0.0092, -0.0573, -0.0263,  ...,  0.0222,  0.0431, -0.0440]],\n       device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0242], device='cuda:0', requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.1850e-02,  9.6254e-05,  5.2145e-02, -2.0427e-02, -7.3187e-03,\n          6.2246e-02,  1.9453e-02, -4.9074e-02, -4.8667e-03,  1.6419e-02,\n          4.7418e-03,  4.9396e-02,  1.3771e-03, -4.6917e-02, -5.0577e-02,\n          2.4406e-02,  2.1224e-02,  3.6825e-02, -1.2623e-02, -5.2208e-02,\n          2.2402e-02,  6.3886e-04,  5.1799e-02, -1.6023e-02, -2.6141e-02,\n          9.1676e-03,  1.6891e-02,  6.1733e-02,  5.2159e-02,  4.5710e-02,\n          5.9459e-02, -3.8299e-02,  5.8606e-03,  5.9016e-02,  6.5828e-03,\n          4.1698e-02,  2.9845e-02,  6.1671e-02, -1.5038e-02,  9.8490e-04,\n          2.6191e-02, -2.5480e-03,  1.5057e-02, -4.6581e-02, -1.0476e-02,\n         -2.6142e-02, -4.8111e-02,  1.6993e-02, -4.7490e-02, -3.2123e-02,\n         -2.4901e-02,  3.7425e-02,  4.1948e-03,  4.6523e-02,  1.4070e-02,\n          2.0280e-02, -4.5477e-02,  7.7266e-03,  5.4545e-02, -3.3317e-02,\n          5.9411e-02,  1.7974e-02, -4.8488e-02, -7.4885e-03,  2.8144e-02,\n         -2.3596e-02,  1.2804e-02,  5.0216e-02,  3.6245e-02, -1.1508e-02,\n         -4.8281e-02, -5.2793e-02, -5.0429e-02,  8.5230e-03,  1.7088e-02,\n         -2.8461e-02,  2.5148e-02, -3.0721e-02,  4.9128e-03,  3.7309e-02,\n         -3.1526e-02,  4.2944e-02,  7.6105e-03, -1.2763e-02,  2.2289e-02,\n         -5.6153e-02,  2.7076e-02, -1.0474e-02,  4.4770e-02,  1.3008e-02,\n          1.6522e-02,  3.3067e-02,  1.0152e-02,  3.0906e-02, -5.8517e-03,\n         -3.7948e-03, -3.2381e-02,  3.2961e-02, -2.2705e-02,  5.7281e-02,\n         -3.3357e-02,  1.0795e-02, -2.6509e-02,  3.4499e-02,  5.9936e-03,\n          4.2765e-02, -2.7076e-02,  2.6296e-02,  2.7945e-02,  4.3302e-03,\n          5.7212e-02,  4.7805e-02,  5.9481e-02, -6.2351e-02, -3.6697e-02,\n          3.5847e-02, -5.7014e-02,  4.5530e-02,  3.2032e-02,  4.6794e-02,\n         -4.4197e-02, -2.9945e-03, -5.2221e-02,  5.0929e-02,  7.6213e-04,\n          4.5927e-02,  6.1937e-02,  3.6511e-02, -6.1067e-02,  4.8873e-02,\n          4.6556e-02, -5.2908e-02,  4.9261e-02,  3.2546e-03, -4.0115e-02,\n         -8.2285e-03, -1.6088e-02,  5.1301e-03,  4.5164e-02,  5.0844e-03,\n         -1.5887e-02,  4.2302e-02,  5.1438e-02,  1.4307e-02,  5.4801e-02,\n         -3.0784e-02, -3.4805e-03,  1.9430e-02,  5.0566e-03, -7.9205e-03,\n          5.4113e-02,  2.6284e-02, -9.4083e-03,  1.9397e-02, -5.4864e-02,\n          3.8903e-02, -5.5359e-02,  6.1466e-03, -7.9018e-03, -3.2284e-02,\n          4.1622e-02,  2.5171e-02,  5.8127e-02,  3.0189e-02, -4.8237e-02,\n         -2.3084e-02, -2.6494e-02, -4.4275e-02,  1.0787e-02,  5.3675e-02,\n         -5.1051e-02,  3.7893e-02, -4.4314e-02,  2.3909e-02,  5.3116e-02,\n         -3.1521e-02, -4.1152e-02,  7.2898e-03, -3.6532e-02,  3.1747e-02,\n          4.1091e-02,  5.8488e-02, -3.4523e-02, -3.0744e-02, -5.7184e-02,\n          6.0100e-02,  3.1318e-02,  6.4005e-03, -3.8256e-02, -6.2171e-02,\n         -4.7432e-03, -2.2598e-02, -6.0701e-02, -8.8612e-03, -9.8999e-03,\n          3.4124e-02,  4.4937e-02,  2.7819e-02,  1.1292e-02, -4.1241e-02,\n          3.2599e-02,  1.4296e-02, -5.4993e-02, -4.7226e-03,  5.6266e-03,\n         -5.7269e-02,  6.0903e-02, -5.8601e-02,  9.1637e-03, -5.7374e-03,\n          4.2750e-02, -3.1434e-02,  3.1183e-02, -2.1519e-02, -5.1015e-02,\n          5.2059e-02,  1.5361e-04,  2.9651e-02,  6.2371e-02,  3.0871e-02,\n         -7.5478e-03, -2.6959e-02,  1.6449e-02,  5.8957e-02, -2.7672e-02,\n          3.5424e-02, -6.2203e-02, -3.9646e-02, -3.3094e-02,  5.6046e-02,\n          3.2608e-02, -3.1356e-02, -4.0486e-02, -2.5819e-02,  1.1862e-02,\n          1.1511e-02, -1.3739e-02,  4.3089e-02,  3.9914e-02,  5.8645e-02,\n         -2.9536e-02,  6.1192e-02,  4.9375e-03, -4.0944e-02, -2.2565e-02,\n         -2.2539e-02,  8.8568e-03, -3.8093e-02,  3.8967e-02, -3.8513e-03,\n          2.8764e-02,  6.5629e-03, -4.6070e-02,  3.3465e-02,  4.8165e-02,\n         -1.7196e-02]], device='cuda:0', requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "ac_targ":	{
                "MLPActorCritic(\n  (pi): SquashedGaussianMLPActor(\n    (net): Sequential(\n      (0): Linear(in_features=11, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu_layer): Linear(in_features=256, out_features=3, bias=True)\n    (log_std_layer): Linear(in_features=256, out_features=3, bias=True)\n  )\n  (q1): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=14, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n      (5): Identity()\n    )\n  )\n  (q2): MLPQFunction(\n    (q): Sequential(\n      (0): Linear(in_features=14, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n      (5): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "SquashedGaussianMLPActor(\n  (net): Sequential(\n    (0): Linear(in_features=11, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu_layer): Linear(in_features=256, out_features=3, bias=True)\n  (log_std_layer): Linear(in_features=256, out_features=3, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "log_std_layer":	{
                                        "Linear(in_features=256, out_features=3, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0445, -0.0330, -0.0369], device='cuda:0')",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0563,  0.0496,  0.0195,  0.0203, -0.0011,  0.0380, -0.0097,  0.0317,\n         -0.0462, -0.0538, -0.0289,  0.0383, -0.0025, -0.0546,  0.0145, -0.0118,\n          0.0444,  0.0108,  0.0052, -0.0580,  0.0158, -0.0621, -0.0299,  0.0412,\n         -0.0406,  0.0239,  0.0578,  0.0084,  0.0291, -0.0384,  0.0056, -0.0492,\n          0.0560, -0.0148,  0.0322, -0.0418, -0.0121, -0.0526,  0.0309,  0.0024,\n         -0.0211, -0.0452,  0.0610, -0.0270,  0.0519, -0.0538, -0.0339,  0.0341,\n         -0.0218,  0.0385, -0.0374,  0.0202, -0.0085,  0.0566, -0.0339, -0.0025,\n          0.0184, -0.0416, -0.0270,  0.0282, -0.0111, -0.0437, -0.0022, -0.0563,\n          0.0276,  0.0355, -0.0483,  0.0610,  0.0231,  0.0229,  0.0312,  0.0506,\n         -0.0619,  0.0551, -0.0439, -0.0312, -0.0496, -0.0030, -0.0261,  0.0610,\n         -0.0279, -0.0556, -0.0514, -0.0016, -0.0476,  0.0093, -0.0451,  0.0348,\n          0.0427,  0.0543, -0.0537, -0.0232,  0.0508,  0.0276, -0.0039, -0.0018,\n         -0.0332, -0.0366,  0.0225, -0.0516, -0.0252, -0.0044,  0.0476, -0.0199,\n          0.0061, -0.0324, -0.0513, -0.0417, -0.0270,  0.0142,  0.0150, -0.0613,\n         -0.0489,  0.0117,  0.0611, -0.0405, -0.0564, -0.0496,  0.0551,  0.0115,\n         -0.0464,  0.0308,  0.0567,  0.0538,  0.0096, -0.0452, -0.0252, -0.0354,\n          0.0040,  0.0004,  0.0478, -0.0591,  0.0351,  0.0389,  0.0075, -0.0101,\n          0.0136, -0.0458, -0.0513, -0.0231,  0.0089, -0.0234,  0.0198,  0.0563,\n         -0.0440, -0.0316, -0.0258,  0.0469,  0.0027, -0.0213, -0.0003, -0.0478,\n         -0.0416,  0.0557,  0.0605, -0.0152,  0.0190, -0.0189,  0.0356,  0.0508,\n         -0.0397,  0.0406, -0.0338,  0.0045,  0.0404,  0.0270,  0.0572, -0.0104,\n          0.0247, -0.0057,  0.0573, -0.0290,  0.0363, -0.0362,  0.0226,  0.0259,\n         -0.0192,  0.0250, -0.0438, -0.0314, -0.0422, -0.0435, -0.0304, -0.0190,\n         -0.0297, -0.0043, -0.0433,  0.0488, -0.0113,  0.0202,  0.0027, -0.0569,\n         -0.0477, -0.0609,  0.0051,  0.0330, -0.0090, -0.0351, -0.0527,  0.0325,\n         -0.0445, -0.0507, -0.0264, -0.0164,  0.0083,  0.0102,  0.0166,  0.0124,\n         -0.0096,  0.0385,  0.0083,  0.0572, -0.0518,  0.0263,  0.0455,  0.0407,\n          0.0470,  0.0355,  0.0343,  0.0080, -0.0547,  0.0140, -0.0423,  0.0342,\n         -0.0463,  0.0274, -0.0518, -0.0556, -0.0475, -0.0530, -0.0505,  0.0278,\n          0.0472, -0.0207,  0.0307, -0.0621, -0.0110,  0.0051,  0.0006, -0.0423,\n         -0.0145,  0.0329, -0.0028, -0.0579, -0.0142, -0.0473, -0.0236, -0.0501,\n          0.0620,  0.0026, -0.0306, -0.0076, -0.0174,  0.0455, -0.0010,  0.0287],\n        [-0.0385,  0.0224, -0.0323, -0.0375, -0.0288, -0.0282,  0.0267,  0.0350,\n          0.0332, -0.0031,  0.0397,  0.0275, -0.0242,  0.0253,  0.0399, -0.0095,\n          0.0179, -0.0161, -0.0143, -0.0490, -0.0139, -0.0314, -0.0457, -0.0007,\n         -0.0516,  0.0624, -0.0227,  0.0563,  0.0078, -0.0552, -0.0431,  0.0587,\n         -0.0119,  0.0558,  0.0392, -0.0224,  0.0214,  0.0484,  0.0332,  0.0007,\n         -0.0561,  0.0152,  0.0497,  0.0006, -0.0517,  0.0217, -0.0563,  0.0618,\n         -0.0609, -0.0559,  0.0621,  0.0335, -0.0569, -0.0186,  0.0072, -0.0514,\n          0.0346, -0.0022,  0.0020,  0.0554,  0.0511,  0.0326, -0.0612,  0.0510,\n         -0.0325,  0.0051,  0.0247,  0.0588,  0.0603, -0.0138, -0.0188, -0.0537,\n         -0.0311,  0.0167, -0.0334, -0.0358,  0.0097,  0.0337,  0.0257, -0.0562,\n          0.0076,  0.0313, -0.0260, -0.0358,  0.0136,  0.0062, -0.0326,  0.0548,\n          0.0457,  0.0155, -0.0201,  0.0313, -0.0453, -0.0088,  0.0569, -0.0353,\n          0.0127,  0.0163,  0.0016,  0.0048,  0.0557, -0.0361,  0.0481,  0.0073,\n         -0.0311,  0.0106,  0.0288,  0.0491, -0.0099,  0.0134, -0.0393,  0.0256,\n          0.0173, -0.0412,  0.0338,  0.0228, -0.0469, -0.0181, -0.0261, -0.0473,\n         -0.0536, -0.0161,  0.0094, -0.0335, -0.0384,  0.0439,  0.0029, -0.0172,\n         -0.0585, -0.0587, -0.0567,  0.0442,  0.0225, -0.0005, -0.0415, -0.0180,\n         -0.0017,  0.0560, -0.0178, -0.0431,  0.0551, -0.0226, -0.0146,  0.0389,\n          0.0223, -0.0498, -0.0480,  0.0450,  0.0472, -0.0610,  0.0602, -0.0328,\n         -0.0435, -0.0599,  0.0250,  0.0110, -0.0447,  0.0158, -0.0331,  0.0511,\n          0.0429, -0.0386, -0.0094,  0.0365,  0.0017, -0.0298, -0.0117,  0.0044,\n          0.0127,  0.0326,  0.0317,  0.0291,  0.0415,  0.0047, -0.0076,  0.0462,\n          0.0495, -0.0091, -0.0008,  0.0415,  0.0447,  0.0332, -0.0606,  0.0198,\n          0.0548, -0.0097,  0.0082,  0.0242, -0.0546,  0.0318, -0.0483, -0.0073,\n          0.0331,  0.0500,  0.0395, -0.0613,  0.0589, -0.0265,  0.0465,  0.0490,\n          0.0356, -0.0037,  0.0137,  0.0050, -0.0434, -0.0059,  0.0222, -0.0107,\n         -0.0097,  0.0152,  0.0545,  0.0382,  0.0099,  0.0508, -0.0145,  0.0390,\n         -0.0379,  0.0250,  0.0102, -0.0361,  0.0224,  0.0307,  0.0303,  0.0156,\n         -0.0120, -0.0372, -0.0190, -0.0434, -0.0107, -0.0119,  0.0462, -0.0545,\n          0.0477,  0.0382, -0.0449,  0.0388, -0.0336,  0.0089,  0.0031, -0.0049,\n         -0.0188, -0.0400,  0.0145, -0.0033,  0.0349, -0.0595,  0.0078,  0.0443,\n         -0.0379, -0.0206, -0.0558, -0.0003,  0.0284, -0.0154, -0.0390, -0.0066],\n        [ 0.0327, -0.0039,  0.0018, -0.0564, -0.0256, -0.0048,  0.0308,  0.0506,\n          0.0446, -0.0566,  0.0440, -0.0316,  0.0367, -0.0099,  0.0467, -0.0202,\n          0.0109,  0.0234,  0.0010, -0.0202, -0.0284, -0.0511, -0.0024, -0.0592,\n         -0.0127,  0.0080,  0.0323,  0.0175,  0.0091,  0.0253, -0.0609, -0.0371,\n          0.0518,  0.0566,  0.0410,  0.0329,  0.0007, -0.0439, -0.0310, -0.0516,\n         -0.0430,  0.0192,  0.0290,  0.0575,  0.0477, -0.0546, -0.0135, -0.0586,\n          0.0232, -0.0014,  0.0130, -0.0327, -0.0431,  0.0101, -0.0187,  0.0014,\n          0.0320, -0.0618,  0.0187,  0.0158,  0.0397, -0.0043,  0.0248, -0.0124,\n         -0.0344, -0.0583,  0.0556,  0.0611,  0.0360, -0.0316,  0.0078,  0.0019,\n          0.0247,  0.0223, -0.0391,  0.0546,  0.0228, -0.0500,  0.0318,  0.0590,\n          0.0116, -0.0289,  0.0012, -0.0304, -0.0442, -0.0303, -0.0236, -0.0027,\n         -0.0317, -0.0424, -0.0012, -0.0108, -0.0456,  0.0392, -0.0167, -0.0368,\n          0.0025,  0.0406,  0.0234,  0.0272,  0.0130,  0.0437, -0.0570, -0.0074,\n          0.0263, -0.0448,  0.0196, -0.0402,  0.0220,  0.0115, -0.0420,  0.0134,\n          0.0058, -0.0047, -0.0605,  0.0311, -0.0328, -0.0501,  0.0383, -0.0542,\n          0.0494,  0.0543, -0.0088,  0.0375,  0.0345,  0.0395, -0.0480,  0.0290,\n         -0.0337,  0.0569, -0.0392, -0.0452,  0.0305,  0.0173, -0.0399, -0.0474,\n          0.0276, -0.0548,  0.0432,  0.0037, -0.0571, -0.0532,  0.0113, -0.0009,\n          0.0585,  0.0278, -0.0025, -0.0202, -0.0186, -0.0456,  0.0432, -0.0117,\n          0.0443,  0.0309,  0.0189,  0.0432, -0.0405, -0.0443,  0.0489,  0.0177,\n          0.0484,  0.0290, -0.0472, -0.0555, -0.0407,  0.0072, -0.0222, -0.0276,\n         -0.0417, -0.0500, -0.0535,  0.0159, -0.0458,  0.0521,  0.0333,  0.0621,\n         -0.0362,  0.0540, -0.0525,  0.0285,  0.0115,  0.0333,  0.0532, -0.0615,\n          0.0084,  0.0341, -0.0514,  0.0219,  0.0122,  0.0164,  0.0596,  0.0441,\n          0.0327,  0.0577,  0.0502, -0.0311, -0.0036,  0.0143, -0.0098, -0.0257,\n         -0.0005, -0.0466, -0.0146,  0.0259,  0.0509, -0.0580, -0.0623,  0.0411,\n         -0.0222, -0.0399,  0.0208, -0.0381,  0.0004,  0.0244,  0.0468, -0.0352,\n         -0.0091,  0.0346,  0.0562,  0.0349, -0.0517, -0.0540,  0.0439, -0.0391,\n         -0.0476, -0.0384,  0.0122,  0.0478,  0.0616,  0.0328, -0.0399, -0.0300,\n          0.0607, -0.0353,  0.0523, -0.0483,  0.0480,  0.0184, -0.0209,  0.0256,\n         -0.0156, -0.0147, -0.0100,  0.0289,  0.0173,  0.0228,  0.0155, -0.0195,\n          0.0582,  0.0034, -0.0013, -0.0218,  0.0052,  0.0088, -0.0071, -0.0269]],\n       device='cuda:0')"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	256,
                                            "out_features":	3,
                                            "training":	true
                                        }
                                    },
                                    "mu_layer":	{
                                        "Linear(in_features=256, out_features=3, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0597,  0.0137,  0.0032], device='cuda:0')",
                                                "weight":	"Parameter containing:\ntensor([[-0.0056,  0.0561,  0.0589, -0.0065,  0.0556,  0.0223, -0.0463,  0.0330,\n         -0.0069,  0.0560, -0.0072,  0.0354,  0.0273, -0.0108, -0.0544,  0.0034,\n         -0.0073,  0.0294,  0.0025,  0.0331, -0.0106,  0.0118, -0.0584, -0.0353,\n          0.0291, -0.0313, -0.0553,  0.0581,  0.0494,  0.0623, -0.0229,  0.0168,\n          0.0106, -0.0269,  0.0534, -0.0575,  0.0598, -0.0386,  0.0315, -0.0032,\n          0.0591,  0.0589, -0.0335, -0.0380, -0.0243,  0.0012,  0.0135, -0.0178,\n          0.0452,  0.0147, -0.0530,  0.0295,  0.0515, -0.0520, -0.0285, -0.0164,\n          0.0173,  0.0423, -0.0273,  0.0327, -0.0558,  0.0616,  0.0585, -0.0262,\n         -0.0304, -0.0506,  0.0245,  0.0573, -0.0221, -0.0537,  0.0497, -0.0236,\n          0.0548, -0.0264, -0.0428, -0.0596, -0.0177, -0.0326, -0.0217,  0.0222,\n          0.0281,  0.0289, -0.0085,  0.0030, -0.0487,  0.0554,  0.0055,  0.0435,\n         -0.0394, -0.0414,  0.0478,  0.0398,  0.0389,  0.0252,  0.0427,  0.0580,\n          0.0587,  0.0112, -0.0101,  0.0553,  0.0232, -0.0535, -0.0264, -0.0004,\n          0.0377,  0.0028, -0.0145, -0.0206,  0.0124, -0.0063,  0.0426,  0.0306,\n         -0.0597,  0.0096, -0.0210, -0.0457,  0.0448,  0.0062,  0.0155, -0.0352,\n          0.0244, -0.0131, -0.0368,  0.0434, -0.0351,  0.0059,  0.0536, -0.0589,\n         -0.0411,  0.0320,  0.0365, -0.0076, -0.0533,  0.0188,  0.0073,  0.0292,\n         -0.0141, -0.0112, -0.0345,  0.0427, -0.0312, -0.0598, -0.0190, -0.0221,\n          0.0577,  0.0033,  0.0156,  0.0221, -0.0532, -0.0282,  0.0099, -0.0421,\n          0.0227,  0.0438,  0.0446,  0.0206, -0.0602,  0.0469,  0.0608, -0.0287,\n          0.0357, -0.0301, -0.0177, -0.0554, -0.0343, -0.0191,  0.0473,  0.0447,\n          0.0235,  0.0109,  0.0067, -0.0475, -0.0375, -0.0264, -0.0277, -0.0522,\n         -0.0298, -0.0372, -0.0191,  0.0384, -0.0002,  0.0118, -0.0458,  0.0581,\n         -0.0483,  0.0550,  0.0043,  0.0485, -0.0095,  0.0211,  0.0521, -0.0005,\n          0.0519, -0.0617,  0.0392, -0.0409, -0.0267, -0.0623, -0.0472, -0.0186,\n         -0.0368, -0.0108,  0.0609, -0.0118,  0.0012,  0.0438,  0.0371, -0.0026,\n         -0.0416,  0.0146,  0.0280, -0.0056, -0.0003,  0.0150, -0.0293, -0.0457,\n          0.0552, -0.0173, -0.0372, -0.0515, -0.0506,  0.0569, -0.0363, -0.0617,\n         -0.0362,  0.0546, -0.0261,  0.0448,  0.0092,  0.0080,  0.0412, -0.0539,\n         -0.0446,  0.0111,  0.0543, -0.0548,  0.0064, -0.0162,  0.0125, -0.0139,\n         -0.0458,  0.0109,  0.0502,  0.0168,  0.0592, -0.0257, -0.0608, -0.0479,\n          0.0018, -0.0322, -0.0271, -0.0044,  0.0087, -0.0122, -0.0112, -0.0581],\n        [-0.0151,  0.0022,  0.0048,  0.0454,  0.0432, -0.0490,  0.0471, -0.0133,\n          0.0333, -0.0519, -0.0049, -0.0050,  0.0172,  0.0405,  0.0025, -0.0216,\n          0.0012, -0.0130, -0.0274,  0.0004,  0.0009,  0.0458, -0.0557, -0.0240,\n         -0.0097,  0.0192, -0.0612,  0.0577, -0.0106,  0.0501,  0.0331,  0.0068,\n          0.0188,  0.0488,  0.0577,  0.0467, -0.0410, -0.0211, -0.0011, -0.0211,\n          0.0505, -0.0049, -0.0137, -0.0361, -0.0541,  0.0208,  0.0181,  0.0487,\n         -0.0436,  0.0479,  0.0379, -0.0244,  0.0343, -0.0148,  0.0388, -0.0269,\n         -0.0361, -0.0393,  0.0007, -0.0429, -0.0211,  0.0141,  0.0528,  0.0063,\n          0.0281,  0.0411,  0.0396, -0.0213,  0.0376,  0.0134, -0.0304, -0.0026,\n          0.0151,  0.0403, -0.0049,  0.0483, -0.0596, -0.0488, -0.0191, -0.0255,\n          0.0101, -0.0278, -0.0463, -0.0509,  0.0039,  0.0526, -0.0157, -0.0507,\n         -0.0497, -0.0604, -0.0550, -0.0614,  0.0017, -0.0170,  0.0564,  0.0121,\n          0.0288, -0.0288, -0.0326,  0.0515, -0.0371, -0.0361,  0.0448,  0.0145,\n          0.0041,  0.0593,  0.0018, -0.0577, -0.0502,  0.0264,  0.0210, -0.0589,\n          0.0153,  0.0041,  0.0163, -0.0476,  0.0188,  0.0478, -0.0050, -0.0396,\n          0.0581, -0.0467,  0.0497, -0.0202, -0.0598, -0.0319, -0.0259,  0.0569,\n         -0.0553,  0.0387,  0.0576, -0.0450,  0.0306,  0.0292,  0.0182, -0.0108,\n         -0.0570,  0.0550,  0.0481,  0.0289, -0.0569,  0.0037, -0.0456, -0.0271,\n         -0.0364, -0.0393, -0.0302, -0.0387,  0.0042,  0.0015,  0.0553,  0.0361,\n          0.0509,  0.0103,  0.0263, -0.0197, -0.0185, -0.0541,  0.0495,  0.0375,\n          0.0120,  0.0455, -0.0037,  0.0101, -0.0360,  0.0624,  0.0425,  0.0487,\n         -0.0420,  0.0305,  0.0443, -0.0174, -0.0596,  0.0440,  0.0223, -0.0420,\n          0.0438, -0.0231,  0.0282, -0.0310, -0.0606, -0.0406, -0.0418,  0.0348,\n          0.0295,  0.0216,  0.0227,  0.0244, -0.0521,  0.0618, -0.0182, -0.0261,\n          0.0017,  0.0403, -0.0365,  0.0470, -0.0168,  0.0006,  0.0560,  0.0244,\n         -0.0215,  0.0600,  0.0272, -0.0592, -0.0154,  0.0622, -0.0494, -0.0581,\n         -0.0108,  0.0560,  0.0495,  0.0367,  0.0471,  0.0367,  0.0511, -0.0128,\n         -0.0423,  0.0473,  0.0113,  0.0472,  0.0465, -0.0610,  0.0319, -0.0481,\n         -0.0089,  0.0154, -0.0182, -0.0266,  0.0499,  0.0293, -0.0065, -0.0167,\n          0.0564,  0.0618,  0.0129, -0.0500,  0.0102,  0.0198,  0.0490, -0.0252,\n          0.0588, -0.0307,  0.0134, -0.0603,  0.0498, -0.0316,  0.0390, -0.0037,\n         -0.0256, -0.0267,  0.0408,  0.0091,  0.0411, -0.0442, -0.0052,  0.0106],\n        [-0.0143, -0.0619, -0.0251,  0.0522, -0.0436, -0.0514,  0.0469, -0.0177,\n         -0.0108, -0.0009,  0.0573,  0.0261, -0.0424, -0.0129, -0.0065, -0.0618,\n          0.0336,  0.0397,  0.0151,  0.0356,  0.0135, -0.0227,  0.0465,  0.0220,\n         -0.0351,  0.0226, -0.0296,  0.0140, -0.0004,  0.0387,  0.0413, -0.0349,\n          0.0344, -0.0504, -0.0180, -0.0287,  0.0254, -0.0060,  0.0368,  0.0222,\n          0.0537,  0.0528,  0.0521, -0.0161, -0.0551, -0.0564,  0.0457,  0.0266,\n          0.0580,  0.0078, -0.0148, -0.0030,  0.0467, -0.0525,  0.0505,  0.0476,\n         -0.0122, -0.0560, -0.0266, -0.0148, -0.0159,  0.0410, -0.0049, -0.0068,\n          0.0292,  0.0388,  0.0486, -0.0145, -0.0583,  0.0311,  0.0160, -0.0118,\n          0.0029, -0.0430, -0.0506,  0.0247, -0.0073, -0.0458,  0.0263, -0.0209,\n          0.0487,  0.0260, -0.0563, -0.0228, -0.0316,  0.0172,  0.0068, -0.0412,\n         -0.0120, -0.0575, -0.0200,  0.0281, -0.0469, -0.0314,  0.0541,  0.0506,\n         -0.0354,  0.0469,  0.0143,  0.0307,  0.0057, -0.0451,  0.0481,  0.0024,\n          0.0016, -0.0290,  0.0383, -0.0233,  0.0508, -0.0583,  0.0491,  0.0003,\n         -0.0201,  0.0027,  0.0148,  0.0261,  0.0605, -0.0056, -0.0568,  0.0164,\n         -0.0050,  0.0300,  0.0188,  0.0621, -0.0562,  0.0610, -0.0177, -0.0330,\n         -0.0190, -0.0074, -0.0398, -0.0403,  0.0504,  0.0125, -0.0541, -0.0122,\n          0.0455, -0.0320,  0.0157, -0.0465, -0.0404,  0.0062, -0.0020,  0.0293,\n         -0.0267, -0.0165, -0.0503, -0.0426,  0.0614, -0.0255,  0.0235, -0.0134,\n          0.0321, -0.0472, -0.0308, -0.0068, -0.0063,  0.0502,  0.0250,  0.0050,\n         -0.0380,  0.0051,  0.0594,  0.0379,  0.0517, -0.0375, -0.0264,  0.0384,\n         -0.0542,  0.0061,  0.0045,  0.0391, -0.0342, -0.0079,  0.0194, -0.0194,\n         -0.0304, -0.0462, -0.0346,  0.0161, -0.0506,  0.0373,  0.0268,  0.0542,\n         -0.0479, -0.0053,  0.0563,  0.0106, -0.0336, -0.0488, -0.0020, -0.0561,\n          0.0411, -0.0041,  0.0298,  0.0276, -0.0282, -0.0281, -0.0373,  0.0340,\n         -0.0338, -0.0018,  0.0101, -0.0246,  0.0061,  0.0438, -0.0309,  0.0277,\n          0.0608,  0.0163, -0.0406, -0.0145,  0.0098,  0.0074, -0.0042, -0.0179,\n          0.0101, -0.0089,  0.0360, -0.0389, -0.0233,  0.0442, -0.0245,  0.0170,\n          0.0621, -0.0523,  0.0156,  0.0582, -0.0326, -0.0581, -0.0235,  0.0300,\n         -0.0128,  0.0383, -0.0121,  0.0557,  0.0164,  0.0016,  0.0596, -0.0170,\n          0.0577,  0.0107, -0.0008, -0.0031, -0.0507,  0.0421, -0.0029, -0.0432,\n         -0.0596, -0.0337, -0.0422, -0.0049,  0.0231, -0.0438,  0.0472,  0.0131]],\n       device='cuda:0')"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	256,
                                            "out_features":	3,
                                            "training":	true
                                        }
                                    },
                                    "net":	{
                                        "Sequential(\n  (0): Linear(in_features=11, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=11, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 2.3528e-01, -1.1756e-01, -2.1102e-01,  1.9181e-01, -4.6902e-02,\n         5.1993e-02,  2.9176e-02, -4.0808e-02,  1.9807e-01, -8.0414e-02,\n         1.5549e-01, -2.6027e-01,  1.1759e-01, -8.9729e-02,  3.1262e-02,\n        -3.5751e-02,  1.0693e-01,  1.4222e-01, -2.1302e-01, -9.1505e-02,\n         2.1113e-01, -1.5893e-01, -2.5049e-01,  2.6801e-01, -2.8664e-01,\n         2.5989e-01,  9.0804e-02, -1.3338e-01,  1.7688e-02, -1.4658e-02,\n         3.6991e-02, -1.1118e-01,  1.1465e-01, -8.5246e-02,  2.5624e-01,\n         2.4020e-02, -2.2129e-01,  2.8736e-01,  1.3636e-01,  1.2980e-01,\n         2.8984e-01,  2.8675e-01, -2.9858e-01, -2.9201e-01,  2.8634e-01,\n        -8.1378e-02, -1.6173e-01,  2.1146e-01, -5.8019e-02, -5.6801e-02,\n        -1.7768e-01, -8.0472e-03, -2.3783e-01,  2.6249e-01, -1.6454e-01,\n         1.3382e-01,  2.7190e-01, -2.0419e-01,  2.5857e-01,  1.8407e-01,\n         2.2776e-01,  5.1021e-02,  1.1875e-01, -2.8891e-01,  2.1369e-01,\n        -2.5593e-01, -3.7154e-02,  1.8676e-01, -2.2017e-01, -2.9591e-01,\n        -9.3203e-02, -1.2008e-01, -5.5501e-02,  2.0166e-01,  1.9397e-01,\n         2.6689e-01,  1.4112e-01, -7.3737e-02,  4.8376e-02,  1.4414e-01,\n         2.5733e-01, -9.3608e-02,  1.2342e-01, -2.4346e-02, -5.5531e-02,\n        -2.3966e-01, -6.1610e-02,  2.9740e-01,  2.0008e-01, -2.3372e-01,\n        -1.0931e-01,  4.5191e-02, -2.9062e-01, -8.4785e-03, -1.5176e-01,\n        -8.6061e-02,  2.8338e-01,  7.9164e-02,  2.5453e-01,  3.9063e-02,\n         1.9278e-01,  2.1812e-01, -2.1576e-01, -2.2757e-01,  8.2260e-02,\n         2.1218e-01, -2.1015e-02,  2.9678e-01,  7.3834e-02,  1.7103e-01,\n        -1.5547e-01, -1.2860e-01,  8.1478e-02,  1.1830e-01,  1.8509e-01,\n         9.6655e-02,  2.5262e-01,  4.0178e-03,  1.4149e-02,  2.1101e-01,\n        -2.2166e-02,  1.3612e-02, -1.3057e-01, -8.2893e-02,  2.9207e-01,\n         7.9276e-02, -9.9322e-02,  5.2722e-02, -1.4787e-01, -1.2038e-01,\n         9.3370e-02,  2.2819e-01, -7.8597e-02,  1.3932e-01,  2.8072e-02,\n         7.7293e-02, -2.7251e-01, -2.9239e-01, -8.0606e-02, -2.8401e-01,\n        -7.9695e-02, -2.0172e-01,  3.7758e-02,  2.3895e-01, -2.3319e-01,\n        -1.3098e-01,  1.3061e-01, -1.0944e-01, -4.1687e-02, -2.4275e-01,\n         1.3633e-01,  1.1173e-01, -1.3405e-01,  2.3542e-01,  5.1754e-02,\n        -2.3945e-01,  1.0521e-02,  1.9292e-01,  2.6847e-01, -2.8062e-01,\n         1.8994e-01,  6.6108e-02, -1.1905e-01, -3.1608e-02, -5.6367e-03,\n         1.8586e-01,  2.5025e-01,  1.0908e-01, -2.3524e-01,  1.3617e-01,\n         1.2392e-01, -1.6711e-01, -1.7319e-01, -2.2005e-01, -1.8671e-01,\n         2.5458e-01,  9.5314e-02, -2.7858e-01,  2.3945e-01, -2.2350e-01,\n        -1.4468e-01, -2.0225e-01,  1.2305e-01,  2.4167e-01, -2.7924e-01,\n        -2.6793e-01,  2.7063e-01,  3.7430e-02,  9.9614e-02, -1.1852e-01,\n        -2.4071e-01,  3.9331e-02,  2.7131e-02,  2.2383e-03,  7.0100e-02,\n         9.5716e-02,  1.0438e-01, -1.4502e-01, -1.1321e-01,  2.1810e-01,\n        -5.1150e-03,  2.1371e-01,  2.1812e-01,  2.4069e-01,  7.3489e-02,\n        -2.2153e-01,  1.3785e-01, -2.8645e-02, -2.2433e-01,  2.7354e-01,\n        -2.4482e-01, -1.6868e-01, -1.7754e-01, -1.8218e-02,  9.3894e-04,\n        -1.1549e-01, -1.4346e-01, -6.7244e-02,  1.7396e-01,  1.2952e-02,\n         6.4056e-02,  1.5566e-01, -2.6454e-01, -4.1963e-02, -1.2937e-01,\n        -2.4078e-01,  8.8560e-02, -2.4987e-01,  1.4266e-01, -1.6436e-01,\n        -3.8392e-02,  3.2850e-02, -8.0605e-02,  1.0449e-02, -2.6906e-02,\n        -2.5154e-02, -1.3813e-01, -1.8100e-01,  7.0266e-02,  2.0095e-01,\n        -5.2479e-02,  5.0345e-02,  8.9551e-02, -4.9288e-02,  9.3552e-02,\n        -2.6084e-01,  2.3340e-01,  2.4582e-01,  2.2462e-01,  1.3845e-01,\n        -2.9290e-04, -1.6319e-01,  1.9023e-01, -2.8132e-01,  2.1850e-02,\n         1.2003e-01], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1886,  0.2749,  0.1040,  ..., -0.2965, -0.2526,  0.2289],\n        [ 0.0466,  0.0334, -0.2213,  ...,  0.1429,  0.0910, -0.1780],\n        [ 0.2549,  0.2367, -0.1734,  ...,  0.1845,  0.1106,  0.2380],\n        ...,\n        [-0.2161,  0.1044,  0.2802,  ...,  0.1007,  0.0116,  0.2316],\n        [ 0.1474,  0.1873, -0.0499,  ..., -0.1511,  0.0026, -0.1289],\n        [-0.0322,  0.2597,  0.2477,  ..., -0.2148, -0.1052,  0.0456]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	11,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0540, -0.0608,  0.0283, -0.0066, -0.0555,  0.0547, -0.0424, -0.0292,\n        -0.0482,  0.0451, -0.0118, -0.0293,  0.0213, -0.0557,  0.0323, -0.0369,\n         0.0467,  0.0624,  0.0014,  0.0128,  0.0160, -0.0593,  0.0028, -0.0269,\n        -0.0246, -0.0494, -0.0536, -0.0201,  0.0080,  0.0257,  0.0474, -0.0017,\n         0.0027,  0.0582,  0.0404,  0.0051,  0.0242,  0.0185, -0.0295,  0.0361,\n         0.0343,  0.0230, -0.0425,  0.0315, -0.0370,  0.0009, -0.0331,  0.0195,\n        -0.0069, -0.0225,  0.0160,  0.0177, -0.0612,  0.0486, -0.0442, -0.0198,\n         0.0363,  0.0579,  0.0605, -0.0420, -0.0199,  0.0314, -0.0551,  0.0491,\n        -0.0602,  0.0447, -0.0181,  0.0546,  0.0187,  0.0257, -0.0440, -0.0478,\n         0.0216, -0.0394,  0.0236,  0.0251, -0.0476, -0.0296, -0.0051, -0.0385,\n         0.0192,  0.0305,  0.0594, -0.0178, -0.0169, -0.0443, -0.0547, -0.0233,\n         0.0072,  0.0264, -0.0175,  0.0054,  0.0169, -0.0615,  0.0072,  0.0104,\n         0.0520,  0.0040,  0.0409,  0.0084,  0.0359,  0.0533,  0.0499,  0.0009,\n        -0.0311, -0.0526, -0.0073,  0.0560, -0.0081,  0.0127, -0.0531, -0.0411,\n        -0.0314,  0.0462,  0.0283, -0.0451, -0.0444,  0.0155,  0.0429,  0.0197,\n         0.0052,  0.0147,  0.0511,  0.0349,  0.0183,  0.0450, -0.0369, -0.0477,\n         0.0310,  0.0010, -0.0229,  0.0601, -0.0158,  0.0379,  0.0085, -0.0456,\n         0.0519, -0.0593, -0.0586,  0.0521, -0.0007, -0.0137,  0.0447, -0.0128,\n        -0.0138, -0.0471, -0.0077,  0.0072,  0.0194,  0.0151,  0.0394,  0.0097,\n        -0.0478,  0.0559,  0.0321,  0.0272,  0.0016, -0.0530,  0.0063, -0.0081,\n        -0.0289,  0.0145, -0.0605, -0.0300,  0.0172, -0.0391, -0.0427, -0.0493,\n        -0.0260,  0.0306,  0.0582, -0.0334,  0.0503,  0.0264,  0.0241, -0.0157,\n        -0.0428,  0.0561,  0.0556, -0.0087,  0.0587, -0.0519, -0.0323,  0.0409,\n        -0.0318, -0.0155, -0.0599, -0.0064,  0.0517,  0.0381, -0.0139,  0.0405,\n         0.0276,  0.0186, -0.0540, -0.0621,  0.0530,  0.0253, -0.0566,  0.0263,\n         0.0417,  0.0602, -0.0529,  0.0270,  0.0056, -0.0485,  0.0035, -0.0033,\n         0.0298,  0.0531, -0.0580,  0.0599,  0.0304, -0.0553,  0.0543,  0.0043,\n        -0.0040, -0.0466,  0.0143,  0.0099, -0.0071,  0.0357,  0.0482, -0.0130,\n         0.0179,  0.0602, -0.0066, -0.0111, -0.0040,  0.0535, -0.0431, -0.0158,\n        -0.0593,  0.0302,  0.0187, -0.0547,  0.0486,  0.0497, -0.0237, -0.0434,\n         0.0212,  0.0063,  0.0055,  0.0588,  0.0331, -0.0285, -0.0544, -0.0258,\n        -0.0190,  0.0378, -0.0581, -0.0447, -0.0391,  0.0127,  0.0400,  0.0023],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0036, -0.0020,  0.0583,  ...,  0.0112, -0.0419, -0.0308],\n        [-0.0168, -0.0059,  0.0166,  ..., -0.0585,  0.0295, -0.0605],\n        [-0.0254,  0.0565,  0.0432,  ...,  0.0213, -0.0463, -0.0407],\n        ...,\n        [ 0.0492, -0.0475,  0.0324,  ..., -0.0347,  0.0382,  0.0276],\n        [-0.0357, -0.0522, -0.0239,  ..., -0.0195,  0.0468, -0.0235],\n        [-0.0612,  0.0447,  0.0446,  ..., -0.0427, -0.0603,  0.0252]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "act_limit":	"1.0",
                                "training":	true
                            }
                        },
                        "q1":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=14, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=14, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=1, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=14, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1187, -0.0145,  0.0472, -0.1500,  0.0601,  0.2632,  0.0794,  0.2635,\n         0.2590, -0.1685, -0.1216,  0.2111,  0.1390,  0.2431,  0.0578, -0.0703,\n        -0.2669,  0.2300,  0.1892, -0.0359,  0.1561,  0.1278,  0.0980,  0.0430,\n         0.0278,  0.2356,  0.1864,  0.0366, -0.0021,  0.2648,  0.0503, -0.1045,\n         0.2375,  0.1275, -0.2135, -0.2219,  0.0610,  0.1196, -0.1942,  0.1406,\n        -0.0023,  0.0892, -0.1256, -0.2571,  0.0010, -0.0347, -0.1354,  0.2448,\n         0.1359,  0.1352,  0.1868, -0.1998, -0.1041, -0.1653, -0.1015, -0.0908,\n         0.2137,  0.2440, -0.0337,  0.2118, -0.2102,  0.0444,  0.0698, -0.0797,\n        -0.2558,  0.1812, -0.2474,  0.1147, -0.0201,  0.1998, -0.0704,  0.1224,\n         0.0079,  0.0169, -0.0843,  0.1925,  0.1529,  0.1960, -0.2108,  0.2457,\n         0.1134,  0.2635,  0.1764,  0.1829,  0.2066, -0.1859, -0.0211, -0.1288,\n         0.1730,  0.0334, -0.1024, -0.2556, -0.0807,  0.1364,  0.0903,  0.0243,\n         0.0169, -0.0635,  0.2378,  0.1600, -0.0249, -0.1315,  0.2648,  0.1173,\n         0.0646,  0.1192, -0.1863,  0.2147, -0.1889, -0.0822,  0.1517, -0.0861,\n        -0.2594, -0.1170, -0.1198,  0.1011,  0.0909, -0.1318, -0.0579,  0.2178,\n         0.0536,  0.1578,  0.1079,  0.2422, -0.1871, -0.1156, -0.0560, -0.0194,\n        -0.1179, -0.1240,  0.0265,  0.2196, -0.2269,  0.1812, -0.2381, -0.1853,\n         0.1541,  0.0747,  0.0456,  0.0907, -0.0716,  0.2380,  0.1666,  0.0769,\n        -0.2177,  0.0687, -0.0033,  0.2397,  0.0850, -0.1259, -0.2130, -0.1403,\n        -0.0627, -0.0112,  0.0158,  0.0590,  0.2606,  0.1373, -0.1481, -0.0768,\n        -0.1176, -0.2616, -0.1427,  0.0392, -0.0765, -0.2561, -0.1658, -0.0670,\n        -0.0896,  0.1721, -0.0049,  0.1459, -0.2168,  0.2293,  0.1679,  0.2153,\n        -0.0464, -0.0898,  0.0510, -0.1421, -0.1843, -0.2579,  0.0663,  0.2005,\n         0.0410,  0.0805,  0.2412,  0.1143,  0.1473,  0.0856,  0.2177, -0.2107,\n         0.1164, -0.1962, -0.1871,  0.2315, -0.2654,  0.1796,  0.1334, -0.1346,\n        -0.0602, -0.2296, -0.2404,  0.0463, -0.2165, -0.2610,  0.0967, -0.0258,\n         0.2468,  0.0411, -0.2633,  0.2437, -0.0163, -0.1576,  0.2194, -0.1359,\n        -0.0019, -0.0553, -0.1896,  0.2638, -0.0884, -0.1851,  0.1906,  0.1083,\n        -0.0356, -0.0145,  0.0043,  0.2652,  0.1696,  0.1438,  0.0136, -0.1383,\n        -0.1451, -0.1022,  0.0974,  0.0780,  0.0478,  0.0823,  0.1098, -0.1671,\n        -0.1036, -0.2430, -0.2483, -0.1689, -0.0668,  0.2102,  0.1385,  0.0409,\n         0.2138, -0.0240, -0.0433,  0.1185,  0.2244, -0.2578, -0.1149, -0.1302],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1768,  0.0056, -0.1600,  ..., -0.2328, -0.0894, -0.0372],\n        [ 0.1734, -0.2291, -0.1992,  ..., -0.0255, -0.1920, -0.0404],\n        [ 0.2403, -0.0665, -0.1089,  ...,  0.0583,  0.1886,  0.0925],\n        ...,\n        [ 0.0321,  0.0782, -0.2351,  ..., -0.0112,  0.0600, -0.2255],\n        [-0.2544, -0.0527,  0.0382,  ..., -0.0369,  0.0429, -0.0143],\n        [ 0.1640,  0.0818,  0.1031,  ...,  0.2423,  0.0885, -0.2002]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	14,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0500,  0.0459,  0.0394,  0.0578, -0.0265, -0.0122, -0.0218, -0.0005,\n        -0.0517,  0.0352, -0.0560,  0.0334,  0.0548,  0.0417, -0.0503,  0.0620,\n        -0.0428, -0.0035,  0.0239, -0.0527, -0.0226,  0.0373,  0.0440,  0.0146,\n         0.0297, -0.0137,  0.0594,  0.0066, -0.0563,  0.0070, -0.0001, -0.0559,\n        -0.0431, -0.0406, -0.0332,  0.0485,  0.0544, -0.0261,  0.0282,  0.0217,\n         0.0387, -0.0035, -0.0168, -0.0237,  0.0240, -0.0403,  0.0483,  0.0196,\n         0.0069, -0.0136, -0.0023, -0.0249, -0.0180,  0.0107,  0.0129,  0.0031,\n         0.0403, -0.0128, -0.0360,  0.0430,  0.0430,  0.0427, -0.0214,  0.0344,\n        -0.0153,  0.0153,  0.0452, -0.0384, -0.0159, -0.0600,  0.0064, -0.0154,\n        -0.0030,  0.0048,  0.0318,  0.0429,  0.0157,  0.0108,  0.0228, -0.0100,\n         0.0064,  0.0049,  0.0025, -0.0161, -0.0195,  0.0397,  0.0272, -0.0411,\n        -0.0042,  0.0384,  0.0482, -0.0279, -0.0418, -0.0138, -0.0404,  0.0168,\n        -0.0500, -0.0219, -0.0539,  0.0256,  0.0302, -0.0083,  0.0118,  0.0592,\n        -0.0616,  0.0266,  0.0330,  0.0176,  0.0565, -0.0589,  0.0465,  0.0207,\n        -0.0097,  0.0325, -0.0359, -0.0500,  0.0425, -0.0356, -0.0150,  0.0312,\n         0.0577,  0.0221, -0.0239, -0.0446, -0.0023, -0.0416, -0.0618,  0.0035,\n         0.0003,  0.0476, -0.0571, -0.0504, -0.0435,  0.0002,  0.0536, -0.0527,\n        -0.0056, -0.0575, -0.0515, -0.0299,  0.0558, -0.0297,  0.0078, -0.0420,\n         0.0056,  0.0092,  0.0451,  0.0258,  0.0125, -0.0574, -0.0269,  0.0209,\n         0.0318, -0.0355, -0.0362,  0.0565, -0.0347, -0.0531, -0.0074, -0.0234,\n        -0.0465, -0.0398, -0.0340,  0.0320,  0.0130, -0.0256,  0.0451,  0.0120,\n         0.0301,  0.0466,  0.0441, -0.0458, -0.0559, -0.0491, -0.0607,  0.0601,\n         0.0574, -0.0135,  0.0583, -0.0002, -0.0585,  0.0623,  0.0417,  0.0281,\n        -0.0450,  0.0511, -0.0393,  0.0040, -0.0574,  0.0532,  0.0153,  0.0289,\n        -0.0074, -0.0599,  0.0037,  0.0261,  0.0175, -0.0142,  0.0197,  0.0453,\n         0.0018,  0.0448,  0.0323,  0.0123, -0.0071,  0.0442, -0.0497,  0.0535,\n        -0.0507,  0.0394,  0.0407,  0.0343, -0.0405,  0.0355,  0.0199, -0.0350,\n        -0.0621,  0.0426,  0.0050, -0.0213,  0.0470, -0.0118, -0.0508,  0.0221,\n         0.0330, -0.0226,  0.0006, -0.0381,  0.0522, -0.0392, -0.0008, -0.0302,\n        -0.0235,  0.0384,  0.0193,  0.0349, -0.0558,  0.0353,  0.0014,  0.0331,\n         0.0465,  0.0482,  0.0071, -0.0235,  0.0420, -0.0139, -0.0378, -0.0112,\n        -0.0110,  0.0388,  0.0064, -0.0414, -0.0127,  0.0277, -0.0226, -0.0171],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0504, -0.0328, -0.0041,  ..., -0.0570,  0.0604,  0.0232],\n        [-0.0472,  0.0321,  0.0306,  ..., -0.0569, -0.0160,  0.0162],\n        [-0.0048,  0.0235, -0.0493,  ..., -0.0485,  0.0614,  0.0435],\n        ...,\n        [ 0.0381,  0.0577,  0.0287,  ...,  0.0430, -0.0070, -0.0096],\n        [-0.0040, -0.0513,  0.0272,  ...,  0.0581,  0.0084, -0.0518],\n        [ 0.0022,  0.0086, -0.0461,  ..., -0.0057, -0.0220, -0.0236]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0057], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0590,  0.0474, -0.0397, -0.0094,  0.0033, -0.0367,  0.0077,  0.0620,\n         -0.0234,  0.0170, -0.0078, -0.0070,  0.0120,  0.0037, -0.0300, -0.0341,\n          0.0440,  0.0029, -0.0441, -0.0583, -0.0546, -0.0554, -0.0112, -0.0069,\n          0.0267,  0.0480, -0.0412,  0.0240,  0.0439,  0.0094,  0.0294, -0.0299,\n          0.0287, -0.0174, -0.0125, -0.0232, -0.0447, -0.0554,  0.0590,  0.0459,\n         -0.0297,  0.0553,  0.0339,  0.0327, -0.0155,  0.0190, -0.0247, -0.0327,\n          0.0004,  0.0605, -0.0142, -0.0173, -0.0006,  0.0592,  0.0199, -0.0062,\n         -0.0006,  0.0295, -0.0373,  0.0223, -0.0474, -0.0215, -0.0203, -0.0322,\n         -0.0465,  0.0047, -0.0156, -0.0463,  0.0453, -0.0402,  0.0148,  0.0334,\n          0.0130, -0.0394,  0.0608,  0.0504,  0.0449,  0.0420, -0.0318, -0.0153,\n         -0.0007, -0.0414, -0.0307,  0.0565,  0.0363, -0.0365, -0.0505,  0.0606,\n         -0.0203, -0.0422,  0.0476, -0.0345,  0.0323,  0.0233,  0.0516,  0.0500,\n          0.0380, -0.0230,  0.0490,  0.0142,  0.0423, -0.0533, -0.0300,  0.0066,\n          0.0095, -0.0199,  0.0378,  0.0608,  0.0620,  0.0455, -0.0338,  0.0063,\n         -0.0035, -0.0034,  0.0559, -0.0384,  0.0352, -0.0284,  0.0417, -0.0142,\n         -0.0371,  0.0590, -0.0278,  0.0096,  0.0021, -0.0271, -0.0083,  0.0381,\n          0.0023, -0.0417,  0.0544,  0.0463, -0.0326,  0.0223,  0.0345,  0.0467,\n         -0.0234,  0.0378, -0.0242,  0.0242,  0.0213, -0.0207, -0.0074, -0.0623,\n          0.0206, -0.0096, -0.0481,  0.0340,  0.0105, -0.0576,  0.0033,  0.0117,\n          0.0262, -0.0012,  0.0591, -0.0281,  0.0064, -0.0399,  0.0428, -0.0173,\n         -0.0014,  0.0019,  0.0621, -0.0086,  0.0179,  0.0362, -0.0336,  0.0386,\n          0.0483,  0.0161, -0.0204, -0.0563,  0.0005, -0.0170,  0.0009,  0.0145,\n         -0.0104,  0.0409, -0.0198,  0.0515,  0.0400, -0.0459, -0.0010,  0.0008,\n          0.0251, -0.0112, -0.0334,  0.0048, -0.0501,  0.0029,  0.0599, -0.0586,\n         -0.0250, -0.0086, -0.0449,  0.0057,  0.0145,  0.0042,  0.0556, -0.0450,\n         -0.0537, -0.0322,  0.0193, -0.0527,  0.0006, -0.0407,  0.0147,  0.0104,\n         -0.0174,  0.0040,  0.0182,  0.0071, -0.0188,  0.0521, -0.0123,  0.0387,\n          0.0615, -0.0316, -0.0281, -0.0448, -0.0414, -0.0623,  0.0384,  0.0581,\n         -0.0162, -0.0191,  0.0460, -0.0279,  0.0456,  0.0114,  0.0234,  0.0211,\n         -0.0593, -0.0341, -0.0460,  0.0392,  0.0512,  0.0163,  0.0096,  0.0156,\n          0.0454,  0.0384, -0.0256, -0.0561,  0.0305, -0.0312, -0.0479, -0.0448,\n          0.0271,  0.0314,  0.0285,  0.0397, -0.0062,  0.0141, -0.0335, -0.0462]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "q2":	{
                            "MLPQFunction(\n  (q): Sequential(\n    (0): Linear(in_features=14, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n    (5): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "q":	{
                                        "Sequential(\n  (0): Linear(in_features=14, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=1, bias=True)\n  (5): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=14, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.2032,  0.1033,  0.0146,  0.1174,  0.2221, -0.0170, -0.2266,  0.0460,\n         0.1687, -0.2493, -0.1780,  0.0422,  0.0139,  0.1795, -0.0274,  0.1105,\n         0.2447, -0.2287, -0.0254, -0.1112,  0.0935, -0.0604, -0.2165, -0.2348,\n        -0.0739,  0.1766, -0.2289, -0.1103, -0.2085,  0.2507,  0.0773, -0.0032,\n        -0.2415,  0.1284, -0.0926, -0.2465,  0.0949, -0.0274, -0.2665, -0.2268,\n         0.1219,  0.0713, -0.0425,  0.1274, -0.1318,  0.0403, -0.0677, -0.1599,\n        -0.0442, -0.1798, -0.1062, -0.0513,  0.0827,  0.2231, -0.0754,  0.1773,\n         0.1280,  0.1007,  0.1004,  0.1427, -0.0326,  0.1999, -0.1815, -0.1373,\n        -0.0983, -0.1201,  0.2469,  0.1166, -0.1803,  0.2008, -0.2350,  0.1539,\n        -0.0096, -0.1768,  0.0046,  0.0657,  0.0348, -0.1833, -0.1977, -0.1395,\n        -0.0021,  0.0656,  0.2488, -0.0722, -0.1850,  0.1612,  0.1828,  0.0423,\n        -0.1406, -0.1220,  0.1332,  0.1295, -0.0005,  0.0364,  0.1262, -0.0765,\n        -0.0469, -0.2306, -0.2509, -0.1462,  0.0808, -0.0757,  0.1172,  0.1691,\n         0.2123,  0.0919, -0.1003,  0.2207, -0.1481,  0.2560, -0.1489,  0.1745,\n        -0.0043,  0.1214, -0.2078, -0.2349, -0.0078, -0.2502,  0.1371,  0.1664,\n        -0.2535,  0.2278,  0.0473,  0.1590,  0.1921, -0.2473, -0.1460, -0.0328,\n         0.0023,  0.2395,  0.1857, -0.1186, -0.0286, -0.2376,  0.1053, -0.2543,\n        -0.0946, -0.2631, -0.1980, -0.0935,  0.2508, -0.0004, -0.1723, -0.1293,\n         0.1148, -0.0571,  0.2159, -0.0394, -0.1759,  0.1327, -0.0061, -0.1728,\n        -0.0070,  0.0265, -0.2391,  0.0311, -0.1826, -0.1239, -0.1390, -0.1259,\n         0.1512, -0.2465, -0.2576,  0.0004,  0.1257, -0.0679, -0.1699,  0.2622,\n        -0.2229,  0.2190, -0.0431,  0.1943, -0.1537, -0.2355, -0.2116,  0.0416,\n        -0.2431, -0.1208, -0.1634,  0.2389,  0.2564, -0.2199, -0.0410,  0.1425,\n        -0.0596, -0.1789, -0.2402, -0.0679, -0.1505,  0.1571,  0.1226,  0.1883,\n         0.2012,  0.0607,  0.0843, -0.1298,  0.0106,  0.1701,  0.0492,  0.2527,\n         0.2212,  0.1765, -0.1075,  0.0468,  0.0386,  0.2602, -0.0949,  0.0126,\n         0.0044, -0.1364,  0.1590, -0.2197,  0.0184, -0.0685,  0.0977, -0.1258,\n         0.0233, -0.1609,  0.2367, -0.0860,  0.0185, -0.1846, -0.2642, -0.1020,\n        -0.1930, -0.1098,  0.1648, -0.1336, -0.0261,  0.2115,  0.0964,  0.1986,\n        -0.0089, -0.2480,  0.1327, -0.1179, -0.2090,  0.1410,  0.0165,  0.2406,\n        -0.0479, -0.1536,  0.2495,  0.0790, -0.2205, -0.1235,  0.0635,  0.2191,\n         0.1709, -0.1656, -0.1424, -0.0169, -0.2439,  0.0067,  0.2386, -0.2451],\n       device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0198,  0.0509,  0.1029,  ..., -0.0809,  0.0448, -0.0199],\n        [ 0.0793, -0.2493, -0.0495,  ...,  0.0817,  0.2073, -0.2551],\n        [-0.2489, -0.2074,  0.2519,  ...,  0.1753,  0.0644,  0.0788],\n        ...,\n        [ 0.0461,  0.0036,  0.0340,  ..., -0.1588, -0.0558,  0.0228],\n        [ 0.2110, -0.1540,  0.0049,  ...,  0.0580,  0.1851, -0.2029],\n        [ 0.0175, -0.1501,  0.1571,  ...,  0.1391, -0.1945, -0.0671]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	14,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=256, out_features=256, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 3.9048e-03,  2.1574e-02, -1.1005e-02,  2.4183e-02,  3.2534e-02,\n        -3.3743e-02, -4.0422e-03, -5.3024e-02, -1.4131e-02, -4.9334e-02,\n        -2.3312e-02,  5.4515e-02, -4.7153e-02,  4.5458e-02, -3.9268e-02,\n         8.3877e-03, -7.3382e-03,  1.6383e-02, -2.8477e-02,  2.2241e-02,\n        -3.8105e-02, -4.7430e-02, -2.3048e-02,  1.8019e-02, -3.3381e-02,\n        -3.1290e-02,  5.8679e-02, -1.2932e-02,  1.3860e-02, -5.5323e-03,\n        -1.6675e-02,  3.0720e-02, -9.0352e-03, -2.6343e-02,  5.2876e-02,\n        -3.0360e-02, -4.4997e-02, -1.3136e-02, -7.3841e-04, -3.0139e-02,\n         2.7645e-03, -7.5837e-03,  3.5965e-02,  1.8923e-02, -5.5858e-02,\n        -3.1186e-02, -2.9359e-02,  6.1492e-02,  3.2940e-03, -3.4747e-02,\n        -3.5472e-02, -1.3977e-02,  3.7621e-02,  6.2461e-02, -2.9364e-02,\n        -3.2132e-02,  1.1491e-02,  7.9730e-03, -4.6148e-02,  3.8341e-02,\n         2.0482e-02,  1.7033e-02,  5.3329e-02, -2.7434e-02,  7.4931e-03,\n        -5.5484e-02,  5.4683e-02, -3.6156e-02,  2.0895e-02,  5.8426e-02,\n        -5.8538e-02, -2.3072e-02, -5.1497e-02, -5.1776e-02, -2.9869e-02,\n        -4.8895e-02,  2.4200e-02, -5.0240e-02, -1.9605e-02, -2.9475e-02,\n         3.9443e-05, -1.3211e-02,  5.7421e-02, -1.9668e-02, -7.8719e-03,\n        -5.5853e-03,  6.7320e-04, -2.2309e-02, -3.6204e-02, -1.0454e-02,\n        -3.7717e-02,  1.4182e-02, -1.8460e-03, -3.2889e-02,  4.8449e-02,\n         2.6050e-02, -6.2479e-02,  3.8324e-03, -2.7123e-02, -1.1528e-02,\n         1.0323e-03,  3.5475e-02,  2.6622e-02,  3.8778e-02, -3.4551e-02,\n         3.3271e-02,  1.6628e-02, -5.6607e-02, -1.7540e-02,  5.3056e-02,\n         2.3654e-02,  2.0510e-02, -1.4940e-02,  3.5134e-02, -6.0713e-02,\n        -5.3427e-02, -5.7889e-03, -4.0597e-02, -1.4364e-02, -6.1374e-02,\n         5.7555e-03,  4.8226e-02,  1.8347e-03, -6.2276e-02,  1.6883e-02,\n        -1.3041e-02,  5.4609e-02, -5.1981e-02, -5.7395e-02, -6.2205e-02,\n         5.0269e-02, -5.5210e-02, -6.0732e-02,  5.9687e-02,  3.0275e-02,\n        -5.6525e-02, -2.1263e-02, -2.3915e-02, -2.9648e-02, -3.8705e-02,\n         2.7335e-03,  3.9414e-02, -1.4854e-02,  9.3599e-03, -9.0421e-03,\n         1.9945e-02, -1.4221e-02,  4.7112e-02, -1.9347e-02,  3.6835e-02,\n        -2.1495e-02,  6.1693e-02, -3.3383e-03, -5.7891e-02, -5.3921e-02,\n         5.8997e-02,  8.8001e-03, -1.6484e-02, -4.7432e-02, -2.5082e-02,\n         4.6924e-03,  1.5771e-02,  3.5383e-03,  4.9198e-02, -2.1220e-02,\n        -4.8849e-02,  4.1869e-04,  9.6992e-03, -3.6853e-02,  3.8505e-03,\n        -2.4716e-02,  3.5932e-02,  9.0228e-03,  2.9376e-02, -3.5010e-02,\n         4.5773e-03, -3.8382e-02,  1.4425e-02, -4.2902e-02, -1.0590e-03,\n        -1.2679e-02,  3.4802e-03, -5.6717e-02,  1.2632e-02, -2.6073e-02,\n        -4.7833e-02, -3.9666e-02,  4.1066e-02,  5.3430e-02, -4.6832e-02,\n        -5.7929e-02, -5.8264e-04, -1.4093e-02,  2.1208e-02,  3.8703e-02,\n         2.9370e-03,  9.1674e-03,  3.0681e-04, -1.0884e-02,  1.2379e-02,\n         3.6347e-03, -1.1364e-03,  4.8373e-02,  2.9317e-02,  5.1176e-02,\n        -3.0153e-02, -2.8935e-03,  1.1227e-02, -5.8618e-02,  1.1969e-02,\n         7.7420e-03,  2.9972e-02,  2.4609e-04,  4.4606e-02, -2.5356e-02,\n         5.6037e-02,  6.3339e-03,  3.4087e-03,  5.6976e-02, -4.1888e-02,\n        -5.7119e-03, -7.6832e-03, -5.3568e-02, -5.4952e-02,  3.9376e-03,\n        -5.8436e-02,  5.6198e-02,  3.4100e-02,  1.7658e-02, -3.2102e-02,\n        -2.1439e-02, -5.5724e-02,  2.1767e-02, -1.8205e-02,  4.8394e-02,\n         1.6337e-02,  7.5377e-03,  1.6566e-02, -2.7799e-02, -5.6529e-02,\n         8.2166e-03, -3.8752e-03, -1.8406e-02, -5.3407e-02, -1.8497e-02,\n         4.3667e-02, -2.1424e-02,  3.4502e-02,  2.0564e-02, -3.2415e-02,\n         3.1211e-02,  3.7426e-02, -4.5413e-02, -8.6662e-03,  4.3584e-02,\n         3.1396e-02], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0398,  0.0204, -0.0081,  ...,  0.0245,  0.0541,  0.0451],\n        [ 0.0604,  0.0507, -0.0585,  ...,  0.0513,  0.0532,  0.0288],\n        [-0.0058, -0.0493,  0.0111,  ...,  0.0608,  0.0396,  0.0344],\n        ...,\n        [-0.0241, -0.0415,  0.0262,  ...,  0.0446, -0.0456, -0.0063],\n        [-0.0394,  0.0555,  0.0034,  ..., -0.0139,  0.0185,  0.0283],\n        [-0.0092, -0.0573, -0.0263,  ...,  0.0222,  0.0431, -0.0440]],\n       device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	256,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=256, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0242], device='cuda:0')",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.1850e-02,  9.6254e-05,  5.2145e-02, -2.0427e-02, -7.3187e-03,\n          6.2246e-02,  1.9453e-02, -4.9074e-02, -4.8667e-03,  1.6419e-02,\n          4.7418e-03,  4.9396e-02,  1.3771e-03, -4.6917e-02, -5.0577e-02,\n          2.4406e-02,  2.1224e-02,  3.6825e-02, -1.2623e-02, -5.2208e-02,\n          2.2402e-02,  6.3886e-04,  5.1799e-02, -1.6023e-02, -2.6141e-02,\n          9.1676e-03,  1.6891e-02,  6.1733e-02,  5.2159e-02,  4.5710e-02,\n          5.9459e-02, -3.8299e-02,  5.8606e-03,  5.9016e-02,  6.5828e-03,\n          4.1698e-02,  2.9845e-02,  6.1671e-02, -1.5038e-02,  9.8490e-04,\n          2.6191e-02, -2.5480e-03,  1.5057e-02, -4.6581e-02, -1.0476e-02,\n         -2.6142e-02, -4.8111e-02,  1.6993e-02, -4.7490e-02, -3.2123e-02,\n         -2.4901e-02,  3.7425e-02,  4.1948e-03,  4.6523e-02,  1.4070e-02,\n          2.0280e-02, -4.5477e-02,  7.7266e-03,  5.4545e-02, -3.3317e-02,\n          5.9411e-02,  1.7974e-02, -4.8488e-02, -7.4885e-03,  2.8144e-02,\n         -2.3596e-02,  1.2804e-02,  5.0216e-02,  3.6245e-02, -1.1508e-02,\n         -4.8281e-02, -5.2793e-02, -5.0429e-02,  8.5230e-03,  1.7088e-02,\n         -2.8461e-02,  2.5148e-02, -3.0721e-02,  4.9128e-03,  3.7309e-02,\n         -3.1526e-02,  4.2944e-02,  7.6105e-03, -1.2763e-02,  2.2289e-02,\n         -5.6153e-02,  2.7076e-02, -1.0474e-02,  4.4770e-02,  1.3008e-02,\n          1.6522e-02,  3.3067e-02,  1.0152e-02,  3.0906e-02, -5.8517e-03,\n         -3.7948e-03, -3.2381e-02,  3.2961e-02, -2.2705e-02,  5.7281e-02,\n         -3.3357e-02,  1.0795e-02, -2.6509e-02,  3.4499e-02,  5.9936e-03,\n          4.2765e-02, -2.7076e-02,  2.6296e-02,  2.7945e-02,  4.3302e-03,\n          5.7212e-02,  4.7805e-02,  5.9481e-02, -6.2351e-02, -3.6697e-02,\n          3.5847e-02, -5.7014e-02,  4.5530e-02,  3.2032e-02,  4.6794e-02,\n         -4.4197e-02, -2.9945e-03, -5.2221e-02,  5.0929e-02,  7.6213e-04,\n          4.5927e-02,  6.1937e-02,  3.6511e-02, -6.1067e-02,  4.8873e-02,\n          4.6556e-02, -5.2908e-02,  4.9261e-02,  3.2546e-03, -4.0115e-02,\n         -8.2285e-03, -1.6088e-02,  5.1301e-03,  4.5164e-02,  5.0844e-03,\n         -1.5887e-02,  4.2302e-02,  5.1438e-02,  1.4307e-02,  5.4801e-02,\n         -3.0784e-02, -3.4805e-03,  1.9430e-02,  5.0566e-03, -7.9205e-03,\n          5.4113e-02,  2.6284e-02, -9.4083e-03,  1.9397e-02, -5.4864e-02,\n          3.8903e-02, -5.5359e-02,  6.1466e-03, -7.9018e-03, -3.2284e-02,\n          4.1622e-02,  2.5171e-02,  5.8127e-02,  3.0189e-02, -4.8237e-02,\n         -2.3084e-02, -2.6494e-02, -4.4275e-02,  1.0787e-02,  5.3675e-02,\n         -5.1051e-02,  3.7893e-02, -4.4314e-02,  2.3909e-02,  5.3116e-02,\n         -3.1521e-02, -4.1152e-02,  7.2898e-03, -3.6532e-02,  3.1747e-02,\n          4.1091e-02,  5.8488e-02, -3.4523e-02, -3.0744e-02, -5.7184e-02,\n          6.0100e-02,  3.1318e-02,  6.4005e-03, -3.8256e-02, -6.2171e-02,\n         -4.7432e-03, -2.2598e-02, -6.0701e-02, -8.8612e-03, -9.8999e-03,\n          3.4124e-02,  4.4937e-02,  2.7819e-02,  1.1292e-02, -4.1241e-02,\n          3.2599e-02,  1.4296e-02, -5.4993e-02, -4.7226e-03,  5.6266e-03,\n         -5.7269e-02,  6.0903e-02, -5.8601e-02,  9.1637e-03, -5.7374e-03,\n          4.2750e-02, -3.1434e-02,  3.1183e-02, -2.1519e-02, -5.1015e-02,\n          5.2059e-02,  1.5361e-04,  2.9651e-02,  6.2371e-02,  3.0871e-02,\n         -7.5478e-03, -2.6959e-02,  1.6449e-02,  5.8957e-02, -2.7672e-02,\n          3.5424e-02, -6.2203e-02, -3.9646e-02, -3.3094e-02,  5.6046e-02,\n          3.2608e-02, -3.1356e-02, -4.0486e-02, -2.5819e-02,  1.1862e-02,\n          1.1511e-02, -1.3739e-02,  4.3089e-02,  3.9914e-02,  5.8645e-02,\n         -2.9536e-02,  6.1192e-02,  4.9375e-03, -4.0944e-02, -2.2565e-02,\n         -2.2539e-02,  8.8568e-03, -3.8093e-02,  3.8967e-02, -3.8513e-03,\n          2.8764e-02,  6.5629e-03, -4.6070e-02,  3.3465e-02,  4.8165e-02,\n         -1.7196e-02]], device='cuda:0')"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	256,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "act_dim":	3,
            "alpha":	0.2,
            "buffer":	{
                "<spinup.alogos.sac.sac.ReplayBuffer object at 0x7fe2aa3a7810>":	{
                    "act_buf":	"[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]\n ...\n [0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]",
                    "device":	"cuda:0",
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "max_size":	1000000,
                    "obs2_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "size":	0
                }
            },
            "delay_up":	0.995,
            "device":	"cuda:0",
            "env":	{
                "<TimeLimit<HopperEnv<Hopper-v2>>>":	{
                    "_action_space":	null,
                    "_elapsed_steps":	null,
                    "_max_episode_steps":	1000,
                    "_metadata":	null,
                    "_observation_space":	null,
                    "_reward_range":	null,
                    "env":	{
                        "<HopperEnv<Hopper-v2>>":	{
                            "_ezpickle_args":	[],
                            "_ezpickle_kwargs":	{},
                            "_viewers":	{},
                            "action_space":	{
                                "Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)":	{
                                    "_np_random":	"RandomState(MT19937)",
                                    "_shape":	[
                                        3
                                    ],
                                    "bounded_above":	"[ True  True  True]",
                                    "bounded_below":	"[ True  True  True]",
                                    "dtype":	"float32",
                                    "high":	"[1. 1. 1.]",
                                    "low":	"[-1. -1. -1.]"
                                }
                            },
                            "data":	"<mujoco_py.cymj.PyMjData object at 0x55557b979ee0>",
                            "frame_skip":	4,
                            "init_qpos":	"[0.   1.25 0.   0.   0.   0.  ]",
                            "init_qvel":	"[0. 0. 0. 0. 0. 0.]",
                            "metadata":	{
                                "render.modes":	[
                                    "human",
                                    "rgb_array",
                                    "depth_array"
                                ],
                                "video.frames_per_second":	125
                            },
                            "model":	"<mujoco_py.cymj.PyMjModel object at 0x55557c145d50>",
                            "np_random":	"RandomState(MT19937)",
                            "observation_space":	{
                                "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)":	{
                                    "_np_random":	null,
                                    "_shape":	[
                                        11
                                    ],
                                    "bounded_above":	"[False False False False False False False False False False False]",
                                    "bounded_below":	"[False False False False False False False False False False False]",
                                    "dtype":	"float64",
                                    "high":	"[inf inf inf inf inf inf inf inf inf inf inf]",
                                    "low":	"[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]"
                                }
                            },
                            "sim":	"<mujoco_py.cymj.MjSim object at 0x7fe28e857f80>",
                            "spec":	{
                                "EnvSpec(Hopper-v2)":	{
                                    "_env_name":	"Hopper",
                                    "_kwargs":	{},
                                    "entry_point":	"gym.envs.mujoco:HopperEnv",
                                    "id":	"Hopper-v2",
                                    "max_episode_steps":	1000,
                                    "nondeterministic":	false,
                                    "order_enforce":	true,
                                    "reward_threshold":	3800.0
                                }
                            },
                            "viewer":	null
                        }
                    }
                }
            },
            "gamma":	0.99,
            "logger":	{
                "<spinup.utils.logx.EpochLogger object at 0x7fe28f517350>":	{
                    "epoch_dict":	{},
                    "exp_name":	"sac_hopper",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/cxliu/deeplearning_zp/spinningup_project/data/sac_hopper/sac_hopper_s0",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/cxliu/deeplearning_zp/spinningup_project/data/sac_hopper/sac_hopper_s0/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "max_ep_len":	1000,
            "num_test_epsodes":	10,
            "obs_dim":	[
                11
            ],
            "pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1886,  0.2749,  0.1040,  ..., -0.2965, -0.2526,  0.2289],\n        [ 0.0466,  0.0334, -0.2213,  ...,  0.1429,  0.0910, -0.1780],\n        [ 0.2549,  0.2367, -0.1734,  ...,  0.1845,  0.1106,  0.2380],\n        ...,\n        [-0.2161,  0.1044,  0.2802,  ...,  0.1007,  0.0116,  0.2316],\n        [ 0.1474,  0.1873, -0.0499,  ..., -0.1511,  0.0026, -0.1289],\n        [-0.0322,  0.2597,  0.2477,  ..., -0.2148, -0.1052,  0.0456]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 2.3528e-01, -1.1756e-01, -2.1102e-01,  1.9181e-01, -4.6902e-02,\n         5.1993e-02,  2.9176e-02, -4.0808e-02,  1.9807e-01, -8.0414e-02,\n         1.5549e-01, -2.6027e-01,  1.1759e-01, -8.9729e-02,  3.1262e-02,\n        -3.5751e-02,  1.0693e-01,  1.4222e-01, -2.1302e-01, -9.1505e-02,\n         2.1113e-01, -1.5893e-01, -2.5049e-01,  2.6801e-01, -2.8664e-01,\n         2.5989e-01,  9.0804e-02, -1.3338e-01,  1.7688e-02, -1.4658e-02,\n         3.6991e-02, -1.1118e-01,  1.1465e-01, -8.5246e-02,  2.5624e-01,\n         2.4020e-02, -2.2129e-01,  2.8736e-01,  1.3636e-01,  1.2980e-01,\n         2.8984e-01,  2.8675e-01, -2.9858e-01, -2.9201e-01,  2.8634e-01,\n        -8.1378e-02, -1.6173e-01,  2.1146e-01, -5.8019e-02, -5.6801e-02,\n        -1.7768e-01, -8.0472e-03, -2.3783e-01,  2.6249e-01, -1.6454e-01,\n         1.3382e-01,  2.7190e-01, -2.0419e-01,  2.5857e-01,  1.8407e-01,\n         2.2776e-01,  5.1021e-02,  1.1875e-01, -2.8891e-01,  2.1369e-01,\n        -2.5593e-01, -3.7154e-02,  1.8676e-01, -2.2017e-01, -2.9591e-01,\n        -9.3203e-02, -1.2008e-01, -5.5501e-02,  2.0166e-01,  1.9397e-01,\n         2.6689e-01,  1.4112e-01, -7.3737e-02,  4.8376e-02,  1.4414e-01,\n         2.5733e-01, -9.3608e-02,  1.2342e-01, -2.4346e-02, -5.5531e-02,\n        -2.3966e-01, -6.1610e-02,  2.9740e-01,  2.0008e-01, -2.3372e-01,\n        -1.0931e-01,  4.5191e-02, -2.9062e-01, -8.4785e-03, -1.5176e-01,\n        -8.6061e-02,  2.8338e-01,  7.9164e-02,  2.5453e-01,  3.9063e-02,\n         1.9278e-01,  2.1812e-01, -2.1576e-01, -2.2757e-01,  8.2260e-02,\n         2.1218e-01, -2.1015e-02,  2.9678e-01,  7.3834e-02,  1.7103e-01,\n        -1.5547e-01, -1.2860e-01,  8.1478e-02,  1.1830e-01,  1.8509e-01,\n         9.6655e-02,  2.5262e-01,  4.0178e-03,  1.4149e-02,  2.1101e-01,\n        -2.2166e-02,  1.3612e-02, -1.3057e-01, -8.2893e-02,  2.9207e-01,\n         7.9276e-02, -9.9322e-02,  5.2722e-02, -1.4787e-01, -1.2038e-01,\n         9.3370e-02,  2.2819e-01, -7.8597e-02,  1.3932e-01,  2.8072e-02,\n         7.7293e-02, -2.7251e-01, -2.9239e-01, -8.0606e-02, -2.8401e-01,\n        -7.9695e-02, -2.0172e-01,  3.7758e-02,  2.3895e-01, -2.3319e-01,\n        -1.3098e-01,  1.3061e-01, -1.0944e-01, -4.1687e-02, -2.4275e-01,\n         1.3633e-01,  1.1173e-01, -1.3405e-01,  2.3542e-01,  5.1754e-02,\n        -2.3945e-01,  1.0521e-02,  1.9292e-01,  2.6847e-01, -2.8062e-01,\n         1.8994e-01,  6.6108e-02, -1.1905e-01, -3.1608e-02, -5.6367e-03,\n         1.8586e-01,  2.5025e-01,  1.0908e-01, -2.3524e-01,  1.3617e-01,\n         1.2392e-01, -1.6711e-01, -1.7319e-01, -2.2005e-01, -1.8671e-01,\n         2.5458e-01,  9.5314e-02, -2.7858e-01,  2.3945e-01, -2.2350e-01,\n        -1.4468e-01, -2.0225e-01,  1.2305e-01,  2.4167e-01, -2.7924e-01,\n        -2.6793e-01,  2.7063e-01,  3.7430e-02,  9.9614e-02, -1.1852e-01,\n        -2.4071e-01,  3.9331e-02,  2.7131e-02,  2.2383e-03,  7.0100e-02,\n         9.5716e-02,  1.0438e-01, -1.4502e-01, -1.1321e-01,  2.1810e-01,\n        -5.1150e-03,  2.1371e-01,  2.1812e-01,  2.4069e-01,  7.3489e-02,\n        -2.2153e-01,  1.3785e-01, -2.8645e-02, -2.2433e-01,  2.7354e-01,\n        -2.4482e-01, -1.6868e-01, -1.7754e-01, -1.8218e-02,  9.3894e-04,\n        -1.1549e-01, -1.4346e-01, -6.7244e-02,  1.7396e-01,  1.2952e-02,\n         6.4056e-02,  1.5566e-01, -2.6454e-01, -4.1963e-02, -1.2937e-01,\n        -2.4078e-01,  8.8560e-02, -2.4987e-01,  1.4266e-01, -1.6436e-01,\n        -3.8392e-02,  3.2850e-02, -8.0605e-02,  1.0449e-02, -2.6906e-02,\n        -2.5154e-02, -1.3813e-01, -1.8100e-01,  7.0266e-02,  2.0095e-01,\n        -5.2479e-02,  5.0345e-02,  8.9551e-02, -4.9288e-02,  9.3552e-02,\n        -2.6084e-01,  2.3340e-01,  2.4582e-01,  2.2462e-01,  1.3845e-01,\n        -2.9290e-04, -1.6319e-01,  1.9023e-01, -2.8132e-01,  2.1850e-02,\n         1.2003e-01], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0036, -0.0020,  0.0583,  ...,  0.0112, -0.0419, -0.0308],\n        [-0.0168, -0.0059,  0.0166,  ..., -0.0585,  0.0295, -0.0605],\n        [-0.0254,  0.0565,  0.0432,  ...,  0.0213, -0.0463, -0.0407],\n        ...,\n        [ 0.0492, -0.0475,  0.0324,  ..., -0.0347,  0.0382,  0.0276],\n        [-0.0357, -0.0522, -0.0239,  ..., -0.0195,  0.0468, -0.0235],\n        [-0.0612,  0.0447,  0.0446,  ..., -0.0427, -0.0603,  0.0252]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0540, -0.0608,  0.0283, -0.0066, -0.0555,  0.0547, -0.0424, -0.0292,\n        -0.0482,  0.0451, -0.0118, -0.0293,  0.0213, -0.0557,  0.0323, -0.0369,\n         0.0467,  0.0624,  0.0014,  0.0128,  0.0160, -0.0593,  0.0028, -0.0269,\n        -0.0246, -0.0494, -0.0536, -0.0201,  0.0080,  0.0257,  0.0474, -0.0017,\n         0.0027,  0.0582,  0.0404,  0.0051,  0.0242,  0.0185, -0.0295,  0.0361,\n         0.0343,  0.0230, -0.0425,  0.0315, -0.0370,  0.0009, -0.0331,  0.0195,\n        -0.0069, -0.0225,  0.0160,  0.0177, -0.0612,  0.0486, -0.0442, -0.0198,\n         0.0363,  0.0579,  0.0605, -0.0420, -0.0199,  0.0314, -0.0551,  0.0491,\n        -0.0602,  0.0447, -0.0181,  0.0546,  0.0187,  0.0257, -0.0440, -0.0478,\n         0.0216, -0.0394,  0.0236,  0.0251, -0.0476, -0.0296, -0.0051, -0.0385,\n         0.0192,  0.0305,  0.0594, -0.0178, -0.0169, -0.0443, -0.0547, -0.0233,\n         0.0072,  0.0264, -0.0175,  0.0054,  0.0169, -0.0615,  0.0072,  0.0104,\n         0.0520,  0.0040,  0.0409,  0.0084,  0.0359,  0.0533,  0.0499,  0.0009,\n        -0.0311, -0.0526, -0.0073,  0.0560, -0.0081,  0.0127, -0.0531, -0.0411,\n        -0.0314,  0.0462,  0.0283, -0.0451, -0.0444,  0.0155,  0.0429,  0.0197,\n         0.0052,  0.0147,  0.0511,  0.0349,  0.0183,  0.0450, -0.0369, -0.0477,\n         0.0310,  0.0010, -0.0229,  0.0601, -0.0158,  0.0379,  0.0085, -0.0456,\n         0.0519, -0.0593, -0.0586,  0.0521, -0.0007, -0.0137,  0.0447, -0.0128,\n        -0.0138, -0.0471, -0.0077,  0.0072,  0.0194,  0.0151,  0.0394,  0.0097,\n        -0.0478,  0.0559,  0.0321,  0.0272,  0.0016, -0.0530,  0.0063, -0.0081,\n        -0.0289,  0.0145, -0.0605, -0.0300,  0.0172, -0.0391, -0.0427, -0.0493,\n        -0.0260,  0.0306,  0.0582, -0.0334,  0.0503,  0.0264,  0.0241, -0.0157,\n        -0.0428,  0.0561,  0.0556, -0.0087,  0.0587, -0.0519, -0.0323,  0.0409,\n        -0.0318, -0.0155, -0.0599, -0.0064,  0.0517,  0.0381, -0.0139,  0.0405,\n         0.0276,  0.0186, -0.0540, -0.0621,  0.0530,  0.0253, -0.0566,  0.0263,\n         0.0417,  0.0602, -0.0529,  0.0270,  0.0056, -0.0485,  0.0035, -0.0033,\n         0.0298,  0.0531, -0.0580,  0.0599,  0.0304, -0.0553,  0.0543,  0.0043,\n        -0.0040, -0.0466,  0.0143,  0.0099, -0.0071,  0.0357,  0.0482, -0.0130,\n         0.0179,  0.0602, -0.0066, -0.0111, -0.0040,  0.0535, -0.0431, -0.0158,\n        -0.0593,  0.0302,  0.0187, -0.0547,  0.0486,  0.0497, -0.0237, -0.0434,\n         0.0212,  0.0063,  0.0055,  0.0588,  0.0331, -0.0285, -0.0544, -0.0258,\n        -0.0190,  0.0378, -0.0581, -0.0447, -0.0391,  0.0127,  0.0400,  0.0023],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0056,  0.0561,  0.0589, -0.0065,  0.0556,  0.0223, -0.0463,  0.0330,\n         -0.0069,  0.0560, -0.0072,  0.0354,  0.0273, -0.0108, -0.0544,  0.0034,\n         -0.0073,  0.0294,  0.0025,  0.0331, -0.0106,  0.0118, -0.0584, -0.0353,\n          0.0291, -0.0313, -0.0553,  0.0581,  0.0494,  0.0623, -0.0229,  0.0168,\n          0.0106, -0.0269,  0.0534, -0.0575,  0.0598, -0.0386,  0.0315, -0.0032,\n          0.0591,  0.0589, -0.0335, -0.0380, -0.0243,  0.0012,  0.0135, -0.0178,\n          0.0452,  0.0147, -0.0530,  0.0295,  0.0515, -0.0520, -0.0285, -0.0164,\n          0.0173,  0.0423, -0.0273,  0.0327, -0.0558,  0.0616,  0.0585, -0.0262,\n         -0.0304, -0.0506,  0.0245,  0.0573, -0.0221, -0.0537,  0.0497, -0.0236,\n          0.0548, -0.0264, -0.0428, -0.0596, -0.0177, -0.0326, -0.0217,  0.0222,\n          0.0281,  0.0289, -0.0085,  0.0030, -0.0487,  0.0554,  0.0055,  0.0435,\n         -0.0394, -0.0414,  0.0478,  0.0398,  0.0389,  0.0252,  0.0427,  0.0580,\n          0.0587,  0.0112, -0.0101,  0.0553,  0.0232, -0.0535, -0.0264, -0.0004,\n          0.0377,  0.0028, -0.0145, -0.0206,  0.0124, -0.0063,  0.0426,  0.0306,\n         -0.0597,  0.0096, -0.0210, -0.0457,  0.0448,  0.0062,  0.0155, -0.0352,\n          0.0244, -0.0131, -0.0368,  0.0434, -0.0351,  0.0059,  0.0536, -0.0589,\n         -0.0411,  0.0320,  0.0365, -0.0076, -0.0533,  0.0188,  0.0073,  0.0292,\n         -0.0141, -0.0112, -0.0345,  0.0427, -0.0312, -0.0598, -0.0190, -0.0221,\n          0.0577,  0.0033,  0.0156,  0.0221, -0.0532, -0.0282,  0.0099, -0.0421,\n          0.0227,  0.0438,  0.0446,  0.0206, -0.0602,  0.0469,  0.0608, -0.0287,\n          0.0357, -0.0301, -0.0177, -0.0554, -0.0343, -0.0191,  0.0473,  0.0447,\n          0.0235,  0.0109,  0.0067, -0.0475, -0.0375, -0.0264, -0.0277, -0.0522,\n         -0.0298, -0.0372, -0.0191,  0.0384, -0.0002,  0.0118, -0.0458,  0.0581,\n         -0.0483,  0.0550,  0.0043,  0.0485, -0.0095,  0.0211,  0.0521, -0.0005,\n          0.0519, -0.0617,  0.0392, -0.0409, -0.0267, -0.0623, -0.0472, -0.0186,\n         -0.0368, -0.0108,  0.0609, -0.0118,  0.0012,  0.0438,  0.0371, -0.0026,\n         -0.0416,  0.0146,  0.0280, -0.0056, -0.0003,  0.0150, -0.0293, -0.0457,\n          0.0552, -0.0173, -0.0372, -0.0515, -0.0506,  0.0569, -0.0363, -0.0617,\n         -0.0362,  0.0546, -0.0261,  0.0448,  0.0092,  0.0080,  0.0412, -0.0539,\n         -0.0446,  0.0111,  0.0543, -0.0548,  0.0064, -0.0162,  0.0125, -0.0139,\n         -0.0458,  0.0109,  0.0502,  0.0168,  0.0592, -0.0257, -0.0608, -0.0479,\n          0.0018, -0.0322, -0.0271, -0.0044,  0.0087, -0.0122, -0.0112, -0.0581],\n        [-0.0151,  0.0022,  0.0048,  0.0454,  0.0432, -0.0490,  0.0471, -0.0133,\n          0.0333, -0.0519, -0.0049, -0.0050,  0.0172,  0.0405,  0.0025, -0.0216,\n          0.0012, -0.0130, -0.0274,  0.0004,  0.0009,  0.0458, -0.0557, -0.0240,\n         -0.0097,  0.0192, -0.0612,  0.0577, -0.0106,  0.0501,  0.0331,  0.0068,\n          0.0188,  0.0488,  0.0577,  0.0467, -0.0410, -0.0211, -0.0011, -0.0211,\n          0.0505, -0.0049, -0.0137, -0.0361, -0.0541,  0.0208,  0.0181,  0.0487,\n         -0.0436,  0.0479,  0.0379, -0.0244,  0.0343, -0.0148,  0.0388, -0.0269,\n         -0.0361, -0.0393,  0.0007, -0.0429, -0.0211,  0.0141,  0.0528,  0.0063,\n          0.0281,  0.0411,  0.0396, -0.0213,  0.0376,  0.0134, -0.0304, -0.0026,\n          0.0151,  0.0403, -0.0049,  0.0483, -0.0596, -0.0488, -0.0191, -0.0255,\n          0.0101, -0.0278, -0.0463, -0.0509,  0.0039,  0.0526, -0.0157, -0.0507,\n         -0.0497, -0.0604, -0.0550, -0.0614,  0.0017, -0.0170,  0.0564,  0.0121,\n          0.0288, -0.0288, -0.0326,  0.0515, -0.0371, -0.0361,  0.0448,  0.0145,\n          0.0041,  0.0593,  0.0018, -0.0577, -0.0502,  0.0264,  0.0210, -0.0589,\n          0.0153,  0.0041,  0.0163, -0.0476,  0.0188,  0.0478, -0.0050, -0.0396,\n          0.0581, -0.0467,  0.0497, -0.0202, -0.0598, -0.0319, -0.0259,  0.0569,\n         -0.0553,  0.0387,  0.0576, -0.0450,  0.0306,  0.0292,  0.0182, -0.0108,\n         -0.0570,  0.0550,  0.0481,  0.0289, -0.0569,  0.0037, -0.0456, -0.0271,\n         -0.0364, -0.0393, -0.0302, -0.0387,  0.0042,  0.0015,  0.0553,  0.0361,\n          0.0509,  0.0103,  0.0263, -0.0197, -0.0185, -0.0541,  0.0495,  0.0375,\n          0.0120,  0.0455, -0.0037,  0.0101, -0.0360,  0.0624,  0.0425,  0.0487,\n         -0.0420,  0.0305,  0.0443, -0.0174, -0.0596,  0.0440,  0.0223, -0.0420,\n          0.0438, -0.0231,  0.0282, -0.0310, -0.0606, -0.0406, -0.0418,  0.0348,\n          0.0295,  0.0216,  0.0227,  0.0244, -0.0521,  0.0618, -0.0182, -0.0261,\n          0.0017,  0.0403, -0.0365,  0.0470, -0.0168,  0.0006,  0.0560,  0.0244,\n         -0.0215,  0.0600,  0.0272, -0.0592, -0.0154,  0.0622, -0.0494, -0.0581,\n         -0.0108,  0.0560,  0.0495,  0.0367,  0.0471,  0.0367,  0.0511, -0.0128,\n         -0.0423,  0.0473,  0.0113,  0.0472,  0.0465, -0.0610,  0.0319, -0.0481,\n         -0.0089,  0.0154, -0.0182, -0.0266,  0.0499,  0.0293, -0.0065, -0.0167,\n          0.0564,  0.0618,  0.0129, -0.0500,  0.0102,  0.0198,  0.0490, -0.0252,\n          0.0588, -0.0307,  0.0134, -0.0603,  0.0498, -0.0316,  0.0390, -0.0037,\n         -0.0256, -0.0267,  0.0408,  0.0091,  0.0411, -0.0442, -0.0052,  0.0106],\n        [-0.0143, -0.0619, -0.0251,  0.0522, -0.0436, -0.0514,  0.0469, -0.0177,\n         -0.0108, -0.0009,  0.0573,  0.0261, -0.0424, -0.0129, -0.0065, -0.0618,\n          0.0336,  0.0397,  0.0151,  0.0356,  0.0135, -0.0227,  0.0465,  0.0220,\n         -0.0351,  0.0226, -0.0296,  0.0140, -0.0004,  0.0387,  0.0413, -0.0349,\n          0.0344, -0.0504, -0.0180, -0.0287,  0.0254, -0.0060,  0.0368,  0.0222,\n          0.0537,  0.0528,  0.0521, -0.0161, -0.0551, -0.0564,  0.0457,  0.0266,\n          0.0580,  0.0078, -0.0148, -0.0030,  0.0467, -0.0525,  0.0505,  0.0476,\n         -0.0122, -0.0560, -0.0266, -0.0148, -0.0159,  0.0410, -0.0049, -0.0068,\n          0.0292,  0.0388,  0.0486, -0.0145, -0.0583,  0.0311,  0.0160, -0.0118,\n          0.0029, -0.0430, -0.0506,  0.0247, -0.0073, -0.0458,  0.0263, -0.0209,\n          0.0487,  0.0260, -0.0563, -0.0228, -0.0316,  0.0172,  0.0068, -0.0412,\n         -0.0120, -0.0575, -0.0200,  0.0281, -0.0469, -0.0314,  0.0541,  0.0506,\n         -0.0354,  0.0469,  0.0143,  0.0307,  0.0057, -0.0451,  0.0481,  0.0024,\n          0.0016, -0.0290,  0.0383, -0.0233,  0.0508, -0.0583,  0.0491,  0.0003,\n         -0.0201,  0.0027,  0.0148,  0.0261,  0.0605, -0.0056, -0.0568,  0.0164,\n         -0.0050,  0.0300,  0.0188,  0.0621, -0.0562,  0.0610, -0.0177, -0.0330,\n         -0.0190, -0.0074, -0.0398, -0.0403,  0.0504,  0.0125, -0.0541, -0.0122,\n          0.0455, -0.0320,  0.0157, -0.0465, -0.0404,  0.0062, -0.0020,  0.0293,\n         -0.0267, -0.0165, -0.0503, -0.0426,  0.0614, -0.0255,  0.0235, -0.0134,\n          0.0321, -0.0472, -0.0308, -0.0068, -0.0063,  0.0502,  0.0250,  0.0050,\n         -0.0380,  0.0051,  0.0594,  0.0379,  0.0517, -0.0375, -0.0264,  0.0384,\n         -0.0542,  0.0061,  0.0045,  0.0391, -0.0342, -0.0079,  0.0194, -0.0194,\n         -0.0304, -0.0462, -0.0346,  0.0161, -0.0506,  0.0373,  0.0268,  0.0542,\n         -0.0479, -0.0053,  0.0563,  0.0106, -0.0336, -0.0488, -0.0020, -0.0561,\n          0.0411, -0.0041,  0.0298,  0.0276, -0.0282, -0.0281, -0.0373,  0.0340,\n         -0.0338, -0.0018,  0.0101, -0.0246,  0.0061,  0.0438, -0.0309,  0.0277,\n          0.0608,  0.0163, -0.0406, -0.0145,  0.0098,  0.0074, -0.0042, -0.0179,\n          0.0101, -0.0089,  0.0360, -0.0389, -0.0233,  0.0442, -0.0245,  0.0170,\n          0.0621, -0.0523,  0.0156,  0.0582, -0.0326, -0.0581, -0.0235,  0.0300,\n         -0.0128,  0.0383, -0.0121,  0.0557,  0.0164,  0.0016,  0.0596, -0.0170,\n          0.0577,  0.0107, -0.0008, -0.0031, -0.0507,  0.0421, -0.0029, -0.0432,\n         -0.0596, -0.0337, -0.0422, -0.0049,  0.0231, -0.0438,  0.0472,  0.0131]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0597,  0.0137,  0.0032], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0563,  0.0496,  0.0195,  0.0203, -0.0011,  0.0380, -0.0097,  0.0317,\n         -0.0462, -0.0538, -0.0289,  0.0383, -0.0025, -0.0546,  0.0145, -0.0118,\n          0.0444,  0.0108,  0.0052, -0.0580,  0.0158, -0.0621, -0.0299,  0.0412,\n         -0.0406,  0.0239,  0.0578,  0.0084,  0.0291, -0.0384,  0.0056, -0.0492,\n          0.0560, -0.0148,  0.0322, -0.0418, -0.0121, -0.0526,  0.0309,  0.0024,\n         -0.0211, -0.0452,  0.0610, -0.0270,  0.0519, -0.0538, -0.0339,  0.0341,\n         -0.0218,  0.0385, -0.0374,  0.0202, -0.0085,  0.0566, -0.0339, -0.0025,\n          0.0184, -0.0416, -0.0270,  0.0282, -0.0111, -0.0437, -0.0022, -0.0563,\n          0.0276,  0.0355, -0.0483,  0.0610,  0.0231,  0.0229,  0.0312,  0.0506,\n         -0.0619,  0.0551, -0.0439, -0.0312, -0.0496, -0.0030, -0.0261,  0.0610,\n         -0.0279, -0.0556, -0.0514, -0.0016, -0.0476,  0.0093, -0.0451,  0.0348,\n          0.0427,  0.0543, -0.0537, -0.0232,  0.0508,  0.0276, -0.0039, -0.0018,\n         -0.0332, -0.0366,  0.0225, -0.0516, -0.0252, -0.0044,  0.0476, -0.0199,\n          0.0061, -0.0324, -0.0513, -0.0417, -0.0270,  0.0142,  0.0150, -0.0613,\n         -0.0489,  0.0117,  0.0611, -0.0405, -0.0564, -0.0496,  0.0551,  0.0115,\n         -0.0464,  0.0308,  0.0567,  0.0538,  0.0096, -0.0452, -0.0252, -0.0354,\n          0.0040,  0.0004,  0.0478, -0.0591,  0.0351,  0.0389,  0.0075, -0.0101,\n          0.0136, -0.0458, -0.0513, -0.0231,  0.0089, -0.0234,  0.0198,  0.0563,\n         -0.0440, -0.0316, -0.0258,  0.0469,  0.0027, -0.0213, -0.0003, -0.0478,\n         -0.0416,  0.0557,  0.0605, -0.0152,  0.0190, -0.0189,  0.0356,  0.0508,\n         -0.0397,  0.0406, -0.0338,  0.0045,  0.0404,  0.0270,  0.0572, -0.0104,\n          0.0247, -0.0057,  0.0573, -0.0290,  0.0363, -0.0362,  0.0226,  0.0259,\n         -0.0192,  0.0250, -0.0438, -0.0314, -0.0422, -0.0435, -0.0304, -0.0190,\n         -0.0297, -0.0043, -0.0433,  0.0488, -0.0113,  0.0202,  0.0027, -0.0569,\n         -0.0477, -0.0609,  0.0051,  0.0330, -0.0090, -0.0351, -0.0527,  0.0325,\n         -0.0445, -0.0507, -0.0264, -0.0164,  0.0083,  0.0102,  0.0166,  0.0124,\n         -0.0096,  0.0385,  0.0083,  0.0572, -0.0518,  0.0263,  0.0455,  0.0407,\n          0.0470,  0.0355,  0.0343,  0.0080, -0.0547,  0.0140, -0.0423,  0.0342,\n         -0.0463,  0.0274, -0.0518, -0.0556, -0.0475, -0.0530, -0.0505,  0.0278,\n          0.0472, -0.0207,  0.0307, -0.0621, -0.0110,  0.0051,  0.0006, -0.0423,\n         -0.0145,  0.0329, -0.0028, -0.0579, -0.0142, -0.0473, -0.0236, -0.0501,\n          0.0620,  0.0026, -0.0306, -0.0076, -0.0174,  0.0455, -0.0010,  0.0287],\n        [-0.0385,  0.0224, -0.0323, -0.0375, -0.0288, -0.0282,  0.0267,  0.0350,\n          0.0332, -0.0031,  0.0397,  0.0275, -0.0242,  0.0253,  0.0399, -0.0095,\n          0.0179, -0.0161, -0.0143, -0.0490, -0.0139, -0.0314, -0.0457, -0.0007,\n         -0.0516,  0.0624, -0.0227,  0.0563,  0.0078, -0.0552, -0.0431,  0.0587,\n         -0.0119,  0.0558,  0.0392, -0.0224,  0.0214,  0.0484,  0.0332,  0.0007,\n         -0.0561,  0.0152,  0.0497,  0.0006, -0.0517,  0.0217, -0.0563,  0.0618,\n         -0.0609, -0.0559,  0.0621,  0.0335, -0.0569, -0.0186,  0.0072, -0.0514,\n          0.0346, -0.0022,  0.0020,  0.0554,  0.0511,  0.0326, -0.0612,  0.0510,\n         -0.0325,  0.0051,  0.0247,  0.0588,  0.0603, -0.0138, -0.0188, -0.0537,\n         -0.0311,  0.0167, -0.0334, -0.0358,  0.0097,  0.0337,  0.0257, -0.0562,\n          0.0076,  0.0313, -0.0260, -0.0358,  0.0136,  0.0062, -0.0326,  0.0548,\n          0.0457,  0.0155, -0.0201,  0.0313, -0.0453, -0.0088,  0.0569, -0.0353,\n          0.0127,  0.0163,  0.0016,  0.0048,  0.0557, -0.0361,  0.0481,  0.0073,\n         -0.0311,  0.0106,  0.0288,  0.0491, -0.0099,  0.0134, -0.0393,  0.0256,\n          0.0173, -0.0412,  0.0338,  0.0228, -0.0469, -0.0181, -0.0261, -0.0473,\n         -0.0536, -0.0161,  0.0094, -0.0335, -0.0384,  0.0439,  0.0029, -0.0172,\n         -0.0585, -0.0587, -0.0567,  0.0442,  0.0225, -0.0005, -0.0415, -0.0180,\n         -0.0017,  0.0560, -0.0178, -0.0431,  0.0551, -0.0226, -0.0146,  0.0389,\n          0.0223, -0.0498, -0.0480,  0.0450,  0.0472, -0.0610,  0.0602, -0.0328,\n         -0.0435, -0.0599,  0.0250,  0.0110, -0.0447,  0.0158, -0.0331,  0.0511,\n          0.0429, -0.0386, -0.0094,  0.0365,  0.0017, -0.0298, -0.0117,  0.0044,\n          0.0127,  0.0326,  0.0317,  0.0291,  0.0415,  0.0047, -0.0076,  0.0462,\n          0.0495, -0.0091, -0.0008,  0.0415,  0.0447,  0.0332, -0.0606,  0.0198,\n          0.0548, -0.0097,  0.0082,  0.0242, -0.0546,  0.0318, -0.0483, -0.0073,\n          0.0331,  0.0500,  0.0395, -0.0613,  0.0589, -0.0265,  0.0465,  0.0490,\n          0.0356, -0.0037,  0.0137,  0.0050, -0.0434, -0.0059,  0.0222, -0.0107,\n         -0.0097,  0.0152,  0.0545,  0.0382,  0.0099,  0.0508, -0.0145,  0.0390,\n         -0.0379,  0.0250,  0.0102, -0.0361,  0.0224,  0.0307,  0.0303,  0.0156,\n         -0.0120, -0.0372, -0.0190, -0.0434, -0.0107, -0.0119,  0.0462, -0.0545,\n          0.0477,  0.0382, -0.0449,  0.0388, -0.0336,  0.0089,  0.0031, -0.0049,\n         -0.0188, -0.0400,  0.0145, -0.0033,  0.0349, -0.0595,  0.0078,  0.0443,\n         -0.0379, -0.0206, -0.0558, -0.0003,  0.0284, -0.0154, -0.0390, -0.0066],\n        [ 0.0327, -0.0039,  0.0018, -0.0564, -0.0256, -0.0048,  0.0308,  0.0506,\n          0.0446, -0.0566,  0.0440, -0.0316,  0.0367, -0.0099,  0.0467, -0.0202,\n          0.0109,  0.0234,  0.0010, -0.0202, -0.0284, -0.0511, -0.0024, -0.0592,\n         -0.0127,  0.0080,  0.0323,  0.0175,  0.0091,  0.0253, -0.0609, -0.0371,\n          0.0518,  0.0566,  0.0410,  0.0329,  0.0007, -0.0439, -0.0310, -0.0516,\n         -0.0430,  0.0192,  0.0290,  0.0575,  0.0477, -0.0546, -0.0135, -0.0586,\n          0.0232, -0.0014,  0.0130, -0.0327, -0.0431,  0.0101, -0.0187,  0.0014,\n          0.0320, -0.0618,  0.0187,  0.0158,  0.0397, -0.0043,  0.0248, -0.0124,\n         -0.0344, -0.0583,  0.0556,  0.0611,  0.0360, -0.0316,  0.0078,  0.0019,\n          0.0247,  0.0223, -0.0391,  0.0546,  0.0228, -0.0500,  0.0318,  0.0590,\n          0.0116, -0.0289,  0.0012, -0.0304, -0.0442, -0.0303, -0.0236, -0.0027,\n         -0.0317, -0.0424, -0.0012, -0.0108, -0.0456,  0.0392, -0.0167, -0.0368,\n          0.0025,  0.0406,  0.0234,  0.0272,  0.0130,  0.0437, -0.0570, -0.0074,\n          0.0263, -0.0448,  0.0196, -0.0402,  0.0220,  0.0115, -0.0420,  0.0134,\n          0.0058, -0.0047, -0.0605,  0.0311, -0.0328, -0.0501,  0.0383, -0.0542,\n          0.0494,  0.0543, -0.0088,  0.0375,  0.0345,  0.0395, -0.0480,  0.0290,\n         -0.0337,  0.0569, -0.0392, -0.0452,  0.0305,  0.0173, -0.0399, -0.0474,\n          0.0276, -0.0548,  0.0432,  0.0037, -0.0571, -0.0532,  0.0113, -0.0009,\n          0.0585,  0.0278, -0.0025, -0.0202, -0.0186, -0.0456,  0.0432, -0.0117,\n          0.0443,  0.0309,  0.0189,  0.0432, -0.0405, -0.0443,  0.0489,  0.0177,\n          0.0484,  0.0290, -0.0472, -0.0555, -0.0407,  0.0072, -0.0222, -0.0276,\n         -0.0417, -0.0500, -0.0535,  0.0159, -0.0458,  0.0521,  0.0333,  0.0621,\n         -0.0362,  0.0540, -0.0525,  0.0285,  0.0115,  0.0333,  0.0532, -0.0615,\n          0.0084,  0.0341, -0.0514,  0.0219,  0.0122,  0.0164,  0.0596,  0.0441,\n          0.0327,  0.0577,  0.0502, -0.0311, -0.0036,  0.0143, -0.0098, -0.0257,\n         -0.0005, -0.0466, -0.0146,  0.0259,  0.0509, -0.0580, -0.0623,  0.0411,\n         -0.0222, -0.0399,  0.0208, -0.0381,  0.0004,  0.0244,  0.0468, -0.0352,\n         -0.0091,  0.0346,  0.0562,  0.0349, -0.0517, -0.0540,  0.0439, -0.0391,\n         -0.0476, -0.0384,  0.0122,  0.0478,  0.0616,  0.0328, -0.0399, -0.0300,\n          0.0607, -0.0353,  0.0523, -0.0483,  0.0480,  0.0184, -0.0209,  0.0256,\n         -0.0156, -0.0147, -0.0100,  0.0289,  0.0173,  0.0228,  0.0155, -0.0195,\n          0.0582,  0.0034, -0.0013, -0.0218,  0.0052,  0.0088, -0.0071, -0.0269]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0445, -0.0330, -0.0369], device='cuda:0', requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)":	{
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1768,  0.0056, -0.1600,  ..., -0.2328, -0.0894, -0.0372],\n        [ 0.1734, -0.2291, -0.1992,  ..., -0.0255, -0.1920, -0.0404],\n        [ 0.2403, -0.0665, -0.1089,  ...,  0.0583,  0.1886,  0.0925],\n        ...,\n        [ 0.0321,  0.0782, -0.2351,  ..., -0.0112,  0.0600, -0.2255],\n        [-0.2544, -0.0527,  0.0382,  ..., -0.0369,  0.0429, -0.0143],\n        [ 0.1640,  0.0818,  0.1031,  ...,  0.2423,  0.0885, -0.2002]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1187, -0.0145,  0.0472, -0.1500,  0.0601,  0.2632,  0.0794,  0.2635,\n         0.2590, -0.1685, -0.1216,  0.2111,  0.1390,  0.2431,  0.0578, -0.0703,\n        -0.2669,  0.2300,  0.1892, -0.0359,  0.1561,  0.1278,  0.0980,  0.0430,\n         0.0278,  0.2356,  0.1864,  0.0366, -0.0021,  0.2648,  0.0503, -0.1045,\n         0.2375,  0.1275, -0.2135, -0.2219,  0.0610,  0.1196, -0.1942,  0.1406,\n        -0.0023,  0.0892, -0.1256, -0.2571,  0.0010, -0.0347, -0.1354,  0.2448,\n         0.1359,  0.1352,  0.1868, -0.1998, -0.1041, -0.1653, -0.1015, -0.0908,\n         0.2137,  0.2440, -0.0337,  0.2118, -0.2102,  0.0444,  0.0698, -0.0797,\n        -0.2558,  0.1812, -0.2474,  0.1147, -0.0201,  0.1998, -0.0704,  0.1224,\n         0.0079,  0.0169, -0.0843,  0.1925,  0.1529,  0.1960, -0.2108,  0.2457,\n         0.1134,  0.2635,  0.1764,  0.1829,  0.2066, -0.1859, -0.0211, -0.1288,\n         0.1730,  0.0334, -0.1024, -0.2556, -0.0807,  0.1364,  0.0903,  0.0243,\n         0.0169, -0.0635,  0.2378,  0.1600, -0.0249, -0.1315,  0.2648,  0.1173,\n         0.0646,  0.1192, -0.1863,  0.2147, -0.1889, -0.0822,  0.1517, -0.0861,\n        -0.2594, -0.1170, -0.1198,  0.1011,  0.0909, -0.1318, -0.0579,  0.2178,\n         0.0536,  0.1578,  0.1079,  0.2422, -0.1871, -0.1156, -0.0560, -0.0194,\n        -0.1179, -0.1240,  0.0265,  0.2196, -0.2269,  0.1812, -0.2381, -0.1853,\n         0.1541,  0.0747,  0.0456,  0.0907, -0.0716,  0.2380,  0.1666,  0.0769,\n        -0.2177,  0.0687, -0.0033,  0.2397,  0.0850, -0.1259, -0.2130, -0.1403,\n        -0.0627, -0.0112,  0.0158,  0.0590,  0.2606,  0.1373, -0.1481, -0.0768,\n        -0.1176, -0.2616, -0.1427,  0.0392, -0.0765, -0.2561, -0.1658, -0.0670,\n        -0.0896,  0.1721, -0.0049,  0.1459, -0.2168,  0.2293,  0.1679,  0.2153,\n        -0.0464, -0.0898,  0.0510, -0.1421, -0.1843, -0.2579,  0.0663,  0.2005,\n         0.0410,  0.0805,  0.2412,  0.1143,  0.1473,  0.0856,  0.2177, -0.2107,\n         0.1164, -0.1962, -0.1871,  0.2315, -0.2654,  0.1796,  0.1334, -0.1346,\n        -0.0602, -0.2296, -0.2404,  0.0463, -0.2165, -0.2610,  0.0967, -0.0258,\n         0.2468,  0.0411, -0.2633,  0.2437, -0.0163, -0.1576,  0.2194, -0.1359,\n        -0.0019, -0.0553, -0.1896,  0.2638, -0.0884, -0.1851,  0.1906,  0.1083,\n        -0.0356, -0.0145,  0.0043,  0.2652,  0.1696,  0.1438,  0.0136, -0.1383,\n        -0.1451, -0.1022,  0.0974,  0.0780,  0.0478,  0.0823,  0.1098, -0.1671,\n        -0.1036, -0.2430, -0.2483, -0.1689, -0.0668,  0.2102,  0.1385,  0.0409,\n         0.2138, -0.0240, -0.0433,  0.1185,  0.2244, -0.2578, -0.1149, -0.1302],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0504, -0.0328, -0.0041,  ..., -0.0570,  0.0604,  0.0232],\n        [-0.0472,  0.0321,  0.0306,  ..., -0.0569, -0.0160,  0.0162],\n        [-0.0048,  0.0235, -0.0493,  ..., -0.0485,  0.0614,  0.0435],\n        ...,\n        [ 0.0381,  0.0577,  0.0287,  ...,  0.0430, -0.0070, -0.0096],\n        [-0.0040, -0.0513,  0.0272,  ...,  0.0581,  0.0084, -0.0518],\n        [ 0.0022,  0.0086, -0.0461,  ..., -0.0057, -0.0220, -0.0236]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0500,  0.0459,  0.0394,  0.0578, -0.0265, -0.0122, -0.0218, -0.0005,\n        -0.0517,  0.0352, -0.0560,  0.0334,  0.0548,  0.0417, -0.0503,  0.0620,\n        -0.0428, -0.0035,  0.0239, -0.0527, -0.0226,  0.0373,  0.0440,  0.0146,\n         0.0297, -0.0137,  0.0594,  0.0066, -0.0563,  0.0070, -0.0001, -0.0559,\n        -0.0431, -0.0406, -0.0332,  0.0485,  0.0544, -0.0261,  0.0282,  0.0217,\n         0.0387, -0.0035, -0.0168, -0.0237,  0.0240, -0.0403,  0.0483,  0.0196,\n         0.0069, -0.0136, -0.0023, -0.0249, -0.0180,  0.0107,  0.0129,  0.0031,\n         0.0403, -0.0128, -0.0360,  0.0430,  0.0430,  0.0427, -0.0214,  0.0344,\n        -0.0153,  0.0153,  0.0452, -0.0384, -0.0159, -0.0600,  0.0064, -0.0154,\n        -0.0030,  0.0048,  0.0318,  0.0429,  0.0157,  0.0108,  0.0228, -0.0100,\n         0.0064,  0.0049,  0.0025, -0.0161, -0.0195,  0.0397,  0.0272, -0.0411,\n        -0.0042,  0.0384,  0.0482, -0.0279, -0.0418, -0.0138, -0.0404,  0.0168,\n        -0.0500, -0.0219, -0.0539,  0.0256,  0.0302, -0.0083,  0.0118,  0.0592,\n        -0.0616,  0.0266,  0.0330,  0.0176,  0.0565, -0.0589,  0.0465,  0.0207,\n        -0.0097,  0.0325, -0.0359, -0.0500,  0.0425, -0.0356, -0.0150,  0.0312,\n         0.0577,  0.0221, -0.0239, -0.0446, -0.0023, -0.0416, -0.0618,  0.0035,\n         0.0003,  0.0476, -0.0571, -0.0504, -0.0435,  0.0002,  0.0536, -0.0527,\n        -0.0056, -0.0575, -0.0515, -0.0299,  0.0558, -0.0297,  0.0078, -0.0420,\n         0.0056,  0.0092,  0.0451,  0.0258,  0.0125, -0.0574, -0.0269,  0.0209,\n         0.0318, -0.0355, -0.0362,  0.0565, -0.0347, -0.0531, -0.0074, -0.0234,\n        -0.0465, -0.0398, -0.0340,  0.0320,  0.0130, -0.0256,  0.0451,  0.0120,\n         0.0301,  0.0466,  0.0441, -0.0458, -0.0559, -0.0491, -0.0607,  0.0601,\n         0.0574, -0.0135,  0.0583, -0.0002, -0.0585,  0.0623,  0.0417,  0.0281,\n        -0.0450,  0.0511, -0.0393,  0.0040, -0.0574,  0.0532,  0.0153,  0.0289,\n        -0.0074, -0.0599,  0.0037,  0.0261,  0.0175, -0.0142,  0.0197,  0.0453,\n         0.0018,  0.0448,  0.0323,  0.0123, -0.0071,  0.0442, -0.0497,  0.0535,\n        -0.0507,  0.0394,  0.0407,  0.0343, -0.0405,  0.0355,  0.0199, -0.0350,\n        -0.0621,  0.0426,  0.0050, -0.0213,  0.0470, -0.0118, -0.0508,  0.0221,\n         0.0330, -0.0226,  0.0006, -0.0381,  0.0522, -0.0392, -0.0008, -0.0302,\n        -0.0235,  0.0384,  0.0193,  0.0349, -0.0558,  0.0353,  0.0014,  0.0331,\n         0.0465,  0.0482,  0.0071, -0.0235,  0.0420, -0.0139, -0.0378, -0.0112,\n        -0.0110,  0.0388,  0.0064, -0.0414, -0.0127,  0.0277, -0.0226, -0.0171],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0590,  0.0474, -0.0397, -0.0094,  0.0033, -0.0367,  0.0077,  0.0620,\n         -0.0234,  0.0170, -0.0078, -0.0070,  0.0120,  0.0037, -0.0300, -0.0341,\n          0.0440,  0.0029, -0.0441, -0.0583, -0.0546, -0.0554, -0.0112, -0.0069,\n          0.0267,  0.0480, -0.0412,  0.0240,  0.0439,  0.0094,  0.0294, -0.0299,\n          0.0287, -0.0174, -0.0125, -0.0232, -0.0447, -0.0554,  0.0590,  0.0459,\n         -0.0297,  0.0553,  0.0339,  0.0327, -0.0155,  0.0190, -0.0247, -0.0327,\n          0.0004,  0.0605, -0.0142, -0.0173, -0.0006,  0.0592,  0.0199, -0.0062,\n         -0.0006,  0.0295, -0.0373,  0.0223, -0.0474, -0.0215, -0.0203, -0.0322,\n         -0.0465,  0.0047, -0.0156, -0.0463,  0.0453, -0.0402,  0.0148,  0.0334,\n          0.0130, -0.0394,  0.0608,  0.0504,  0.0449,  0.0420, -0.0318, -0.0153,\n         -0.0007, -0.0414, -0.0307,  0.0565,  0.0363, -0.0365, -0.0505,  0.0606,\n         -0.0203, -0.0422,  0.0476, -0.0345,  0.0323,  0.0233,  0.0516,  0.0500,\n          0.0380, -0.0230,  0.0490,  0.0142,  0.0423, -0.0533, -0.0300,  0.0066,\n          0.0095, -0.0199,  0.0378,  0.0608,  0.0620,  0.0455, -0.0338,  0.0063,\n         -0.0035, -0.0034,  0.0559, -0.0384,  0.0352, -0.0284,  0.0417, -0.0142,\n         -0.0371,  0.0590, -0.0278,  0.0096,  0.0021, -0.0271, -0.0083,  0.0381,\n          0.0023, -0.0417,  0.0544,  0.0463, -0.0326,  0.0223,  0.0345,  0.0467,\n         -0.0234,  0.0378, -0.0242,  0.0242,  0.0213, -0.0207, -0.0074, -0.0623,\n          0.0206, -0.0096, -0.0481,  0.0340,  0.0105, -0.0576,  0.0033,  0.0117,\n          0.0262, -0.0012,  0.0591, -0.0281,  0.0064, -0.0399,  0.0428, -0.0173,\n         -0.0014,  0.0019,  0.0621, -0.0086,  0.0179,  0.0362, -0.0336,  0.0386,\n          0.0483,  0.0161, -0.0204, -0.0563,  0.0005, -0.0170,  0.0009,  0.0145,\n         -0.0104,  0.0409, -0.0198,  0.0515,  0.0400, -0.0459, -0.0010,  0.0008,\n          0.0251, -0.0112, -0.0334,  0.0048, -0.0501,  0.0029,  0.0599, -0.0586,\n         -0.0250, -0.0086, -0.0449,  0.0057,  0.0145,  0.0042,  0.0556, -0.0450,\n         -0.0537, -0.0322,  0.0193, -0.0527,  0.0006, -0.0407,  0.0147,  0.0104,\n         -0.0174,  0.0040,  0.0182,  0.0071, -0.0188,  0.0521, -0.0123,  0.0387,\n          0.0615, -0.0316, -0.0281, -0.0448, -0.0414, -0.0623,  0.0384,  0.0581,\n         -0.0162, -0.0191,  0.0460, -0.0279,  0.0456,  0.0114,  0.0234,  0.0211,\n         -0.0593, -0.0341, -0.0460,  0.0392,  0.0512,  0.0163,  0.0096,  0.0156,\n          0.0454,  0.0384, -0.0256, -0.0561,  0.0305, -0.0312, -0.0479, -0.0448,\n          0.0271,  0.0314,  0.0285,  0.0397, -0.0062,  0.0141, -0.0335, -0.0462]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([0.0057], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0198,  0.0509,  0.1029,  ..., -0.0809,  0.0448, -0.0199],\n        [ 0.0793, -0.2493, -0.0495,  ...,  0.0817,  0.2073, -0.2551],\n        [-0.2489, -0.2074,  0.2519,  ...,  0.1753,  0.0644,  0.0788],\n        ...,\n        [ 0.0461,  0.0036,  0.0340,  ..., -0.1588, -0.0558,  0.0228],\n        [ 0.2110, -0.1540,  0.0049,  ...,  0.0580,  0.1851, -0.2029],\n        [ 0.0175, -0.1501,  0.1571,  ...,  0.1391, -0.1945, -0.0671]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2032,  0.1033,  0.0146,  0.1174,  0.2221, -0.0170, -0.2266,  0.0460,\n         0.1687, -0.2493, -0.1780,  0.0422,  0.0139,  0.1795, -0.0274,  0.1105,\n         0.2447, -0.2287, -0.0254, -0.1112,  0.0935, -0.0604, -0.2165, -0.2348,\n        -0.0739,  0.1766, -0.2289, -0.1103, -0.2085,  0.2507,  0.0773, -0.0032,\n        -0.2415,  0.1284, -0.0926, -0.2465,  0.0949, -0.0274, -0.2665, -0.2268,\n         0.1219,  0.0713, -0.0425,  0.1274, -0.1318,  0.0403, -0.0677, -0.1599,\n        -0.0442, -0.1798, -0.1062, -0.0513,  0.0827,  0.2231, -0.0754,  0.1773,\n         0.1280,  0.1007,  0.1004,  0.1427, -0.0326,  0.1999, -0.1815, -0.1373,\n        -0.0983, -0.1201,  0.2469,  0.1166, -0.1803,  0.2008, -0.2350,  0.1539,\n        -0.0096, -0.1768,  0.0046,  0.0657,  0.0348, -0.1833, -0.1977, -0.1395,\n        -0.0021,  0.0656,  0.2488, -0.0722, -0.1850,  0.1612,  0.1828,  0.0423,\n        -0.1406, -0.1220,  0.1332,  0.1295, -0.0005,  0.0364,  0.1262, -0.0765,\n        -0.0469, -0.2306, -0.2509, -0.1462,  0.0808, -0.0757,  0.1172,  0.1691,\n         0.2123,  0.0919, -0.1003,  0.2207, -0.1481,  0.2560, -0.1489,  0.1745,\n        -0.0043,  0.1214, -0.2078, -0.2349, -0.0078, -0.2502,  0.1371,  0.1664,\n        -0.2535,  0.2278,  0.0473,  0.1590,  0.1921, -0.2473, -0.1460, -0.0328,\n         0.0023,  0.2395,  0.1857, -0.1186, -0.0286, -0.2376,  0.1053, -0.2543,\n        -0.0946, -0.2631, -0.1980, -0.0935,  0.2508, -0.0004, -0.1723, -0.1293,\n         0.1148, -0.0571,  0.2159, -0.0394, -0.1759,  0.1327, -0.0061, -0.1728,\n        -0.0070,  0.0265, -0.2391,  0.0311, -0.1826, -0.1239, -0.1390, -0.1259,\n         0.1512, -0.2465, -0.2576,  0.0004,  0.1257, -0.0679, -0.1699,  0.2622,\n        -0.2229,  0.2190, -0.0431,  0.1943, -0.1537, -0.2355, -0.2116,  0.0416,\n        -0.2431, -0.1208, -0.1634,  0.2389,  0.2564, -0.2199, -0.0410,  0.1425,\n        -0.0596, -0.1789, -0.2402, -0.0679, -0.1505,  0.1571,  0.1226,  0.1883,\n         0.2012,  0.0607,  0.0843, -0.1298,  0.0106,  0.1701,  0.0492,  0.2527,\n         0.2212,  0.1765, -0.1075,  0.0468,  0.0386,  0.2602, -0.0949,  0.0126,\n         0.0044, -0.1364,  0.1590, -0.2197,  0.0184, -0.0685,  0.0977, -0.1258,\n         0.0233, -0.1609,  0.2367, -0.0860,  0.0185, -0.1846, -0.2642, -0.1020,\n        -0.1930, -0.1098,  0.1648, -0.1336, -0.0261,  0.2115,  0.0964,  0.1986,\n        -0.0089, -0.2480,  0.1327, -0.1179, -0.2090,  0.1410,  0.0165,  0.2406,\n        -0.0479, -0.1536,  0.2495,  0.0790, -0.2205, -0.1235,  0.0635,  0.2191,\n         0.1709, -0.1656, -0.1424, -0.0169, -0.2439,  0.0067,  0.2386, -0.2451],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0398,  0.0204, -0.0081,  ...,  0.0245,  0.0541,  0.0451],\n        [ 0.0604,  0.0507, -0.0585,  ...,  0.0513,  0.0532,  0.0288],\n        [-0.0058, -0.0493,  0.0111,  ...,  0.0608,  0.0396,  0.0344],\n        ...,\n        [-0.0241, -0.0415,  0.0262,  ...,  0.0446, -0.0456, -0.0063],\n        [-0.0394,  0.0555,  0.0034,  ..., -0.0139,  0.0185,  0.0283],\n        [-0.0092, -0.0573, -0.0263,  ...,  0.0222,  0.0431, -0.0440]],\n       device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([ 3.9048e-03,  2.1574e-02, -1.1005e-02,  2.4183e-02,  3.2534e-02,\n        -3.3743e-02, -4.0422e-03, -5.3024e-02, -1.4131e-02, -4.9334e-02,\n        -2.3312e-02,  5.4515e-02, -4.7153e-02,  4.5458e-02, -3.9268e-02,\n         8.3877e-03, -7.3382e-03,  1.6383e-02, -2.8477e-02,  2.2241e-02,\n        -3.8105e-02, -4.7430e-02, -2.3048e-02,  1.8019e-02, -3.3381e-02,\n        -3.1290e-02,  5.8679e-02, -1.2932e-02,  1.3860e-02, -5.5323e-03,\n        -1.6675e-02,  3.0720e-02, -9.0352e-03, -2.6343e-02,  5.2876e-02,\n        -3.0360e-02, -4.4997e-02, -1.3136e-02, -7.3841e-04, -3.0139e-02,\n         2.7645e-03, -7.5837e-03,  3.5965e-02,  1.8923e-02, -5.5858e-02,\n        -3.1186e-02, -2.9359e-02,  6.1492e-02,  3.2940e-03, -3.4747e-02,\n        -3.5472e-02, -1.3977e-02,  3.7621e-02,  6.2461e-02, -2.9364e-02,\n        -3.2132e-02,  1.1491e-02,  7.9730e-03, -4.6148e-02,  3.8341e-02,\n         2.0482e-02,  1.7033e-02,  5.3329e-02, -2.7434e-02,  7.4931e-03,\n        -5.5484e-02,  5.4683e-02, -3.6156e-02,  2.0895e-02,  5.8426e-02,\n        -5.8538e-02, -2.3072e-02, -5.1497e-02, -5.1776e-02, -2.9869e-02,\n        -4.8895e-02,  2.4200e-02, -5.0240e-02, -1.9605e-02, -2.9475e-02,\n         3.9443e-05, -1.3211e-02,  5.7421e-02, -1.9668e-02, -7.8719e-03,\n        -5.5853e-03,  6.7320e-04, -2.2309e-02, -3.6204e-02, -1.0454e-02,\n        -3.7717e-02,  1.4182e-02, -1.8460e-03, -3.2889e-02,  4.8449e-02,\n         2.6050e-02, -6.2479e-02,  3.8324e-03, -2.7123e-02, -1.1528e-02,\n         1.0323e-03,  3.5475e-02,  2.6622e-02,  3.8778e-02, -3.4551e-02,\n         3.3271e-02,  1.6628e-02, -5.6607e-02, -1.7540e-02,  5.3056e-02,\n         2.3654e-02,  2.0510e-02, -1.4940e-02,  3.5134e-02, -6.0713e-02,\n        -5.3427e-02, -5.7889e-03, -4.0597e-02, -1.4364e-02, -6.1374e-02,\n         5.7555e-03,  4.8226e-02,  1.8347e-03, -6.2276e-02,  1.6883e-02,\n        -1.3041e-02,  5.4609e-02, -5.1981e-02, -5.7395e-02, -6.2205e-02,\n         5.0269e-02, -5.5210e-02, -6.0732e-02,  5.9687e-02,  3.0275e-02,\n        -5.6525e-02, -2.1263e-02, -2.3915e-02, -2.9648e-02, -3.8705e-02,\n         2.7335e-03,  3.9414e-02, -1.4854e-02,  9.3599e-03, -9.0421e-03,\n         1.9945e-02, -1.4221e-02,  4.7112e-02, -1.9347e-02,  3.6835e-02,\n        -2.1495e-02,  6.1693e-02, -3.3383e-03, -5.7891e-02, -5.3921e-02,\n         5.8997e-02,  8.8001e-03, -1.6484e-02, -4.7432e-02, -2.5082e-02,\n         4.6924e-03,  1.5771e-02,  3.5383e-03,  4.9198e-02, -2.1220e-02,\n        -4.8849e-02,  4.1869e-04,  9.6992e-03, -3.6853e-02,  3.8505e-03,\n        -2.4716e-02,  3.5932e-02,  9.0228e-03,  2.9376e-02, -3.5010e-02,\n         4.5773e-03, -3.8382e-02,  1.4425e-02, -4.2902e-02, -1.0590e-03,\n        -1.2679e-02,  3.4802e-03, -5.6717e-02,  1.2632e-02, -2.6073e-02,\n        -4.7833e-02, -3.9666e-02,  4.1066e-02,  5.3430e-02, -4.6832e-02,\n        -5.7929e-02, -5.8264e-04, -1.4093e-02,  2.1208e-02,  3.8703e-02,\n         2.9370e-03,  9.1674e-03,  3.0681e-04, -1.0884e-02,  1.2379e-02,\n         3.6347e-03, -1.1364e-03,  4.8373e-02,  2.9317e-02,  5.1176e-02,\n        -3.0153e-02, -2.8935e-03,  1.1227e-02, -5.8618e-02,  1.1969e-02,\n         7.7420e-03,  2.9972e-02,  2.4609e-04,  4.4606e-02, -2.5356e-02,\n         5.6037e-02,  6.3339e-03,  3.4087e-03,  5.6976e-02, -4.1888e-02,\n        -5.7119e-03, -7.6832e-03, -5.3568e-02, -5.4952e-02,  3.9376e-03,\n        -5.8436e-02,  5.6198e-02,  3.4100e-02,  1.7658e-02, -3.2102e-02,\n        -2.1439e-02, -5.5724e-02,  2.1767e-02, -1.8205e-02,  4.8394e-02,\n         1.6337e-02,  7.5377e-03,  1.6566e-02, -2.7799e-02, -5.6529e-02,\n         8.2166e-03, -3.8752e-03, -1.8406e-02, -5.3407e-02, -1.8497e-02,\n         4.3667e-02, -2.1424e-02,  3.4502e-02,  2.0564e-02, -3.2415e-02,\n         3.1211e-02,  3.7426e-02, -4.5413e-02, -8.6662e-03,  4.3584e-02,\n         3.1396e-02], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.1850e-02,  9.6254e-05,  5.2145e-02, -2.0427e-02, -7.3187e-03,\n          6.2246e-02,  1.9453e-02, -4.9074e-02, -4.8667e-03,  1.6419e-02,\n          4.7418e-03,  4.9396e-02,  1.3771e-03, -4.6917e-02, -5.0577e-02,\n          2.4406e-02,  2.1224e-02,  3.6825e-02, -1.2623e-02, -5.2208e-02,\n          2.2402e-02,  6.3886e-04,  5.1799e-02, -1.6023e-02, -2.6141e-02,\n          9.1676e-03,  1.6891e-02,  6.1733e-02,  5.2159e-02,  4.5710e-02,\n          5.9459e-02, -3.8299e-02,  5.8606e-03,  5.9016e-02,  6.5828e-03,\n          4.1698e-02,  2.9845e-02,  6.1671e-02, -1.5038e-02,  9.8490e-04,\n          2.6191e-02, -2.5480e-03,  1.5057e-02, -4.6581e-02, -1.0476e-02,\n         -2.6142e-02, -4.8111e-02,  1.6993e-02, -4.7490e-02, -3.2123e-02,\n         -2.4901e-02,  3.7425e-02,  4.1948e-03,  4.6523e-02,  1.4070e-02,\n          2.0280e-02, -4.5477e-02,  7.7266e-03,  5.4545e-02, -3.3317e-02,\n          5.9411e-02,  1.7974e-02, -4.8488e-02, -7.4885e-03,  2.8144e-02,\n         -2.3596e-02,  1.2804e-02,  5.0216e-02,  3.6245e-02, -1.1508e-02,\n         -4.8281e-02, -5.2793e-02, -5.0429e-02,  8.5230e-03,  1.7088e-02,\n         -2.8461e-02,  2.5148e-02, -3.0721e-02,  4.9128e-03,  3.7309e-02,\n         -3.1526e-02,  4.2944e-02,  7.6105e-03, -1.2763e-02,  2.2289e-02,\n         -5.6153e-02,  2.7076e-02, -1.0474e-02,  4.4770e-02,  1.3008e-02,\n          1.6522e-02,  3.3067e-02,  1.0152e-02,  3.0906e-02, -5.8517e-03,\n         -3.7948e-03, -3.2381e-02,  3.2961e-02, -2.2705e-02,  5.7281e-02,\n         -3.3357e-02,  1.0795e-02, -2.6509e-02,  3.4499e-02,  5.9936e-03,\n          4.2765e-02, -2.7076e-02,  2.6296e-02,  2.7945e-02,  4.3302e-03,\n          5.7212e-02,  4.7805e-02,  5.9481e-02, -6.2351e-02, -3.6697e-02,\n          3.5847e-02, -5.7014e-02,  4.5530e-02,  3.2032e-02,  4.6794e-02,\n         -4.4197e-02, -2.9945e-03, -5.2221e-02,  5.0929e-02,  7.6213e-04,\n          4.5927e-02,  6.1937e-02,  3.6511e-02, -6.1067e-02,  4.8873e-02,\n          4.6556e-02, -5.2908e-02,  4.9261e-02,  3.2546e-03, -4.0115e-02,\n         -8.2285e-03, -1.6088e-02,  5.1301e-03,  4.5164e-02,  5.0844e-03,\n         -1.5887e-02,  4.2302e-02,  5.1438e-02,  1.4307e-02,  5.4801e-02,\n         -3.0784e-02, -3.4805e-03,  1.9430e-02,  5.0566e-03, -7.9205e-03,\n          5.4113e-02,  2.6284e-02, -9.4083e-03,  1.9397e-02, -5.4864e-02,\n          3.8903e-02, -5.5359e-02,  6.1466e-03, -7.9018e-03, -3.2284e-02,\n          4.1622e-02,  2.5171e-02,  5.8127e-02,  3.0189e-02, -4.8237e-02,\n         -2.3084e-02, -2.6494e-02, -4.4275e-02,  1.0787e-02,  5.3675e-02,\n         -5.1051e-02,  3.7893e-02, -4.4314e-02,  2.3909e-02,  5.3116e-02,\n         -3.1521e-02, -4.1152e-02,  7.2898e-03, -3.6532e-02,  3.1747e-02,\n          4.1091e-02,  5.8488e-02, -3.4523e-02, -3.0744e-02, -5.7184e-02,\n          6.0100e-02,  3.1318e-02,  6.4005e-03, -3.8256e-02, -6.2171e-02,\n         -4.7432e-03, -2.2598e-02, -6.0701e-02, -8.8612e-03, -9.8999e-03,\n          3.4124e-02,  4.4937e-02,  2.7819e-02,  1.1292e-02, -4.1241e-02,\n          3.2599e-02,  1.4296e-02, -5.4993e-02, -4.7226e-03,  5.6266e-03,\n         -5.7269e-02,  6.0903e-02, -5.8601e-02,  9.1637e-03, -5.7374e-03,\n          4.2750e-02, -3.1434e-02,  3.1183e-02, -2.1519e-02, -5.1015e-02,\n          5.2059e-02,  1.5361e-04,  2.9651e-02,  6.2371e-02,  3.0871e-02,\n         -7.5478e-03, -2.6959e-02,  1.6449e-02,  5.8957e-02, -2.7672e-02,\n          3.5424e-02, -6.2203e-02, -3.9646e-02, -3.3094e-02,  5.6046e-02,\n          3.2608e-02, -3.1356e-02, -4.0486e-02, -2.5819e-02,  1.1862e-02,\n          1.1511e-02, -1.3739e-02,  4.3089e-02,  3.9914e-02,  5.8645e-02,\n         -2.9536e-02,  6.1192e-02,  4.9375e-03, -4.0944e-02, -2.2565e-02,\n         -2.2539e-02,  8.8568e-03, -3.8093e-02,  3.8967e-02, -3.8513e-03,\n          2.8764e-02,  6.5629e-03, -4.6070e-02,  3.3465e-02,  4.8165e-02,\n         -1.7196e-02]], device='cuda:0', requires_grad=True)",
                                "Parameter containing:\ntensor([0.0242], device='cuda:0', requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "q_params":	"<itertools.chain object at 0x7fe28e658e10>",
            "test_env":	{
                "<TimeLimit<HopperEnv<Hopper-v2>>>":	{
                    "_action_space":	null,
                    "_elapsed_steps":	null,
                    "_max_episode_steps":	1000,
                    "_metadata":	null,
                    "_observation_space":	null,
                    "_reward_range":	null,
                    "env":	{
                        "<HopperEnv<Hopper-v2>>":	{
                            "_ezpickle_args":	[],
                            "_ezpickle_kwargs":	{},
                            "_viewers":	{},
                            "action_space":	{
                                "Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)":	{
                                    "_np_random":	"RandomState(MT19937)",
                                    "_shape":	[
                                        3
                                    ],
                                    "bounded_above":	"[ True  True  True]",
                                    "bounded_below":	"[ True  True  True]",
                                    "dtype":	"float32",
                                    "high":	"[1. 1. 1.]",
                                    "low":	"[-1. -1. -1.]"
                                }
                            },
                            "data":	"<mujoco_py.cymj.PyMjData object at 0x55557c082b50>",
                            "frame_skip":	4,
                            "init_qpos":	"[0.   1.25 0.   0.   0.   0.  ]",
                            "init_qvel":	"[0. 0. 0. 0. 0. 0.]",
                            "metadata":	{
                                "render.modes":	[
                                    "human",
                                    "rgb_array",
                                    "depth_array"
                                ],
                                "video.frames_per_second":	125
                            },
                            "model":	"<mujoco_py.cymj.PyMjModel object at 0x55557cf396f0>",
                            "np_random":	"RandomState(MT19937)",
                            "observation_space":	{
                                "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)":	{
                                    "_np_random":	null,
                                    "_shape":	[
                                        11
                                    ],
                                    "bounded_above":	"[False False False False False False False False False False False]",
                                    "bounded_below":	"[False False False False False False False False False False False]",
                                    "dtype":	"float64",
                                    "high":	"[inf inf inf inf inf inf inf inf inf inf inf]",
                                    "low":	"[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]"
                                }
                            },
                            "sim":	"<mujoco_py.cymj.MjSim object at 0x7fe28e776200>",
                            "spec":	{
                                "EnvSpec(Hopper-v2)":	{
                                    "_env_name":	"Hopper",
                                    "_kwargs":	{},
                                    "entry_point":	"gym.envs.mujoco:HopperEnv",
                                    "id":	"Hopper-v2",
                                    "max_episode_steps":	1000,
                                    "nondeterministic":	false,
                                    "order_enforce":	true,
                                    "reward_threshold":	3800.0
                                }
                            },
                            "viewer":	null
                        }
                    }
                }
            }
        }
    }
}